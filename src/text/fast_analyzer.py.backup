#!/usr/bin/env python3
"""
ë¹ ë¥¸ ë¶„ì„ ì„œë¹„ìŠ¤ - ì‚¬ì „ ë¡œë”©ëœ ëª¨ë¸ í™œìš©
ë¶„ì„ ìš”ì²­ ì‹œ ì¦‰ì‹œ ì²˜ë¦¬ (ëª¨ë¸ ë¡œë”© ì‹œê°„ ì œê±°)
"""

import asyncio
import logging
import time
from typing import Dict, Any, List
from pathlib import Path
import librosa
import numpy as np

from .model_preloader import model_preloader

logger = logging.getLogger(__name__)

class FastAnalyzer:
    """ì‚¬ì „ ë¡œë”©ëœ ëª¨ë¸ì„ í™œìš©í•œ ë¹ ë¥¸ ë¶„ì„"""
    
    def __init__(self):
        self.ready = False
        
    async def wait_for_models(self, timeout: int = 300):
        """ëª¨ë¸ ì¤€ë¹„ ëŒ€ê¸°"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            if model_preloader.preload_complete:
                self.ready = True
                logger.info("âœ… ëª¨ë“  ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ - ë¹ ë¥¸ ë¶„ì„ ê°€ëŠ¥")
                return True
            
            await asyncio.sleep(2)
            logger.info("â³ ëª¨ë¸ ë¡œë”© ëŒ€ê¸° ì¤‘...")
        
        logger.error("âŒ ëª¨ë¸ ë¡œë”© íƒ€ì„ì•„ì›ƒ")
        return False
    
    async def analyze_audio_fast(self, audio_path: str) -> Dict[str, Any]:
        """ğŸš€ ë¹ ë¥¸ ì˜¤ë””ì˜¤ ë¶„ì„ (ì‚¬ì „ ë¡œë”©ëœ ëª¨ë¸ ì‚¬ìš©)"""
        
        if not self.ready:
            raise ValueError("ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. wait_for_models()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        start_time = time.time()
        logger.info(f"ğŸ¯ ë¹ ë¥¸ ë¶„ì„ ì‹œì‘: {audio_path}")
        
        try:
            # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
            audio_data, sample_rate = librosa.load(audio_path, sr=16000)
            
            # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
            tasks = [
                self._transcribe_fast(audio_data, sample_rate),
                self._diarize_fast(audio_data, sample_rate),
            ]
            
            # ìŒì„± ì¸ì‹ + í™”ì ë¶„ë¦¬ ë³‘ë ¬ ì‹¤í–‰
            transcription_result, diarization_result = await asyncio.gather(*tasks)
            
            # í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ (ìˆœì°¨ ì‹¤í–‰ - ë¹ ë¦„)
            text_content = transcription_result.get('text', '')
            
            # ë¬¸ì¥ ë¶€í˜¸ ë³µì›
            punctuated_text = await self._restore_punctuation_fast(text_content)
            
            # ê°ì • ë¶„ì„ 
            sentiment_result = await self._analyze_sentiment_fast(punctuated_text)
            
            # ê²°ê³¼ í†µí•©
            total_time = time.time() - start_time
            
            result = {
                "audio_path": audio_path,
                "processing_time": f"{total_time:.2f}ì´ˆ",
                "transcription": transcription_result,
                "speaker_diarization": diarization_result,
                "punctuated_text": punctuated_text,
                "sentiment_analysis": sentiment_result,
                "status": "completed",
                "fast_analysis": True
            }
            
            logger.info(f"âœ… ë¹ ë¥¸ ë¶„ì„ ì™„ë£Œ: {total_time:.2f}ì´ˆ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë¹ ë¥¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    async def _transcribe_fast(self, audio_data: np.ndarray, sample_rate: int) -> Dict[str, Any]:
        """ë¹ ë¥¸ ìŒì„± ì¸ì‹ (ì‚¬ì „ ë¡œë”©ëœ Whisper ì‚¬ìš©)"""
        try:
            whisper_model = model_preloader.get_model('whisper')
            
            # ì¦‰ì‹œ ì¶”ë¡  (ëª¨ë¸ ì´ë¯¸ ë¡œë”©ë¨)
            result = whisper_model.transcribe(audio_data)
            
            return {
                "text": result["text"],
                "language": result.get("language", "ko"),
                "segments": result.get("segments", [])
            }
            
        except Exception as e:
            logger.error(f"ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
            return {"text": "", "error": str(e)}
    
    async def _diarize_fast(self, audio_data: np.ndarray, sample_rate: int) -> Dict[str, Any]:
        """ë¹ ë¥¸ í™”ì ë¶„ë¦¬ (ì‚¬ì „ ë¡œë”©ëœ ëª¨ë¸ ì‚¬ìš©)"""
        try:
            diarization_model = model_preloader.get_model('diarization')
            
            # ì˜¤ë””ì˜¤ ë°ì´í„° ì¤€ë¹„
            import torch
            waveform = torch.from_numpy(audio_data).unsqueeze(0)
            if model_preloader.device == "cuda":
                waveform = waveform.cuda()
            
            audio_input = {
                "waveform": waveform,
                "sample_rate": sample_rate
            }
            
            # ì¦‰ì‹œ ì¶”ë¡  (ëª¨ë¸ ì´ë¯¸ ë¡œë”©ë¨)
            diarization_result = diarization_model(audio_input)
            
            # ê²°ê³¼ ì²˜ë¦¬
            segments = []
            for turn, _, speaker in diarization_result.itertracks(yield_label=True):
                segments.append({
                    "start": turn.start,
                    "end": turn.end,
                    "speaker": speaker
                })
            
            return {
                "segments": segments,
                "num_speakers": len(set(seg["speaker"] for seg in segments))
            }
            
        except Exception as e:
            logger.error(f"í™”ì ë¶„ë¦¬ ì‹¤íŒ¨: {e}")
            return {"segments": [], "error": str(e)}
    
    async def _restore_punctuation_fast(self, text: str) -> str:
        """ë¹ ë¥¸ ë¬¸ì¥ ë¶€í˜¸ ë³µì›"""
        try:
            punctuation_model = model_preloader.get_model('punctuation')
            
            # ì¦‰ì‹œ ì¶”ë¡ 
            result = punctuation_model(text)
            
            return result[0]["generated_text"] if result else text
            
        except Exception as e:
            logger.error(f"ë¬¸ì¥ ë¶€í˜¸ ë³µì› ì‹¤íŒ¨: {e}")
            return text
    
    async def _analyze_sentiment_fast(self, text: str) -> Dict[str, Any]:
        """ë¹ ë¥¸ ê°ì • ë¶„ì„"""
        try:
            sentiment_model = model_preloader.get_model('sentiment')
            
            # í…ìŠ¤íŠ¸ ë¶„í•  (ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬)
            chunks = [text[i:i+512] for i in range(0, len(text), 512)]
            
            results = []
            for chunk in chunks:
                if chunk.strip():
                    result = sentiment_model(chunk)
                    results.extend(result)
            
            # í‰ê·  ì ìˆ˜ ê³„ì‚°
            if results:
                avg_score = sum(r["score"] for r in results) / len(results)
                dominant_label = max(set(r["label"] for r in results), 
                                   key=lambda x: sum(1 for r in results if r["label"] == x))
                
                return {
                    "overall_sentiment": dominant_label,
                    "confidence": avg_score,
                    "details": results
                }
            
            return {"overall_sentiment": "neutral", "confidence": 0.5}
            
        except Exception as e:
            logger.error(f"ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"overall_sentiment": "unknown", "error": str(e)}
    
    def get_status(self) -> Dict[str, Any]:
        """ë¶„ì„ê¸° ìƒíƒœ í™•ì¸"""
        return {
            "ready": self.ready,
            "models_ready": model_preloader.preload_complete,
            "model_status": model_preloader.get_status()
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
fast_analyzer = FastAnalyzer() 