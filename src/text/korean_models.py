# Standard library imports
import os
import torch
import pickle
import hashlib
from pathlib import Path
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
import re
import time
import gc
import requests
import json
from dotenv import load_dotenv

# Related third-party imports
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
# import openai  # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
# from openai import OpenAI  # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ

# Local imports
from src.text.model import LanguageModel

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


class APIModelHandler:
    """
    API ê¸°ë°˜ ëª¨ë¸ í•¸ë“¤ëŸ¬
    Hugging Face API, ChatGPT API, Azure APIë¥¼ í†µí•© ê´€ë¦¬
    """
    
    def __init__(self):
        """API í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”"""
        # .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
        self.hf_token = os.getenv("HUGGINGFACE_TOKEN")
        # self.openai_key = os.getenv("OPENAI_API_KEY")  # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
        self.azure_key = os.getenv("AZURE_OPENAI_API_KEY")
        self.azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        
        # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        # if self.openai_key:
        #     self.openai_client = OpenAI(api_key=self.openai_key)
        # else:
        #     self.openai_client = None
            
        if self.azure_key and self.azure_endpoint:
            self.azure_client = OpenAI(
                api_key=self.azure_key,
                base_url=self.azure_endpoint
            )
        else:
            self.azure_client = None
    
    async def generate_with_api(
        self, 
        messages: List[Dict[str, str]], 
        api_type: str = "openai",
        model_name: str = "gpt-4.1-nano"
    ) -> str:
        """
        APIë¥¼ í†µí•´ í…ìŠ¤íŠ¸ ìƒì„±
        
        Parameters
        ----------
        messages : List[Dict[str, str]]
            ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        api_type : str
            API íƒ€ì… (openai, azure, huggingface)
        model_name : str
            ëª¨ë¸ ì´ë¦„
            
        Returns
        -------
        str
            ìƒì„±ëœ í…ìŠ¤íŠ¸
        """
        try:
            if api_type == "openai" and self.openai_client:
                response = self.openai_client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    temperature=0.3,
                    max_tokens=2000
                )
                return response.choices[0].message.content
                
            elif api_type == "azure" and self.azure_client:
                response = self.azure_client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    temperature=0.3,
                    max_tokens=2000
                )
                return response.choices[0].message.content
                
            elif api_type == "huggingface" and self.hf_token:
                # Hugging Face Inference API ì‚¬ìš©
                api_url = f"https://api-inference.huggingface.co/models/{model_name}"
                headers = {"Authorization": f"Bearer {self.hf_token}"}
                
                # ë©”ì‹œì§€ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                text = self._messages_to_text(messages)
                
                response = requests.post(
                    api_url,
                    headers=headers,
                    json={"inputs": text, "parameters": {"max_new_tokens": 2000}}
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if isinstance(result, list) and len(result) > 0:
                        return result[0].get("generated_text", "")
                    return str(result)
                else:
                    raise Exception(f"Hugging Face API ì˜¤ë¥˜: {response.status_code}")
            
            else:
                raise Exception(f"ì‚¬ìš© ê°€ëŠ¥í•œ APIê°€ ì—†ìŠµë‹ˆë‹¤: {api_type}")
                
        except Exception as e:
            print(f"API í˜¸ì¶œ ì‹¤íŒ¨ ({api_type}): {e}")
            return "API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    def _messages_to_text(self, messages: List[Dict[str, str]]) -> str:
        """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        text = None
        for message in messages:
            role = message.get("role", "")
            content = message.get("content", "")
            if role == "system":
                text += f"ì‹œìŠ¤í…œ: {content}\n"
            elif role == "user":
                text += f"ì‚¬ìš©ì: {content}\n"
            elif role == "assistant":
                text += f"ì–´ì‹œìŠ¤í„´íŠ¸: {content}\n"
        return text
    
    def text_get_available_apis(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ API ëª©ë¡ ë°˜í™˜"""
        available = []
        # if self.openai_key:
        #     available.append("openai")
        if self.azure_key and self.azure_endpoint:
            available.append("azure")
        if self.hf_token:
            available.append("huggingface")
        return available


class ModelCache:
    """
    ëª¨ë¸ ìºì‹± ì‹œìŠ¤í…œ
    ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ëª¨ë¸ ë¡œë”©ê³¼ ìºì‹±ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, cache_dir: str = "/app/.cache/models"):
        """
        ëª¨ë¸ ìºì‹œ ì´ˆê¸°í™”
        
        Parameters
        ----------
        cache_dir : str
            ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.loaded_models = {}
        self.model_metadata = {}
        
        # ìºì‹œ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self._load_metadata()
    
    def _load_metadata(self):
        """ìºì‹œ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        metadata_file = self.cache_dir / "metadata.pkl"
        if metadata_file.exists():
            try:
                with open(metadata_file, 'rb') as f:
                    self.model_metadata = pickle.load(f)
            except Exception as e:
                print(f"ìºì‹œ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.model_metadata = {}
    
    def _save_metadata(self):
        """ìºì‹œ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        metadata_file = self.cache_dir / "metadata.pkl"
        try:
            with open(metadata_file, 'wb') as f:
                pickle.dump(self.model_metadata, f)
        except Exception as e:
            print(f"ìºì‹œ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _get_model_hash(self, model_name: str, model_type: str) -> str:
        """ëª¨ë¸ì˜ í•´ì‹œê°’ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        content = f"{model_name}_{model_type}_{torch.__version__}"
        return hashlib.md5(content.encode("utf-8")).hexdigest()
    
    def text_get_cached_model(self, model_name: str, model_type: str):
        """ìºì‹œëœ ëª¨ë¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        model_hash = self._get_model_hash(model_name, model_type)
        cache_key = f"{model_name}_{model_type}"
        
        # ë©”ëª¨ë¦¬ì— ë¡œë“œëœ ëª¨ë¸ í™•ì¸
        if cache_key in self.loaded_models:
            return self.loaded_models[cache_key]
        
        # ë””ìŠ¤í¬ ìºì‹œ í™•ì¸
        cache_file = self.cache_dir / f"{model_hash}.pkl"
        if cache_file.exists():
            try:
                print(f"ìºì‹œì—ì„œ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
                with open(cache_file, 'rb') as f:
                    model_data = pickle.load(f)
                
                # ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ
                self.loaded_models[cache_key] = model_data
                return model_data
            except Exception as e:
                print(f"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return None
    
    def text_cache_model(self, model_name: str, model_type: str, model_data: Any):
        """ëª¨ë¸ì„ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
        model_hash = self._get_model_hash(model_name, model_type)
        cache_key = f"{model_name}_{model_type}"
        
        # ë©”ëª¨ë¦¬ì— ì €ì¥
        self.loaded_models[cache_key] = model_data
        
        # ë””ìŠ¤í¬ì— ì €ì¥
        cache_file = self.cache_dir / f"{model_hash}.pkl"
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(model_data, f)
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            self.model_metadata[cache_key] = {
                'hash': model_hash,
                'timestamp': time.time(),
                'size': cache_file.stat().st_size
            }
            self._save_metadata()
            
            print(f"ëª¨ë¸ ìºì‹œ ì €ì¥ ì™„ë£Œ: {model_name}")
        except Exception as e:
            print(f"ëª¨ë¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def text_unload_model(self, model_name: str, model_type: str):
        """ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì—ì„œ í•´ì œí•©ë‹ˆë‹¤."""
        cache_key = f"{model_name}_{model_type}"
        if cache_key in self.loaded_models:
            del self.loaded_models[cache_key]
            gc.collect()  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
            print(f"ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ: {model_name}")
    
    def text_cleanup_old_cache(self, max_age_days: int = 30):
        """ì˜¤ë˜ëœ ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
        current_time = time.time()
        max_age_seconds = max_age_days * 24 * 3600
        
        for cache_key, metadata in list(self.model_metadata.items()):
            if current_time - metadata['timestamp'] > max_age_seconds:
                cache_file = self.cache_dir / f"{metadata['hash']}.pkl"
                if cache_file.exists():
                    cache_file.unlink()
                del self.model_metadata[cache_key]
        
        self._save_metadata()
        print(f"ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬ ì™„ë£Œ (ìµœëŒ€ {max_age_days}ì¼)")


@dataclass
class KoreanModelConfig:
    """í•œêµ­ì–´ ëª¨ë¸ ì„¤ì • (API ìš°ì„ )"""
    api_type: str = "openai"  # "openai", "azure", "huggingface"
    model_name: str = "gpt-4.1-nano"
    temperature: float = 0.3
    max_tokens: int = 2000


class KoreanLanguageModel(LanguageModel):
    """
    API ê¸°ë°˜ í•œêµ­ì–´ ì–¸ì–´ ëª¨ë¸
    
    OpenAI, Azure, Hugging Face APIë¥¼ í†µí•´ ë¯¼ì› ë¶„ì„, ë¶„ë¥˜, ì§ˆì˜ì‘ë‹µ, ìš”ì•½ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, config: KoreanModelConfig):
        super().__init__(config.__dict__)
        self.config = config
        self.api_handler = APIModelHandler()
        
        print(f"API ê¸°ë°˜ í•œêµ­ì–´ ëª¨ë¸ ì´ˆê¸°í™”: {config.api_type}")
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ API: {self.api_handler.text_get_available_apis()}")
        
    async def generate(
        self,
        messages: List[Dict[str, str]],
        max_new_tokens: int | None = None,
        **kwargs
    ) -> str:
        """
        APIë¥¼ í†µí•´ í…ìŠ¤íŠ¸ ìƒì„±
        
        Parameters
        ----------
        messages : List[Dict[str, str]]
            ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        max_new_tokens : int | None
            ìµœëŒ€ ìƒì„± í† í° ìˆ˜ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, configì—ì„œ ê´€ë¦¬)
        **kwargs
            ì¶”ê°€ í‚¤ì›Œë“œ ì¸ì
            
        Returns
        -------
        str
            ìƒì„±ëœ í…ìŠ¤íŠ¸
        """
        try:
            # API íƒ€ì… ìš°ì„ ìˆœìœ„ ê²°ì •
            available_apis = self.api_handler.text_get_available_apis()
            
            if self.config.api_type in available_apis:
                api_type = self.config.api_type
            elif "openai" in available_apis:
                api_type = "openai"
            elif "azure" in available_apis:
                api_type = "azure"
            elif "huggingface" in available_apis:
                api_type = "huggingface"
            else:
                return "ì‚¬ìš© ê°€ëŠ¥í•œ APIê°€ ì—†ìŠµë‹ˆë‹¤."
            
            return await self.api_handler.generate_with_api(
                messages=messages,
                api_type=api_type,
                model_name=self.config.model_name
            )
            
        except Exception as e:
            print(f"API ê¸°ë°˜ í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return "í…ìŠ¤íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    def text_unload(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (API ê¸°ë°˜ì´ë¯€ë¡œ ë³„ë„ ì •ë¦¬ ë¶ˆí•„ìš”)"""
        print("API ê¸°ë°˜ ëª¨ë¸ ì–¸ë¡œë“œ ì™„ë£Œ")


class KoreanModelManager:
    """API ê¸°ë°˜ í•œêµ­ì–´ ëª¨ë¸ ê´€ë¦¬ì"""
    
    def __init__(self, config_path: str):
        self.config_path = config_path
        self.models = {}
        
    def text_load_model(self, model_id: str, config: KoreanModelConfig) -> KoreanLanguageModel:
        """ëª¨ë¸ ë¡œë“œ"""
        if model_id not in self.models:
            self.models[model_id] = KoreanLanguageModel(config)
        return self.models[model_id]
    
    def text_get_model(self, model_id: str) -> Optional[KoreanLanguageModel]:
        """ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°"""
        return self.models.get(model_id)
    
    def text_unload_model(self, model_id: str):
        """ëª¨ë¸ ì–¸ë¡œë“œ"""
        if model_id in self.models:
            self.models[model_id].text_unload()
            del self.models[model_id]
    
    def text_unload_all(self):
        """ëª¨ë“  ëª¨ë¸ ì–¸ë¡œë“œ"""
        for model_id in list(self.models.keys()):
            self.text_unload_model(model_id) 


class LanguageDetector:
    """
    ìë™ ì–¸ì–´ ê°ì§€ í´ë˜ìŠ¤ (API ê¸°ë°˜)
    í•œêµ­ì–´ì™€ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ êµ¬ë¶„í•˜ì—¬ ì ì ˆí•œ ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """
        ì–¸ì–´ ê°ì§€ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        try:
            # ë‹¤êµ­ì–´ ì–¸ì–´ ê°ì§€ ëª¨ë¸ ë¡œë“œ (ê°€ë²¼ìš´ ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©)
            # Transformers 4.44.0 í˜¸í™˜ì„±ì„ ìœ„í•œ ì„¤ì •
            self.language_detector = pipeline(
                "text-classification",
                model="papluca/xlm-roberta-base-language-detection",
                device=0 if torch.cuda.is_available() else -1
            )
            print("âœ… ì–¸ì–´ ê°ì§€ ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ì–¸ì–´ ê°ì§€ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ”„ ì–¸ì–´ ê°ì§€ ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.")
            self.language_detector = None

    def text_detect_language(self, text: str) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
        
        Parameters
        ----------
        text : str
            ê°ì§€í•  í…ìŠ¤íŠ¸
            
        Returns
        -------
        Dict[str, Any]
            ì–¸ì–´ ê°ì§€ ê²°ê³¼
        """
        if not self.language_detector:
            return {"language": "ko", "confidence": 1.0, "is_korean": True}
        
        try:
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            cleaned_text = self._clean_text(text)
            if len(cleaned_text) < 10:
                return {"language": "ko", "confidence": 1.0, "is_korean": True}
            
            # ì–¸ì–´ ê°ì§€
            result = self.language_detector(cleaned_text[:512])  # ìµœëŒ€ 512ìë§Œ ì‚¬ìš©
            
            detected_lang = result[0]['label'].lower()
            confidence = result[0]['score']
            
            # í•œêµ­ì–´ ì—¬ë¶€ í™•ì¸
            is_korean = detected_lang in ['ko', 'korean', 'ko-kr']
            
            return {
                "language": detected_lang,
                "confidence": confidence,
                "is_korean": is_korean
            }
            
        except Exception as e:
            print(f"ì–¸ì–´ ê°ì§€ ì˜¤ë¥˜: {e}")
            return {"language": "ko", "confidence": 1.0, "is_korean": True}

    def _clean_text(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì •ì œí•©ë‹ˆë‹¤.
        
        Parameters
        ----------
        text : str
            ì •ì œí•  í…ìŠ¤íŠ¸
            
        Returns
        -------
        str
            ì •ì œëœ í…ìŠ¤íŠ¸
        """
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def text_is_korean_audio(self, text: str, threshold: float = 0.7) -> bool:
        """
        ì˜¤ë””ì˜¤ê°€ í•œêµ­ì–´ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        Parameters
        ----------
        text : str
            í™•ì¸í•  í…ìŠ¤íŠ¸
        threshold : float
            í•œêµ­ì–´ íŒì • ì„ê³„ê°’
            
        Returns
        -------
        bool
            í•œêµ­ì–´ ì—¬ë¶€
        """
        result = self.text_detect_language(text)
        return result["is_korean"] and result["confidence"] >= threshold


class KoreanModels:
    """
    API ê¸°ë°˜ í•œêµ­ì–´ ëª¨ë¸ë“¤ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    """

    def __init__(self, device: str = "cuda"):
        """
        í•œêµ­ì–´ ëª¨ë¸ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Parameters
        ----------
        device : str
            ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (cuda/cpu) - API ê¸°ë°˜ì´ë¯€ë¡œ ì‹¤ì œë¡œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        """
        self.device = device
        self.language_detector = LanguageDetector()
        self.api_handler = APIModelHandler()
        
        # API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        available_apis = self.api_handler.text_get_available_apis()
        print(f"ğŸ”§ API ê¸°ë°˜ í•œêµ­ì–´ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“¡ ì‚¬ìš© ê°€ëŠ¥í•œ API: {available_apis}")
        
        if not available_apis:
            print("âš ï¸ ê²½ê³ : ì‚¬ìš© ê°€ëŠ¥í•œ APIê°€ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    async def analyze_sentiment_with_api(self, text: str) -> str:
        """
        APIë¥¼ í†µí•´ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Parameters
        ----------
        text : str
            ë¶„ì„í•  í…ìŠ¤íŠ¸

        Returns
        -------
        str
            ê°ì • ë¶„ì„ ê²°ê³¼ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)
        """
        try:
            messages = [
                {
                    "role": "system", 
                    "content": """ë‹¹ì‹ ì€ í†µì‹ ì‚¬ ê³ ê° ìƒë‹´ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê³ ê°ê³¼ ìƒë‹´ì›ì˜ ë°œí™”ì—ì„œ ê°ì •ì„ ì •í™•íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¶„ì„ ê¸°ì¤€:
- ê¸ì •: ë§Œì¡±, ê°ì‚¬, ê¸°ì¨, í˜¸ì˜ì  í‘œí˜„
- ë¶€ì •: ë¶ˆë§Œ, í™”ë‚¨, ì‹¤ë§, ë¹„íŒì  í‘œí˜„  
- ì¤‘ë¦½: ë‹¨ìˆœ ë¬¸ì˜, ì‚¬ì‹¤ ì „ë‹¬, ê°ì • í‘œí˜„ ì—†ìŒ

íŠ¹ë³„ ê³ ë ¤ì‚¬í•­:
- í†µì‹ ì‚¬ ì—…ë¬´ íŠ¹ì„± ë°˜ì˜
- í•œêµ­ì–´ ì¡´ëŒ“ë§/ë°˜ë§ ë‰˜ì•™ìŠ¤
- ìƒí™©ì  ë§¥ë½ ê³ ë ¤

ë°˜ë“œì‹œ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë§Œ ë‹µë³€í•˜ì„¸ìš”."""
                },
                {"role": "user", "content": f"ë‹¤ìŒ í†µì‹ ì‚¬ ìƒë‹´ ë°œí™”ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: {text}"}
            ]
            
            response = await self.api_handler.generate_with_api(
                messages=messages,
                api_type="openai",
                model_name="gpt-4.1-nano"
            )
            
            # ì‘ë‹µì—ì„œ ê°ì • ì¶”ì¶œ (ë” ì •í™•í•œ ë§¤ì¹­)
            response_lower = response.lower()
            if any(word in response for word in ["ê¸ì •", "positive", "ë§Œì¡±", "ì¢‹"]):
                return "ê¸ì •"
            elif any(word in response for word in ["ë¶€ì •", "negative", "ë¶ˆë§Œ", "í™”", "ì‹«"]):
                return "ë¶€ì •"
            else:
                return "ì¤‘ë¦½"
                
        except Exception as e:
            print(f"API ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "ì¤‘ë¦½"

    async def analyze_sentiment_batch(self, texts: List[str]) -> List[str]:
        """
        ë°°ì¹˜ë¡œ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Parameters
        ----------
        texts : List[str]
            ë¶„ì„í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns
        -------
        List[str]
            ê°ì • ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        for text in texts:
            result = await self.analyze_sentiment_with_api(text)
            results.append(result)
        return results

    async def detect_profanity_with_api(self, text: str) -> bool:
        """
        APIë¥¼ í†µí•´ ë¹„ì†ì–´ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.

        Parameters
        ----------
        text : str
            ê°ì§€í•  í…ìŠ¤íŠ¸

        Returns
        -------
        bool
            ë¹„ì†ì–´ í¬í•¨ ì—¬ë¶€
        """
        try:
            messages = [
                {
                    "role": "system", 
                    "content": """ë‹¹ì‹ ì€ í†µì‹ ì‚¬ ê³ ê° ìƒë‹´ ì–¸ì–´ í’ˆì§ˆ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ë¶€ì ì ˆí•œ ì–¸ì–´ ì‚¬ìš©ì„ ê°ì§€í•´ì£¼ì„¸ìš”.

ê°ì§€ ëŒ€ìƒ:
1. ì§ì ‘ì ì¸ ìš•ì„¤ ë° ë¹„ì†ì–´
2. ëª¨ìš•ì ì´ê±°ë‚˜ ê³µê²©ì ì¸ í‘œí˜„
3. ì°¨ë³„ì  ì–¸ì–´
4. ìœ„í˜‘ì  í‘œí˜„
5. ì„±ì  ë˜ëŠ” í˜ì˜¤ í‘œí˜„

ì œì™¸ ì‚¬í•­:
- ì •ë‹¹í•œ ë¶ˆë§Œ í‘œí˜„
- ê°ì •ì ì´ì§€ë§Œ ì ì ˆí•œ í‘œí˜„
- ì—…ë¬´ìƒ í•„ìš”í•œ ê°•í•œ ì–´ì¡°

ë°˜ë“œì‹œ 'ì˜ˆ' ë˜ëŠ” 'ì•„ë‹ˆì˜¤'ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."""
                },
                {"role": "user", "content": f"ë‹¤ìŒ í†µì‹ ì‚¬ ìƒë‹´ ë°œí™”ì— ë¶€ì ì ˆí•œ ì–¸ì–´ê°€ í¬í•¨ë˜ì–´ ìˆë‚˜ìš”: {text}"}
            ]
            
            response = await self.api_handler.generate_with_api(
                messages=messages,
                api_type="openai",
                model_name="gpt-4.1-nano"
            )
            
            # ë” ì •í™•í•œ íŒë‹¨ ë¡œì§
            response_clean = response.strip().lower()
            return any(word in response_clean for word in ["ì˜ˆ", "yes", "í¬í•¨", "ìˆìŠµë‹ˆë‹¤", "ë°œê²¬"])
                
        except Exception as e:
            print(f"API ë¹„ì†ì–´ ê°ì§€ ì˜¤ë¥˜: {e}")
            return False

    async def detect_profanity_batch(self, texts: List[str]) -> List[bool]:
        """
        ë°°ì¹˜ë¡œ ë¹„ì†ì–´ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.

        Parameters
        ----------
        texts : List[str]
            ê°ì§€í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns
        -------
        List[bool]
            ë¹„ì†ì–´ í¬í•¨ ì—¬ë¶€ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        for text in texts:
            result = await self.detect_profanity_with_api(text)
            results.append(result)
        return results

    async def classify_speaker_with_api(self, text: str) -> str:
        """
        APIë¥¼ í†µí•´ í™”ì ì—­í• ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.

        Parameters
        ----------
        text : str
            ë¶„ë¥˜í•  í…ìŠ¤íŠ¸

        Returns
        -------
        str
            í™”ì ì—­í•  (ê³ ê°/ìƒë‹´ì›)
        """
        try:
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê³ ê° ìƒë‹´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°œí™”ê°€ 'ê³ ê°'ì¸ì§€ 'ìƒë‹´ì›'ì¸ì§€ ë¶„ë¥˜í•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": f"ë‹¤ìŒ ë°œí™”ì˜ í™”ìë¥¼ ë¶„ë¥˜í•´ì£¼ì„¸ìš”: {text}"}
            ]
            
            response = await self.api_handler.generate_with_api(
                messages=messages,
                api_type="openai",
                model_name="gpt-4.1-nano"
            )
            
            if "ìƒë‹´ì›" in response or "agent" in response.lower():
                return "ìƒë‹´ì›"
            else:
                return "ê³ ê°"
                
        except Exception as e:
            print(f"API í™”ì ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return "ê³ ê°"

    async def classify_speaker_batch(self, texts: List[str]) -> List[str]:
        """
        ë°°ì¹˜ë¡œ í™”ì ì—­í• ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.

        Parameters
        ----------
        texts : List[str]
            ë¶„ë¥˜í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns
        -------
        List[str]
            í™”ì ì—­í•  ë¦¬ìŠ¤íŠ¸ (ê³ ê°/ìƒë‹´ì›)
        """
        results = []
        for text in texts:
            result = await self.classify_speaker_with_api(text)
            results.append(result)
        return results

    def text_is_korean_content(self, text: str) -> bool:
        """
        ì½˜í…ì¸ ê°€ í•œêµ­ì–´ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.

        Parameters
        ----------
        text : str
            í™•ì¸í•  í…ìŠ¤íŠ¸

        Returns
        -------
        bool
            í•œêµ­ì–´ ì—¬ë¶€
        """
        return self.language_detector.text_is_korean_audio(text)

    def text_get_model_status(self) -> Dict[str, Any]:
        """
        ëª¨ë¸ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns
        -------
        Dict[str, Any]
            ëª¨ë¸ ìƒíƒœ ì •ë³´
        """
        return {
            "api_available": bool(self.api_handler.text_get_available_apis()),
            "available_apis": self.api_handler.text_get_available_apis(),
            "language_detector": self.language_detector.language_detector is not None
        } 