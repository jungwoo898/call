#!/usr/bin/env python3
"""
LLM ê¸°ë°˜ ì •ì„± í‰ê°€ ì§€í‘œ ê°„ë‹¨ í…ŒìŠ¤íŠ¸
ì˜ì¡´ì„± ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸
"""

import sys
import os
import asyncio
from typing import Dict, List, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.abspath('.'))

# í…ŒìŠ¤íŠ¸ìš© Mock LLMHandler í´ëž˜ìŠ¤
class MockLLMHandler:
    """í…ŒìŠ¤íŠ¸ìš© LLM í•¸ë“¤ëŸ¬ Mock"""
    
    def __init__(self):
        self.client = self
        
    async def chat_completions_create(self, **kwargs):
        """Mock API í˜¸ì¶œ"""
        messages = kwargs.get('messages', [])
        user_content = ""
        
        # ì‚¬ìš©ìž ë©”ì‹œì§€ì—ì„œ ëŒ€í™” ë‚´ìš© ì¶”ì¶œ
        for msg in messages:
            if msg.get('role') == 'user':
                user_content = msg.get('content', '')
                break
        
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        if "ìš”ê¸ˆ" in user_content and "í™•ì¸" in user_content and "ë°ì´í„°" in user_content:
            # ì²« ë²ˆì§¸ ì œì•ˆìœ¼ë¡œ í•´ê²°ëœ ì¼€ì´ìŠ¤
            response_text = "1.0"
        elif "ì¸í„°ë„·" in user_content and "ëª¨ëŽ€" in user_content:
            # ë‘ ë²ˆì§¸ ì œì•ˆìœ¼ë¡œ í•´ê²°ëœ ì¼€ì´ìŠ¤  
            response_text = "0.6"
        elif "ë³µìž¡" in user_content or "ì—¬ëŸ¬" in user_content:
            # ì—¬ëŸ¬ ë²ˆ ì œì•ˆí•œ ì¼€ì´ìŠ¤
            response_text = "0.2"
        else:
            # í•´ê²°ë˜ì§€ ì•Šì€ ì¼€ì´ìŠ¤
            response_text = "0.0"
        
        # Mock ì‘ë‹µ ê°ì²´
        class MockChoice:
            def __init__(self, text):
                self.message = type('obj', (object,), {'content': text})()
        
        class MockResponse:
            def __init__(self, text):
                self.choices = [MockChoice(text)]
        
        return MockResponse(response_text)
    
    # chat.completions.createì˜ ë³„ì¹­
    class ChatCompletions:
        def __init__(self, handler):
            self.handler = handler
            
        async def create(self, **kwargs):
            return await self.handler.chat_completions_create(**kwargs)
    
    @property
    def chat(self):
        class Chat:
            def __init__(self, handler):
                self.completions = MockLLMHandler.ChatCompletions(handler)
        return Chat(self)


# í…ŒìŠ¤íŠ¸ìš© CommunicationQualityAnalyzer
class TestCommunicationQualityAnalyzer:
    """í…ŒìŠ¤íŠ¸ìš© ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.llm_handler = MockLLMHandler()
        print("âœ… Mock LLM í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def _calculate_suggestions_score(self, utterances_data: List[Dict[str, Any]]) -> Optional[float]:
        """ë¬¸ì œ í•´ê²° ì œì•ˆ ì ìˆ˜ ê³„ì‚° (í…ŒìŠ¤íŠ¸ ë²„ì „)"""
        try:
            # ëŒ€í™”ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            conversation_text = ""
            for utterance in utterances_data:
                speaker = utterance.get('speaker', 'Unknown')
                text = utterance.get('text', '').strip()
                if text:
                    conversation_text += f"{speaker}: {text}\n"
            
            if not conversation_text.strip():
                return None
            
            # Mock API í˜¸ì¶œ
            response = await self.llm_handler.chat.completions.create(
                model="gpt-4.1-nano",
                messages=[
                    {"role": "system", "content": "ë¬¸ì œ í•´ê²° ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì„¸ìš”."},
                    {"role": "user", "content": f"ëŒ€í™” ë¶„ì„:\n\n{conversation_text}"}
                ],
                temperature=0.1,
                max_tokens=50
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # ì ìˆ˜ ì¶”ì¶œ
            if "1.0" in response_text:
                return 1.0
            elif "0.6" in response_text:
                return 0.6
            elif "0.2" in response_text:
                return 0.2
            elif "0.0" in response_text:
                return 0.0
            else:
                return None
                
        except Exception as e:
            print(f"âš ï¸ ë¬¸ì œ í•´ê²° ì œì•ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return None
    
    def _calculate_interruption_count(self, utterances_data: List[Dict[str, Any]]) -> Optional[int]:
        """ëŒ€í™” ê°€ë¡œì±„ê¸° íšŸìˆ˜ ê³„ì‚°"""
        try:
            if len(utterances_data) < 2:
                return 0
            
            interruption_count = 0
            
            # ë°œí™” ìˆœì„œëŒ€ë¡œ ì •ë ¬
            sorted_utterances = sorted(utterances_data, key=lambda x: x.get('start_time', 0))
            
            # ì—°ì†ëœ ë°œí™” ìŒì„ ê²€ì‚¬
            for i in range(1, len(sorted_utterances)):
                prev_utterance = sorted_utterances[i-1]
                curr_utterance = sorted_utterances[i]
                
                prev_speaker = prev_utterance.get('speaker', '').lower()
                curr_speaker = curr_utterance.get('speaker', '').lower()
                
                prev_end_time = prev_utterance.get('end_time')
                curr_start_time = curr_utterance.get('start_time')
                
                # ì‹œê°„ ì •ë³´ê°€ ìžˆëŠ” ê²½ìš°ë§Œ ê²€ì‚¬
                if prev_end_time is not None and curr_start_time is not None:
                    # ì´ì „ ë°œí™”ê°€ ê³ ê°, í˜„ìž¬ ë°œí™”ê°€ ìƒë‹´ì‚¬ì¸ ê²½ìš°
                    if (any(keyword in prev_speaker for keyword in ['ê³ ê°', 'customer', 'client', 'user']) and
                        any(keyword in curr_speaker for keyword in ['ìƒë‹´ì‚¬', 'counselor', 'agent', 'csr', 'staff'])):
                        
                        # ìƒë‹´ì‚¬ ë°œí™” ì‹œìž‘ ì‹œê°„ < ê³ ê° ë°œí™” ì¢…ë£Œ ì‹œê°„ â†’ ê°€ë¡œì±„ê¸°
                        if curr_start_time < prev_end_time:
                            interruption_count += 1
                            print(f"ðŸ” ê°€ë¡œì±„ê¸° ê°ì§€: ìƒë‹´ì‚¬ê°€ {prev_end_time - curr_start_time:.2f}ì´ˆ ì¼ì° ë°œí™” ì‹œìž‘")
            
            return interruption_count
            
        except Exception as e:
            print(f"âš ï¸ ëŒ€í™” ê°€ë¡œì±„ê¸° íšŸìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return None


async def test_llm_qualitative_metrics():
    """LLM ê¸°ë°˜ ì •ì„± í‰ê°€ ì§€í‘œ í…ŒìŠ¤íŠ¸"""
    
    print("=" * 60)
    print("ðŸ¤– LLM ê¸°ë°˜ ì •ì„± í‰ê°€ ì§€í‘œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ë¶„ì„ê¸° ìƒì„±
    analyzer = TestCommunicationQualityAnalyzer()
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 1: ì²« ë²ˆì§¸ ì œì•ˆìœ¼ë¡œ ë¬¸ì œ í•´ê²°
    print("\nðŸ“‹ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 1: ì²« ë²ˆì§¸ ì œì•ˆìœ¼ë¡œ ë¬¸ì œ í•´ê²°")
    scenario1_data = [
        {"speaker": "ê³ ê°", "text": "ì•ˆë…•í•˜ì„¸ìš”. ìš”ê¸ˆ ê´€ë ¨í•´ì„œ ë¬¸ì˜ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤.", 
         "start_time": 0.0, "end_time": 3.0},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì•ˆë…•í•˜ì„¸ìš”. ê³ ê°ë‹˜. ìš”ê¸ˆ ê´€ë ¨ ë¬¸ì˜ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.", 
         "start_time": 4.0, "end_time": 7.0},
        {"speaker": "ê³ ê°", "text": "ì´ë²ˆ ë‹¬ ìš”ê¸ˆì´ ë„ˆë¬´ ë§Žì´ ë‚˜ì™”ì–´ìš”.", 
         "start_time": 8.0, "end_time": 11.0},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ìš”ê¸ˆ ë‚´ì—­ì„ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë°ì´í„° ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•´ë³´ë‹ˆ ë§Žì´ ì‚¬ìš©í•˜ì…¨ë„¤ìš”.", 
         "start_time": 12.0, "end_time": 17.0},
        {"speaker": "ê³ ê°", "text": "ì•„ ê·¸ë ‡êµ°ìš”. ê°ì‚¬í•©ë‹ˆë‹¤.", 
         "start_time": 18.0, "end_time": 20.0}
    ]
    
    suggestions1 = await analyzer._calculate_suggestions_score(scenario1_data)
    interruptions1 = analyzer._calculate_interruption_count(scenario1_data)
    
    print(f"  ðŸ“Š ë¬¸ì œ í•´ê²° ì œì•ˆ ì ìˆ˜: {suggestions1}")
    print(f"  ðŸ“Š ëŒ€í™” ê°€ë¡œì±„ê¸° íšŸìˆ˜: {interruptions1}íšŒ")
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 2: ê°€ë¡œì±„ê¸°ê°€ ìžˆëŠ” ìƒë‹´
    print("\nðŸ“‹ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 2: ê°€ë¡œì±„ê¸°ê°€ ìžˆëŠ” ìƒë‹´")
    scenario2_data = [
        {"speaker": "ê³ ê°", "text": "ì•ˆë…•í•˜ì„¸ìš”. ì¸í„°ë„·ì´ ìžê¾¸ ëŠì–´ì ¸ì„œ...", 
         "start_time": 0.0, "end_time": 4.0},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ë„¤, ì¸í„°ë„· ë¬¸ì œì‹œì£ .", 
         "start_time": 3.5, "end_time": 5.0},  # ê°€ë¡œì±„ê¸° ë°œìƒ
        {"speaker": "ê³ ê°", "text": "ë„¤, ë§žìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?", 
         "start_time": 6.0, "end_time": 9.0},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ìš°ì„  ëª¨ëŽ€ì„ ìž¬ë¶€íŒ…í•´ë³´ì„¸ìš”.", 
         "start_time": 8.5, "end_time": 11.0},  # ê°€ë¡œì±„ê¸° ë°œìƒ
        {"speaker": "ê³ ê°", "text": "ì•Œê² ìŠµë‹ˆë‹¤.", 
         "start_time": 12.0, "end_time": 13.0}
    ]
    
    suggestions2 = await analyzer._calculate_suggestions_score(scenario2_data)
    interruptions2 = analyzer._calculate_interruption_count(scenario2_data)
    
    print(f"  ðŸ“Š ë¬¸ì œ í•´ê²° ì œì•ˆ ì ìˆ˜: {suggestions2}")
    print(f"  ðŸ“Š ëŒ€í™” ê°€ë¡œì±„ê¸° íšŸìˆ˜: {interruptions2}íšŒ")
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 3: ë³µìž¡í•œ ë¬¸ì œ í•´ê²° ê³¼ì •
    print("\nðŸ“‹ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 3: ë³µìž¡í•œ ë¬¸ì œ í•´ê²° ê³¼ì •")
    scenario3_data = [
        {"speaker": "ê³ ê°", "text": "ë³µìž¡í•œ ë¬¸ì œê°€ ìžˆì–´ì„œ ì—¬ëŸ¬ ê°€ì§€ ì‹œë„ë¥¼ í•´ë´¤ëŠ”ë° ì•ˆ ë©ë‹ˆë‹¤.", 
         "start_time": 0.0, "end_time": 4.0},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì²« ë²ˆì§¸ ë°©ë²•ì„ ì‹œë„í•´ë³´ì„¸ìš”.", 
         "start_time": 5.0, "end_time": 7.0},
        {"speaker": "ê³ ê°", "text": "ê·¸ê²ƒë„ ì•ˆ ë˜ë„¤ìš”.", 
         "start_time": 8.0, "end_time": 10.0},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ê·¸ëŸ¼ ë‘ ë²ˆì§¸ ë°©ë²•ìœ¼ë¡œ í•´ë³´ê² ìŠµë‹ˆë‹¤.", 
         "start_time": 11.0, "end_time": 13.0},
        {"speaker": "ê³ ê°", "text": "ì´ê²ƒë„ ì•ˆ ë©ë‹ˆë‹¤.", 
         "start_time": 14.0, "end_time": 16.0},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ë§ˆì§€ë§‰ìœ¼ë¡œ ì„¸ ë²ˆì§¸ ë°©ë²•ì„ ì‹œë„í•´ë³´ì„¸ìš”.", 
         "start_time": 17.0, "end_time": 20.0}
    ]
    
    suggestions3 = await analyzer._calculate_suggestions_score(scenario3_data)
    interruptions3 = analyzer._calculate_interruption_count(scenario3_data)
    
    print(f"  ðŸ“Š ë¬¸ì œ í•´ê²° ì œì•ˆ ì ìˆ˜: {suggestions3}")
    print(f"  ðŸ“Š ëŒ€í™” ê°€ë¡œì±„ê¸° íšŸìˆ˜: {interruptions3}íšŒ")
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ðŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print(f"ì‹œë‚˜ë¦¬ì˜¤ 1 - ì²« ë²ˆì§¸ ì œì•ˆ ì„±ê³µ: ì œì•ˆì ìˆ˜={suggestions1}, ê°€ë¡œì±„ê¸°={interruptions1}íšŒ")
    print(f"ì‹œë‚˜ë¦¬ì˜¤ 2 - ê°€ë¡œì±„ê¸° ë°œìƒ: ì œì•ˆì ìˆ˜={suggestions2}, ê°€ë¡œì±„ê¸°={interruptions2}íšŒ")
    print(f"ì‹œë‚˜ë¦¬ì˜¤ 3 - ë³µìž¡í•œ í•´ê²°ê³¼ì •: ì œì•ˆì ìˆ˜={suggestions3}, ê°€ë¡œì±„ê¸°={interruptions3}íšŒ")
    
    # ê²€ì¦
    success_count = 0
    total_tests = 6
    
    if suggestions1 == 1.0:  # ì²« ë²ˆì§¸ ì œì•ˆ ì„±ê³µ
        print("âœ… ì‹œë‚˜ë¦¬ì˜¤ 1 ì œì•ˆ ì ìˆ˜ ì •ìƒ")
        success_count += 1
    else:
        print(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ 1 ì œì•ˆ ì ìˆ˜ ì˜¤ë¥˜: ì˜ˆìƒ=1.0, ì‹¤ì œ={suggestions1}")
    
    if interruptions1 == 0:  # ê°€ë¡œì±„ê¸° ì—†ìŒ
        print("âœ… ì‹œë‚˜ë¦¬ì˜¤ 1 ê°€ë¡œì±„ê¸° íšŸìˆ˜ ì •ìƒ")
        success_count += 1
    else:
        print(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ 1 ê°€ë¡œì±„ê¸° íšŸìˆ˜ ì˜¤ë¥˜: ì˜ˆìƒ=0, ì‹¤ì œ={interruptions1}")
    
    if suggestions2 == 0.6:  # ë‘ ë²ˆì§¸ ì œì•ˆìœ¼ë¡œ í•´ê²°
        print("âœ… ì‹œë‚˜ë¦¬ì˜¤ 2 ì œì•ˆ ì ìˆ˜ ì •ìƒ")
        success_count += 1
    else:
        print(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ 2 ì œì•ˆ ì ìˆ˜ ì˜¤ë¥˜: ì˜ˆìƒ=0.6, ì‹¤ì œ={suggestions2}")
    
    if interruptions2 == 2:  # 2ë²ˆ ê°€ë¡œì±„ê¸°
        print("âœ… ì‹œë‚˜ë¦¬ì˜¤ 2 ê°€ë¡œì±„ê¸° íšŸìˆ˜ ì •ìƒ")
        success_count += 1
    else:
        print(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ 2 ê°€ë¡œì±„ê¸° íšŸìˆ˜ ì˜¤ë¥˜: ì˜ˆìƒ=2, ì‹¤ì œ={interruptions2}")
    
    if suggestions3 == 0.2:  # 3ë²ˆ ì´ìƒ ì œì•ˆ
        print("âœ… ì‹œë‚˜ë¦¬ì˜¤ 3 ì œì•ˆ ì ìˆ˜ ì •ìƒ")
        success_count += 1
    else:
        print(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ 3 ì œì•ˆ ì ìˆ˜ ì˜¤ë¥˜: ì˜ˆìƒ=0.2, ì‹¤ì œ={suggestions3}")
    
    if interruptions3 == 0:  # ê°€ë¡œì±„ê¸° ì—†ìŒ
        print("âœ… ì‹œë‚˜ë¦¬ì˜¤ 3 ê°€ë¡œì±„ê¸° íšŸìˆ˜ ì •ìƒ")
        success_count += 1
    else:
        print(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ 3 ê°€ë¡œì±„ê¸° íšŸìˆ˜ ì˜¤ë¥˜: ì˜ˆìƒ=0, ì‹¤ì œ={interruptions3}")
    
    print(f"\nðŸŽ¯ í…ŒìŠ¤íŠ¸ ì„±ê³µë¥ : {success_count}/{total_tests} ({success_count/total_tests*100:.1f}%)")
    
    if success_count == total_tests:
        print("ðŸŽ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        print("ðŸš€ LLM ê¸°ë°˜ ì •ì„± í‰ê°€ ì§€í‘œ í…ŒìŠ¤íŠ¸ ì‹œìž‘")
        
        # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        result = asyncio.run(test_llm_qualitative_metrics())
        
        if result:
            print("\nâœ… ì „ì²´ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return 0
        else:
            print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return 1
            
    except Exception as e:
        print(f"\nðŸ’¥ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main()) 