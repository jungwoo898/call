# Standard library imports
import os
import asyncio
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
import uvicorn
from contextlib import asynccontextmanager

# Related third-party imports
from omegaconf import OmegaConf

# NeMo ì•ˆì „ import
NeuralDiarizer = None
try:
    from nemo.collections.asr.models.msdd_models import NeuralDiarizer
    print("âœ… NeMo NeuralDiarizer imported successfully")
except ImportError as e:
    print(f"âš ï¸ NeMo import failed: {e}")
    print("ğŸ”„ Diarization will run in fallback mode")
except Exception as e:
    print(f"âš ï¸ NeMo error: {e}")
    print("ğŸ”„ Diarization will run in fallback mode")

# Local imports
from src.audio.utils import Formatter
from src.audio.metrics import SilenceStats
from src.audio.error import DialogueDetecting
from src.audio.alignment import ForcedAligner
from src.audio.effect import DemucsVocalSeparator
from src.audio.preprocessing import SpeechEnhancement
from src.audio.io import SpeakerTimestampReader, TranscriptWriter
from src.audio.analysis import WordSpeakerMapper, SentenceSpeakerMapper, Audio
from src.audio.processing import AudioProcessor, Transcriber, PunctuationRestorer
from src.text.utils import Annotator
from src.text.llm import LLMOrchestrator, LLMResultHandler
from src.text.communication_quality_analyzer import CommunicationQualityAnalyzer
from src.utils.utils import Cleaner, Watcher
from src.db.manager import DatabaseManager
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer
from src.text.korean_models import KoreanModels

# FastAPI ì•± ìƒì„±
app = FastAPI(title="Callytics API", version="1.0.0")

# ì „ì—­ ë³€ìˆ˜ë¡œ ì²˜ë¦¬ ìƒíƒœ ê´€ë¦¬
processing_status = {
    "is_processing": False,
    "current_file": None,
    "total_processed": 0,
    "errors": []
}

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    # ì‹œì‘ ì‹œ ì´ˆê¸°í™”
    print("ğŸš€ Callytics API ì„œë²„ ì‹œì‘")
    yield
    # ì¢…ë£Œ ì‹œ ì •ë¦¬
    print("ğŸ›‘ Callytics API ì„œë²„ ì¢…ë£Œ")

app = FastAPI(title="Callytics API", version="1.0.0", lifespan=lifespan)

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # ê¸°ë³¸ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        import torch
        cuda_available = torch.cuda.is_available()
        
        # API í‚¤ í™•ì¸
        api_keys = {
            "openai": bool(os.getenv("OPENAI_API_KEY")),
            "azure": bool(os.getenv("AZURE_OPENAI_API_KEY") and os.getenv("AZURE_OPENAI_ENDPOINT")),
            "huggingface": bool(os.getenv("HUGGINGFACE_TOKEN"))
        }
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
        db_path = os.getenv('DATABASE_URL', '/app/Callytics_new.sqlite')
        if db_path.startswith('sqlite:///'):
            db_path = db_path.replace('sqlite:///', '')
        db_accessible = os.path.exists(db_path)
        
        # ì˜¤ë””ì˜¤ ë””ë ‰í† ë¦¬ í™•ì¸
        audio_dir = "/app/audio"
        audio_accessible = os.path.exists(audio_dir)
        
        status = "healthy" if any(api_keys.values()) and db_accessible else "degraded"
        
        return JSONResponse({
            "status": status,
            "timestamp": asyncio.get_event_loop().time(),
            "cuda_available": cuda_available,
            "api_keys_configured": api_keys,
            "database_accessible": db_accessible,
            "audio_directory_accessible": audio_accessible,
            "processing_status": processing_status
        })
    except Exception as e:
        return JSONResponse({
            "status": "unhealthy",
            "error": str(e)
        }, status_code=500)

@app.get("/metrics")
async def get_metrics():
    """ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸ (Prometheusìš©)"""
    try:
        import psutil
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        
        # GPU ë©”íŠ¸ë¦­ (ê°€ëŠ¥í•œ ê²½ìš°)
        gpu_metrics = {}
        try:
            import torch
            if torch.cuda.is_available():
                gpu_metrics = {
                    "gpu_count": torch.cuda.device_count(),
                    "gpu_memory_allocated": torch.cuda.memory_allocated() / 1024**3,  # GB
                    "gpu_memory_reserved": torch.cuda.memory_reserved() / 1024**3,    # GB
                }
        except:
            pass
        
        return JSONResponse({
            "cpu_percent": cpu_percent,
            "memory_percent": memory.percent,
            "memory_available_gb": memory.available / 1024**3,
            "gpu_metrics": gpu_metrics,
            "processing_status": processing_status
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "Callytics API ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤",
        "version": "1.0.0",
        "endpoints": {
            "health": "/health",
            "metrics": "/metrics",
            "docs": "/docs"
        }
    }

async def main(audio_file_path: str):
    """
    Process an audio file to perform diarization, transcription, punctuation restoration,
    and speaker role classification.

    Parameters
    ----------
    audio_file_path : str
        The path to the input audio file to be processed.

    Returns
    -------
    None
    """
    # Paths - ê³ ìœ í•œ ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    import uuid
    import time
    unique_id = f"{int(time.time())}_{str(uuid.uuid4())[:8]}"
    temp_dir = f"/app/.temp/session_{unique_id}"
    os.makedirs(temp_dir, exist_ok=True)
    
    config_nemo = "config/nemo/diar_infer_telephonic.yaml"
    manifest_path = os.path.join(temp_dir, "manifest.json")
    rttm_file_path = os.path.join(temp_dir, "pred_rttms", "mono_file.rttm")
    transcript_output_path = os.path.join(temp_dir, "output.txt")
    srt_output_path = os.path.join(temp_dir, "output.srt")
    config_path = "config/config.yaml"
    prompt_path = "config/prompt.yaml"
    db_path = os.getenv('DATABASE_URL', '/app/Callytics_new.sqlite')
    if db_path.startswith('sqlite:///'):
        db_path = db_path.replace('sqlite:///', '')
    db_topic_fetch_path = "src/db/sql/TopicFetch.sql"
    db_topic_insert_path = "src/db/sql/TopicInsert.sql"
    db_audio_properties_insert_path = "src/db/sql/AudioPropertiesInsert.sql"
    db_utterance_insert_path = "src/db/sql/UtteranceInsert.sql"

    # Configuration
    config = OmegaConf.load(config_path)
    device = config.runtime.device
    compute_type = config.runtime.compute_type
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = config.runtime.cuda_alloc_conf

    # Step 0: Audio Normalization (FFmpeg ê¸°ë°˜)
    normalized_audio_path = os.path.join(temp_dir, "normalized.wav")
    try:
        import subprocess
        print(f"ğŸ”„ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ê·œí™” ì‹œì‘: {audio_file_path}")
        
        # FFmpegë¡œ ì˜¤ë””ì˜¤ë¥¼ í‘œì¤€ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        cmd = [
            'ffmpeg', '-i', audio_file_path,
            '-acodec', 'pcm_s16le',  # 16ë¹„íŠ¸ PCM
            '-ar', '16000',          # 16kHz ìƒ˜í”Œë§
            '-ac', '1',              # ëª¨ë…¸ ì±„ë„
            '-y', normalized_audio_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… ì˜¤ë””ì˜¤ ì •ê·œí™” ì™„ë£Œ: {normalized_audio_path}")
            # ì •ê·œí™”ëœ íŒŒì¼ì„ ì‚¬ìš©
            audio_file_path = normalized_audio_path
        else:
            print(f"âš ï¸ ì˜¤ë””ì˜¤ ì •ê·œí™” ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {result.stderr}")
            
    except Exception as e:
        print(f"âš ï¸ ì˜¤ë””ì˜¤ ì •ê·œí™” ì˜¤ë¥˜, ì›ë³¸ ì‚¬ìš©: {e}")

    # Initialize Classes
    dialogue_detector = DialogueDetecting(delete_original=True)
    enhancer = SpeechEnhancement(config_path=config_path, output_dir=temp_dir)
    separator = DemucsVocalSeparator()
    processor = AudioProcessor(audio_path=audio_file_path, temp_dir=temp_dir)
    transcriber = Transcriber(device=device, compute_type=compute_type)
    aligner = ForcedAligner(device=device)
    llm_handler = LLMOrchestrator(config_path=config_path, prompt_config_path=prompt_path, model_id="openai")
    llm_result_handler = LLMResultHandler()
    cleaner = Cleaner()
    formatter = Formatter()
    db = DatabaseManager(config_path)
    audio_feature_extractor = Audio(audio_file_path)

    # Step 1: Detect Dialogue
    try:
        print("ğŸ” ëŒ€í™” ê°ì§€ ì‹œì‘...")
        has_dialogue = dialogue_detector.process(audio_file_path)
        print(f"ğŸ” ëŒ€í™” ê°ì§€ ê²°ê³¼: {has_dialogue}")
        if not has_dialogue:
            print("âš ï¸ ëŒ€í™”ê°€ ê°ì§€ë˜ì§€ ì•Šì•„ ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
    except Exception as e:
        print(f"âŒ ëŒ€í™” ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return

    # Step 2: Speech Enhancement
    audio_path = enhancer.enhance_audio(
        input_path=audio_file_path,
        output_path=os.path.join(temp_dir, "enhanced.wav"),
        noise_threshold=0.0001,
        verbose=True
    )

    # Step 3: Vocal Separation
    vocal_path = separator.separate_vocals(audio_file=audio_path, output_dir=temp_dir)

    # Step 4: Transcription
    transcript, info = transcriber.transcribe(audio_path=vocal_path)
    detected_language = info["language"]
    whisper_word_timestamps = info.get("word_timestamps", [])  # faster-whisper word timestamps ì¶”ì¶œ

    # Step 5: Forced Alignment (faster-whisper word_timestamps ìš°ì„  í™œìš©)
    word_timestamps = aligner.align(
        audio_path=vocal_path,
        transcript=transcript,
        language=detected_language,
        whisper_word_timestamps=whisper_word_timestamps  # faster-whisper ê²°ê³¼ ì „ë‹¬
    )

    # Step 6: Diarization
    processor.audio_path = vocal_path
    mono_audio_path = processor.convert_to_mono()
    processor.audio_path = mono_audio_path
    processor.create_manifest(manifest_path)
    
    # NeuralDiarizerë¥¼ ì‚¬ìš©í•œ í™”ì ë¶„ë¦¬ (fallback ëª¨ë“œ ì§€ì›)
    if NeuralDiarizer is None:
        print("Warning: NeuralDiarizer is not available. Using fallback diarization.")
        # ë”ë¯¸ RTTM íŒŒì¼ ìƒì„± (ë‹¨ì¼ í™”ìë¡œ ê°€ì •)
        os.makedirs(os.path.join(temp_dir, "pred_rttms"), exist_ok=True)
        with open(rttm_file_path, 'w') as f:
            duration = processor.get_duration()
            f.write(f"SPEAKER mono_file 1 0.0 {duration} <NA> <NA> SPEAKER_00 <NA> <NA>\n")
        print(f"Created fallback RTTM file: {rttm_file_path}")
    else:
        try:
            cfg = OmegaConf.load(config_nemo)
            cfg.diarizer.manifest_filepath = manifest_path
            cfg.diarizer.out_dir = temp_dir
            msdd_model = NeuralDiarizer(cfg=cfg)
            msdd_model.diarize()
        except Exception as e:
            print(f"Warning: NeuralDiarizer failed: {e}")
            # ë”ë¯¸ RTTM íŒŒì¼ ìƒì„±
            os.makedirs(os.path.join(temp_dir, "pred_rttms"), exist_ok=True)
            with open(rttm_file_path, 'w') as f:
                duration = processor.get_duration()
                f.write(f"SPEAKER mono_file 1 0.0 {duration} <NA> <NA> SPEAKER_00 <NA> <NA>\n")
            print(f"Created fallback RTTM file: {rttm_file_path}")

    # Step 7: Processing Transcript
    # Step 7.1: Speaker Timestamps
    speaker_reader = SpeakerTimestampReader(rttm_path=rttm_file_path)
    speaker_ts = speaker_reader.read_speaker_timestamps()

    # Step 7.2: Mapping Words
    word_speaker_mapper = WordSpeakerMapper(word_timestamps, speaker_ts)
    wsm = word_speaker_mapper.get_words_speaker_mapping()

    # Step 7.3: Punctuation Restoration
    punct_restorer = PunctuationRestorer(language=detected_language)
    wsm = punct_restorer.restore_punctuation(wsm)
    word_speaker_mapper.word_speaker_mapping = wsm
    word_speaker_mapper.realign_with_punctuation()
    wsm = word_speaker_mapper.word_speaker_mapping

    # Step 7.4: Mapping Sentences
    sentence_mapper = SentenceSpeakerMapper()
    ssm = sentence_mapper.get_sentences_speaker_mapping(wsm)

    # Step 7.5: ì–¸ì–´ ê°ì§€ ë° ê²€ì¦
    # API ê¸°ë°˜ í•œêµ­ì–´ ëª¨ë¸ ì´ˆê¸°í™”
    korean_models = KoreanModels(device=device)
    
    # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•©ì³ì„œ ì–¸ì–´ ê°ì§€
    full_text = " ".join([utterance["text"] for utterance in ssm])
    
    if not korean_models.is_korean_content(full_text):
        print("âš ï¸ ê²½ê³ : í•œêµ­ì–´ê°€ ì•„ë‹Œ ì˜¤ë””ì˜¤ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ğŸ“ ê°ì§€ëœ ì–¸ì–´ë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ í•œêµ­ì–´ ì˜¤ë””ì˜¤ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        # í•œêµ­ì–´ê°€ ì•„ë‹Œ ê²½ìš°ì—ë„ ê³„ì† ì§„í–‰í•˜ë˜ ê²½ê³  í‘œì‹œ
        language_warning = True
    else:
        print("âœ… í•œêµ­ì–´ ì˜¤ë””ì˜¤ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        language_warning = False

    # Step 8 (Optional): Write Transcript and SRT Files
    writer = TranscriptWriter()
    writer.write_transcript(ssm, transcript_output_path)
    writer.write_srt(ssm, srt_output_path)
    
    # JSON ëŒ€ë³¸ ì¶œë ¥ ê²½ë¡œ ì„¤ì •
    json_output_path = os.path.join(temp_dir, "transcript.json")
    comprehensive_json_path = os.path.join(temp_dir, "analysis_complete.json")

    # Step 9: Classify Speaker Roles
    speaker_roles = await llm_handler.generate("Classification", ssm)

    # Step 9.1: LLM results validate and fallback
    ssm = llm_result_handler.validate_and_fallback(speaker_roles, ssm)
    llm_result_handler.log_result(ssm, speaker_roles)

    # Step 10: Sentiment Analysis (API ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬)
    ssm_with_indices = formatter.add_indices_to_ssm(ssm)
    annotator = Annotator(ssm_with_indices)
    
    # APIë¥¼ í†µí•´ ë°°ì¹˜ë¡œ ê°ì • ë¶„ì„ ìˆ˜í–‰
    texts_for_sentiment = [utterance["text"] for utterance in ssm]
    sentiment_results = await korean_models.analyze_sentiment_batch(texts_for_sentiment)
    
    # ê²°ê³¼ë¥¼ SSMì— ì ìš©
    for i, utterance in enumerate(ssm):
        utterance["sentiment"] = sentiment_results[i]
    
    # Step 11: Profanity Word Detection (API ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬)
    profanity_results = await korean_models.detect_profanity_batch(texts_for_sentiment)
    
    # ê²°ê³¼ë¥¼ SSMì— ì ìš©
    for i, utterance in enumerate(ssm):
        utterance["profane"] = profanity_results[i]

    # Step 12: Summary
    summary_result = await llm_handler.generate("Summary", user_input=ssm)
    annotator.add_summary(summary_result)

    # Step 13: Conflict Detection
    conflict_result = await llm_handler.generate("ConflictDetection", user_input=ssm)
    annotator.add_conflict(conflict_result)

    # Step 14: Topic Detection
    topics = db.fetch(db_topic_fetch_path)
    topic_result = await llm_handler.generate(
        "TopicDetection",
        user_input=ssm,
        system_input=topics
    )
    annotator.add_topic(topic_result)

    # Step 15: Complaint Analysis
    complaint_result = await llm_handler.generate("ComplaintAnalysis", user_input=ssm)
    annotator.add_complaint(complaint_result)

    # Step 16: Action Items
    action_result = await llm_handler.generate("ActionItems", user_input=ssm)
    annotator.add_action_items(action_result)

    # Step 17: Quality Assessment
    quality_result = await llm_handler.generate("QualityAssessment", user_input=ssm)
    annotator.add_quality_assessment(quality_result)

    # Step 17.5: Communication Quality Analysis (ìƒˆë¡œìš´ LLM ì •ì„± ì§€í‘œ)
    try:
        print("ğŸ“Š ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ ì‹œì‘...")
        quality_analyzer = CommunicationQualityAnalyzer()
        quality_analysis_result = await quality_analyzer.analyze_communication_quality(ssm)
        
        print(f"ğŸ“Š ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ:")
        print(f"   - ë¬¸ì œ í•´ê²° ì œì•ˆ ì ìˆ˜: {quality_analysis_result.suggestions}")
        print(f"   - ëŒ€í™” ê°€ë¡œì±„ê¸° íšŸìˆ˜: {quality_analysis_result.interruption_count}íšŒ")
        print(f"   - ì¡´ëŒ“ë§ ë¹„ìœ¨: {quality_analysis_result.honorific_ratio:.2f}")
        print(f"   - ê¸ì •ì–´ ë¹„ìœ¨: {quality_analysis_result.positive_word_ratio:.2f}")
        
    except Exception as e:
        print(f"âŒ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
        quality_analysis_result = None

    # Step 18: Generate JSON Outputs
    # Step 18.1: Basic JSON transcript with analysis
    writer.write_json(ssm, json_output_path, include_analysis=True)
    
    # Step 18.2: Export complete analysis results
    analysis_json_path = os.path.join(temp_dir, "analysis_results.json")
    annotator.export_to_json(analysis_json_path)
    
    # Step 18.3: Extract Audio Properties
    audio_properties = audio_feature_extractor.extract_properties()
    
    # Step 18.4: Generate comprehensive JSON report
    analysis_summary = annotator.get_analysis_summary()
    writer.write_comprehensive_json(
        ssm, 
        comprehensive_json_path,
        analysis_results=analysis_summary,
        audio_properties=audio_properties
    )

    # Step 19: Database Operations
    # Step 19.1: Insert Audio Properties (ê¸°ì¡´ SQL íŒŒì¼ ì‚¬ìš©)
    try:
        # Audio í´ë˜ìŠ¤ì˜ extract_properties() ë©”ì†Œë“œ ì‚¬ìš©
        audio_properties = audio_feature_extractor.extract_properties()
        
        # properties() ë©”ì†Œë“œë¡œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
        (
            name,
            extension,
            path,
            sample_rate,
            min_freq,
            max_freq,
            bit_depth,
            channels,
            duration,
            rms_loudness,
            final_features
        ) = audio_feature_extractor.properties()
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        summary = "ì˜¤ë””ì˜¤ ë¶„ì„ ì™„ë£Œ"
        conflict_flag = 0
        silence_value = 0.0
        detected_topic = "ì¼ë°˜"
        
        # Topic ID ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’ 1 ì‚¬ìš©)
        topic_id = 1
        
        # AudioPropertiesInsert.sqlì— ë§ëŠ” íŒŒë¼ë¯¸í„° êµ¬ì„± (33ê°œ íŒŒë¼ë¯¸í„° í•„ìš”)
        params = (
            path,           # 1. file_path
            name,           # 2. file_name
            duration,       # 3. duration
            sample_rate,    # 4. sample_rate
            channels,       # 5. channels
            topic_id,       # 6. topic_id
            extension,      # 7. extension
            min_freq,       # 8. min_frequency
            max_freq,       # 9. max_frequency
            bit_depth if bit_depth is not None else 16,  # 10. bit_depth
            rms_loudness,   # 11. rms_loudness
            final_features.get("ZeroCrossingRate", 0.0),  # 12. zero_crossing_rate
            final_features.get("SpectralCentroid", 0.0),  # 13. spectral_centroid
            final_features.get("EQ_20_250_Hz", 0.0),      # 14. eq_20_250_hz
            final_features.get("EQ_250_2000_Hz", 0.0),    # 15. eq_250_2000_hz
            final_features.get("EQ_2000_6000_Hz", 0.0),   # 16. eq_2000_6000_hz
            final_features.get("EQ_6000_20000_Hz", 0.0),  # 17. eq_6000_20000_hz
            final_features.get("MFCC_1", 0.0),            # 18. mfcc_1
            final_features.get("MFCC_2", 0.0),            # 19. mfcc_2
            final_features.get("MFCC_3", 0.0),            # 20. mfcc_3
            final_features.get("MFCC_4", 0.0),            # 21. mfcc_4
            final_features.get("MFCC_5", 0.0),            # 22. mfcc_5
            final_features.get("MFCC_6", 0.0),            # 23. mfcc_6
            final_features.get("MFCC_7", 0.0),            # 24. mfcc_7
            final_features.get("MFCC_8", 0.0),            # 25. mfcc_8
            final_features.get("MFCC_9", 0.0),            # 26. mfcc_9
            final_features.get("MFCC_10", 0.0),           # 27. mfcc_10
            final_features.get("MFCC_11", 0.0),           # 28. mfcc_11
            final_features.get("MFCC_12", 0.0),           # 29. mfcc_12
            final_features.get("MFCC_13", 0.0),           # 30. mfcc_13
            summary,        # 31. summary
            conflict_flag,  # 32. conflict_flag
            silence_value   # 33. silence_value
            # 34. created_atì€ SQLì—ì„œ datetime('now')ë¡œ ìë™ ìƒì„±ë¨
        )
        
        last_id = db.insert(db_audio_properties_insert_path, params)
        print(f"âœ… ì˜¤ë””ì˜¤ ì†ì„± DB ì €ì¥ ì™„ë£Œ: ID {last_id}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ì†ì„± DB ì €ì¥ ì‹¤íŒ¨: {e}")
        last_id = None

    # Step 19.2: Insert Utterances (ê¸°ì¡´ SQL íŒŒì¼ ì‚¬ìš©)
    if last_id is not None:
        try:
            for i, utterance in enumerate(ssm):
                # UtteranceInsert.sqlì— ë§ëŠ” íŒŒë¼ë¯¸í„° êµ¬ì„±
                utterance_params = (
                    last_id,  # audio_properties_id
                    utterance["speaker"],  # speaker
                    utterance["start_time"] / 1000.0,  # start_time (ì´ˆ ë‹¨ìœ„) - í•„ë“œëª… ìˆ˜ì •
                    utterance["end_time"] / 1000.0,  # end_time (ì´ˆ ë‹¨ìœ„) - í•„ë“œëª… ìˆ˜ì •
                    utterance["text"],  # text
                    1.0,  # confidence (ê¸°ë³¸ê°’)
                    i + 1,  # sequence
                    utterance.get("sentiment", "ì¤‘ë¦½"),  # sentiment
                    1 if utterance.get("profane", False) else 0  # profane (0/1)
                )
                db.insert(db_utterance_insert_path, utterance_params)
            
            print(f"âœ… ë°œí™” ë°ì´í„° DB ì €ì¥ ì™„ë£Œ: {len(ssm)}ê°œ ë°œí™”")
            
        except Exception as e:
            print(f"âŒ ë°œí™” ë°ì´í„° DB ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        print("âš ï¸ File IDê°€ ì—†ì–´ ë°œí™” ë°ì´í„° ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    # Step 19.3: Insert Consultation Analysis (LLM ë¶„ì„ ê²°ê³¼ ì €ì¥)
    if last_id is not None:
        try:
            # ë¶„ì„ ê²°ê³¼ì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
            analysis_summary = annotator.get_analysis_summary()
            global_analysis = analysis_summary.get("global_analysis", {})
            
            # êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
            summary_data = global_analysis.get("summary", {})
            conflict_data = global_analysis.get("conflict", {})
            topic_data = global_analysis.get("topic", {})
            complaint_data = global_analysis.get("complaint", {})
            quality_data = global_analysis.get("quality_assessment", {})
            
            # ì£¼ì œ ë¶„ë¥˜ ê²°ê³¼ ì²˜ë¦¬ (ê°œì„ ëœ êµ¬ì¡°)
            if isinstance(topic_data, dict):
                primary_topic = topic_data.get("primary_topic", "ê¸°íƒ€")
                topic_confidence = topic_data.get("confidence", 0.7)
            else:
                primary_topic = str(topic_data) if topic_data else "ê¸°íƒ€"
                topic_confidence = 0.7
            
            # ì£¼ì œì— ë”°ë¥¸ ì—…ë¬´ ìœ í˜• ë§¤í•‘ (í™•ì¥ëœ ë§¤í•‘)
            business_type = "OTHER"  # ê¸°ë³¸ê°’
            topic_mapping = {
                "ìš”ê¸ˆ": "FEE_INFO", "ìš”ê¸ˆì œ": "PLAN_CHANGE", "ë‚©ë¶€": "FEE_PAYMENT",
                "í• ì¸": "SELECTIVE_DISCOUNT", "ê²°ì œ": "PAYMENT_METHOD_CHANGE",
                "ë¶€ê°€ì„œë¹„ìŠ¤": "ADDITIONAL_SERVICE", "ì†Œì•¡ê²°ì œ": "MICRO_PAYMENT",
                "ì •ì§€": "PHONE_SUSPENSION_LOSS_DAMAGE", "ë¶„ì‹¤": "PHONE_SUSPENSION_LOSS_DAMAGE",
                "ê¸°ê¸°": "DEVICE_CHANGE", "ëª…ì˜": "NAME_NUMBER_USIM_CANCEL",
                "ë²ˆí˜¸": "NAME_NUMBER_USIM_CANCEL", "í•´ì§€": "NAME_NUMBER_USIM_CANCEL"
            }
            
            for keyword, biz_type in topic_mapping.items():
                if keyword in primary_topic:
                    business_type = biz_type
                    break
            
            # ê°ˆë“± ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ (ê°œì„ ëœ êµ¬ì¡°)
            if isinstance(conflict_data, dict):
                conflict_detected = conflict_data.get("conflict_detected", False)
                conflict_level = conflict_data.get("conflict_level", "ë‚®ìŒ")
            else:
                conflict_detected = bool(conflict_data)
                conflict_level = "ë³´í†µ" if conflict_detected else "ë‚®ìŒ"
            
            consultation_content = "COMPLAINT" if conflict_detected else "GENERAL_INQUIRY"
            
            # í’ˆì§ˆ í‰ê°€ ê²°ê³¼ ì²˜ë¦¬ (ê°œì„ ëœ êµ¬ì¡°)
            if isinstance(quality_data, dict):
                satisfaction_score = quality_data.get("customer_satisfaction_predicted", 3)
                overall_score = quality_data.get("overall_score", 3)
            else:
                satisfaction_score = 3
                overall_score = 3
            
            # ìƒë‹´ ê²°ê³¼ ê²°ì • ë¡œì§ ê°œì„ 
            if overall_score >= 4:
                consultation_result = "SATISFACTION"
            elif overall_score >= 3:
                consultation_result = "INSUFFICIENT" 
            else:
                consultation_result = "UNSOLVABLE"
            
            # ìš”ì•½ ë°ì´í„° ì²˜ë¦¬ (ê°œì„ ëœ êµ¬ì¡°)
            if isinstance(summary_data, dict):
                summary_text = summary_data.get("summary", "")
                customer_inquiry = summary_data.get("customer_inquiry", "")
                agent_response = summary_data.get("agent_response", "")
            else:
                summary_text = str(summary_data) if summary_data else ""
                customer_inquiry = ""
                agent_response = ""
            
            # ì•¡ì…˜ ì•„ì´í…œ ì²˜ë¦¬
            action_items = global_analysis.get("action_items", {})
            if isinstance(action_items, dict):
                immediate_actions = action_items.get("immediate_actions", [])
                follow_up_actions = action_items.get("follow_up_actions", [])
                customer_request = "; ".join(immediate_actions[:3]) if immediate_actions else customer_inquiry
                solution = "; ".join(follow_up_actions[:3]) if follow_up_actions else agent_response
            else:
                customer_request = customer_inquiry
                solution = agent_response
            
            # ë¶ˆë§Œ ë¶„ì„ ì¶”ê°€ ì •ë³´
            if isinstance(complaint_data, dict):
                additional_info = complaint_data.get("department_recommendation", "")
                if not additional_info:
                    additional_info = f"ê°ˆë“±ìˆ˜ì¤€: {conflict_level}, ì‹ ë¢°ë„: {topic_confidence:.2f}"
            else:
                additional_info = f"ê°ˆë“±ìˆ˜ì¤€: {conflict_level}, ì‹ ë¢°ë„: {topic_confidence:.2f}"
            
            # ConsultationAnalysisInsert.sql íŒŒë¼ë¯¸í„° êµ¬ì„±
            consultation_params = (
                last_id,  # audio_properties_id
                business_type,  # business_type
                "CONSULTATION_CONTENT",  # classification_type
                consultation_content,  # detail_classification
                consultation_result,  # consultation_result
                summary_text or "ìƒë‹´ ë¶„ì„ ì™„ë£Œ",  # summary
                customer_request or "ê³ ê° ìš”ì²­ì‚¬í•­ ì—†ìŒ",  # customer_request
                solution or "í•´ê²°ë°©ì•ˆ ì œì‹œë¨",  # solution
                additional_info,  # additional_info
                max(topic_confidence, 0.5),  # confidence
                0.0   # processing_time
            )
            
            # ConsultationAnalysisInsert.sql íŒŒì¼ ê²½ë¡œ
            db_consultation_insert_path = os.path.join("src", "db", "sql", "ConsultationAnalysisInsert.sql")
            
            db.insert(db_consultation_insert_path, consultation_params)
            print(f"âœ… ìƒë‹´ ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ (ì—…ë¬´ìœ í˜•: {business_type}, ê°ˆë“±: {conflict_detected})")
            
        except Exception as e:
            print(f"âŒ ìƒë‹´ ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("âš ï¸ File IDê°€ ì—†ì–´ ìƒë‹´ ë¶„ì„ ê²°ê³¼ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    # Step 19.4: Insert Communication Quality (ìƒˆë¡œìš´ LLM ì§€í‘œ ì €ì¥)
    if last_id is not None and quality_analysis_result:
        try:
            print("ğŸ’¾ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì‹œì‘...")
            
            # ì§ì ‘ SQL ì‹¤í–‰ìœ¼ë¡œ communication_quality í…Œì´ë¸”ì— ì €ì¥
            import sqlite3
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO communication_quality (
                        audio_properties_id, consultation_id,
                        honorific_ratio, positive_word_ratio, negative_word_ratio,
                        euphonious_word_ratio, empathy_ratio, apology_ratio,
                        total_sentences, 
                        customer_sentiment_early, customer_sentiment_late, customer_sentiment_trend,
                        avg_response_latency, task_ratio,
                        suggestions, interruption_count,
                        analysis_details
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    last_id,  # audio_properties_id
                    f"CONSULT_{last_id}",  # consultation_id
                    quality_analysis_result.honorific_ratio or 0.0,
                    quality_analysis_result.positive_word_ratio or 0.0,
                    quality_analysis_result.negative_word_ratio or 0.0,
                    quality_analysis_result.euphonious_word_ratio or 0.0,
                    quality_analysis_result.empathy_ratio or 0.0,
                    quality_analysis_result.apology_ratio or 0.0,
                    quality_analysis_result.total_sentences or 0,
                    quality_analysis_result.customer_sentiment_early or 0.0,
                    quality_analysis_result.customer_sentiment_late or 0.0,
                    quality_analysis_result.customer_sentiment_trend or 0.0,
                    quality_analysis_result.avg_response_latency or 0.0,
                    quality_analysis_result.task_ratio or 0.0,
                    quality_analysis_result.suggestions or 0.0,  # ìƒˆë¡œìš´ LLM ì§€í‘œ
                    quality_analysis_result.interruption_count or 0,  # ìƒˆë¡œìš´ LLM ì§€í‘œ
                    str(quality_analysis_result.analysis_details or {})
                ))
                conn.commit()
            
            print(f"âœ… ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ")
            print(f"   - ìƒˆë¡œìš´ LLM ì§€í‘œ: suggestions={quality_analysis_result.suggestions}, interruption_count={quality_analysis_result.interruption_count}")
            
        except Exception as e:
            print(f"âŒ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    else:
        if last_id is None:
            print("âš ï¸ File IDê°€ ì—†ì–´ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        if not quality_analysis_result:
            print("âš ï¸ í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ê°€ ì—†ì–´ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    # Step 20: Cleanup
    cleaner.cleanup_temp_files(temp_dir)

    print(f"âœ… ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ: {audio_file_path}")
    print(f"ğŸ“Š ì²˜ë¦¬ëœ ë°œí™” ìˆ˜: {len(ssm)}")
    print(f"ğŸ—£ï¸ ê°ì§€ëœ í™”ì ìˆ˜: {len(set(utterance['speaker'] for utterance in ssm))}")
    print(f"ğŸ“ ê°ì§€ëœ ì–¸ì–´: {detected_language}")
    
    # ìƒˆë¡œìš´ LLM ì§€í‘œ ê²°ê³¼ ì¶œë ¥
    if quality_analysis_result:
        print(f"ğŸ¯ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ ê²°ê³¼:")
        print(f"   - ë¬¸ì œ í•´ê²° ì œì•ˆ ì ìˆ˜: {quality_analysis_result.suggestions:.2f}")
        print(f"   - ëŒ€í™” ê°€ë¡œì±„ê¸° íšŸìˆ˜: {quality_analysis_result.interruption_count}íšŒ")
        print(f"   - ì¡´ëŒ“ë§ ë¹„ìœ¨: {quality_analysis_result.honorific_ratio:.2f}")
        print(f"   - ê¸ì •ì–´ ë¹„ìœ¨: {quality_analysis_result.positive_word_ratio:.2f}")
        print(f"   - ì „ì²´ ë¶„ì„ ì§€í‘œ: 13ê°œ (ê¸°ì¡´ 11ê°œ + ìƒˆë¡œìš´ LLM ì§€í‘œ 2ê°œ)")
    
    print(f"ğŸ“„ ìƒì„±ëœ ì¶œë ¥ íŒŒì¼:")
    print(f"   - í…ìŠ¤íŠ¸ ëŒ€ë³¸: {transcript_output_path}")
    print(f"   - SRT ìë§‰: {srt_output_path}")
    print(f"   - JSON ëŒ€ë³¸: {json_output_path}")
    print(f"   - ë¶„ì„ ê²°ê³¼: {analysis_json_path}")
    print(f"   - ì¢…í•© ë³´ê³ ì„œ: {comprehensive_json_path}")
    if language_warning:
        print("âš ï¸ ì–¸ì–´ ê²½ê³ : í•œêµ­ì–´ê°€ ì•„ë‹Œ ì½˜í…ì¸ ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")


async def process(path: str):
    """
    Process a single audio file asynchronously.

    Parameters
    ----------
    path : str
        Path to the audio file to process.

    Returns
    -------
    None
    """
    success = False
    try:
        # ì²˜ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸
        processing_status["is_processing"] = True
        processing_status["current_file"] = path
        processing_status["errors"] = []
        
        print(f"ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {path}")
        await main(path)
        print(f"âœ… ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {path}")
        
        # ì²˜ë¦¬ ì„±ê³µ í‘œì‹œ
        success = True
        
        # ì²˜ë¦¬ ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
        processing_status["total_processed"] += 1
        processing_status["current_file"] = None
        
    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {path}")
        print(f"ì˜¤ë¥˜: {e}")
        print(f"ğŸ“ ì‹¤íŒ¨í•œ íŒŒì¼ ë³´ì¡´: {path}")
        
        # ì˜¤ë¥˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        processing_status["errors"].append({
            "file": path,
            "error": str(e),
            "timestamp": asyncio.get_event_loop().time()
        })
        
    finally:
        # ì„±ê³µí•œ ê²½ìš°ì—ë§Œ íŒŒì¼ ì‚­ì œ
        if success:
            try:
                if os.path.exists(path):
                    os.remove(path)
                    print(f"ğŸ—‘ï¸ ì²˜ë¦¬ ì™„ë£Œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì‚­ì œ: {path}")
                else:
                    print(f"âš ï¸ ì‚­ì œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
            except Exception as e:
                print(f"âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {path} - {e}")
        
        # ì²˜ë¦¬ ì™„ë£Œ
        processing_status["is_processing"] = False


def watch_and_process():
    """
    Watch for new audio files and process them automatically.
    """
    print("ğŸ” ì˜¤ë””ì˜¤ íŒŒì¼ ê°ì‹œ ì‹œì‘...")
    
    # ê°ì‹œí•  ë””ë ‰í† ë¦¬ ì„¤ì •
    watch_directories = [
        "/app/audio",
        "/app/.temp"
    ]
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ í´ë˜ìŠ¤ ì •ì˜
    class FileHandler(FileSystemEventHandler):
        def __init__(self, callback):
            self.callback = callback
            self.processing_files = set()
        
        def on_created(self, event):
            if not event.is_directory:
                self._handle_file(event.src_path)
        
        def on_moved(self, event):
            if not event.is_directory:
                self._handle_file(event.dest_path)
        
        def _handle_file(self, file_path):
            # ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì¸ íŒŒì¼ì¸ì§€ í™•ì¸
            if file_path in self.processing_files:
                return
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¥ì í™•ì¸
            audio_extensions = {'.wav', '.mp3', '.flac', '.m4a', '.aac', '.ogg'}
            if any(file_path.lower().endswith(ext) for ext in audio_extensions):
                print(f"ğŸµ ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ íŒŒì¼ ê°ì§€: {file_path}")
                self.processing_files.add(file_path)
                
                # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë™ê¸° ì²˜ë¦¬
                import threading
                thread = threading.Thread(target=self._process_file, args=(file_path,))
                thread.daemon = True
                thread.start()
        
        def _process_file(self, file_path):
            try:
                # ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
                asyncio.run(self.callback(file_path))
            finally:
                # ì²˜ë¦¬ ì™„ë£Œ í›„ íŒŒì¼ ëª©ë¡ì—ì„œ ì œê±°
                self.processing_files.discard(file_path)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ ìƒì„±
    handler = FileHandler(process)
    
    # Observer ì„¤ì • ë° ì‹œì‘
    observer = Observer()
    for directory in watch_directories:
        if os.path.exists(directory):
            observer.schedule(handler, directory, recursive=False)
            print(f"ğŸ“ ë””ë ‰í† ë¦¬ ê°ì‹œ ì‹œì‘: {directory}")
        else:
            print(f"âš ï¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory}")
    
    observer.start()
    
    try:
        print("ğŸ”„ íŒŒì¼ ê°ì‹œ ì¤‘... (Ctrl+Cë¡œ ì¢…ë£Œ)")
        while True:
            import time
            time.sleep(1)
    except KeyboardInterrupt:
        print("\nğŸ›‘ íŒŒì¼ ê°ì‹œ ì¤‘ì§€...")
        observer.stop()
    
    observer.join()
    print("âœ… íŒŒì¼ ê°ì‹œ ì¢…ë£Œ")


if __name__ == "__main__":
    import sys
    import threading
    
    if len(sys.argv) > 1:
        # íŒŒì¼ ê²½ë¡œê°€ ì œê³µëœ ê²½ìš° í•´ë‹¹ íŒŒì¼ë§Œ ì²˜ë¦¬
        file_path = sys.argv[1]
        asyncio.run(process(file_path))
    else:
        # FastAPI ì„œë²„ì™€ íŒŒì¼ ê°ì‹œë¥¼ ë™ì‹œì— ì‹¤í–‰
        def run_file_watcher():
            """ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ íŒŒì¼ ê°ì‹œ ì‹¤í–‰"""
            watch_and_process()
        
        # íŒŒì¼ ê°ì‹œ ìŠ¤ë ˆë“œ ì‹œì‘
        watcher_thread = threading.Thread(target=run_file_watcher, daemon=True)
        watcher_thread.start()
        
        # FastAPI ì„œë²„ ì‹œì‘
        print("ğŸš€ Callytics API ì„œë²„ ì‹œì‘...")
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=8000,
            log_level="info",
            access_log=True
        )