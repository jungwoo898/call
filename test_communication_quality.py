#!/usr/bin/env python3
"""
ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.text.communication_quality_analyzer import CommunicationQualityAnalyzer, test_communication_quality_analyzer
from src.integrated_analyzer import IntegratedAnalyzer
import json


def test_basic_functionality():
    """ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ê¸°ë³¸ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # ìƒ˜í”Œ ìƒë‹´ ë°ì´í„° (ë” ë‹¤ì–‘í•œ íŒ¨í„´ í¬í•¨)
    sample_utterances = [
        {"speaker": "ê³ ê°", "text": "ì•ˆë…•í•˜ì„¸ìš”. ìš”ê¸ˆ ê´€ë ¨í•´ì„œ ë¬¸ì˜ë“œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤."},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜. ìš”ê¸ˆ ê´€ë ¨ ë¬¸ì˜ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì–´ë–¤ ë¶€ë¶„ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"},
        {"speaker": "ê³ ê°", "text": "ì´ë²ˆ ë‹¬ ìš”ê¸ˆì´ ë„ˆë¬´ ë§ì´ ë‚˜ì™”ì–´ìš”. ì™œ ì´ë ‡ê²Œ ë§ì´ ë‚˜ì˜¨ ê±´ì§€ ëª¨ë¥´ê² ì–´ìš”."},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ê±±ì •ë˜ì…¨ê² ì–´ìš”. ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ê¸ˆ ë‚´ì—­ì„ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. í˜¹ì‹œ í•´ì™¸ ë¡œë°ì„ ì‚¬ìš©í•˜ì…¨ë‚˜ìš”?"},
        {"speaker": "ê³ ê°", "text": "ì•„ë‹ˆìš”. í•´ì™¸ì— ì•ˆ ê°”ëŠ”ë°ìš”."},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ê·¸ë ‡ë‹¤ë©´ ë°ì´í„° ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤. ì‹¤ë¡€ì§€ë§Œ íœ´ëŒ€í° ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?"},
        {"speaker": "ê³ ê°", "text": "010-1234-5678ì…ë‹ˆë‹¤."},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ê°ì‚¬í•©ë‹ˆë‹¤. í™•ì¸í•´ë³´ë‹ˆ ì´ë²ˆ ë‹¬ì— ë°ì´í„°ë¥¼ ë§ì´ ì‚¬ìš©í•˜ì…¨ë„¤ìš”. ë™ì˜ìƒ ì‹œì²­ì´ë‚˜ ê²Œì„ì„ í•˜ì…¨ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."},
        {"speaker": "ê³ ê°", "text": "ì•„ ê·¸ëŸ°ê°€ìš”? ê·¸ëŸ¼ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?"},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ë‹¤ìŒ ë‹¬ë¶€í„°ëŠ” ë°ì´í„° ì‚¬ìš©ëŸ‰ì„ ì²´í¬í•´ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”?"},
        {"speaker": "ê³ ê°", "text": "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤."},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ê³ ê°ë‹˜ê»˜ì„œ ë§Œì¡±í•´ì£¼ì…”ì„œ ê¸°ì©ë‹ˆë‹¤. ë‹¤ë¥¸ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½í•´ì£¼ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤."}
    ]
    
    # ë¶„ì„ ìˆ˜í–‰
    analyzer = CommunicationQualityAnalyzer()
    result = analyzer.analyze_communication_quality(sample_utterances)
    
    # ê²°ê³¼ ì¶œë ¥
    analyzer.print_analysis_report(result)
    
    # DataFrame ë³€í™˜ í…ŒìŠ¤íŠ¸
    df = analyzer.export_results_to_dataframe(result)
    print("\nğŸ“Š DataFrame ê²°ê³¼:")
    print(df.to_string(index=False))
    
    return result


def test_edge_cases():
    """ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    analyzer = CommunicationQualityAnalyzer()
    
    # 1. ìƒë‹´ì‚¬ ë°œí™”ê°€ ì—†ëŠ” ê²½ìš°
    print("\n1. ìƒë‹´ì‚¬ ë°œí™”ê°€ ì—†ëŠ” ê²½ìš°:")
    no_counselor_data = [
        {"speaker": "ê³ ê°", "text": "ì•ˆë…•í•˜ì„¸ìš”."},
        {"speaker": "ê³ ê°", "text": "ë¬¸ì˜ê°€ ìˆìŠµë‹ˆë‹¤."}
    ]
    result1 = analyzer.analyze_communication_quality(no_counselor_data)
    print(f"   ê²°ê³¼: ì´ ë¬¸ì¥ ìˆ˜ = {result1.total_sentences}")
    
    # 2. ë¹ˆ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ê²½ìš°
    print("\n2. ë¹ˆ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ê²½ìš°:")
    empty_text_data = [
        {"speaker": "ìƒë‹´ì‚¬", "text": ""},
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì•ˆë…•í•˜ì„¸ìš”."},
        {"speaker": "ìƒë‹´ì‚¬", "text": "   "}  # ê³µë°±ë§Œ
    ]
    result2 = analyzer.analyze_communication_quality(empty_text_data)
    print(f"   ê²°ê³¼: ì´ ë¬¸ì¥ ìˆ˜ = {result2.total_sentences}")
    
    # 3. ë‹¤ì–‘í•œ í™”ì ì´ë¦„ í…ŒìŠ¤íŠ¸
    print("\n3. ë‹¤ì–‘í•œ í™”ì ì´ë¦„ í…ŒìŠ¤íŠ¸:")
    various_speakers_data = [
        {"speaker": "Agent", "text": "ì•ˆë…•í•˜ì„¸ìš”. ë„ì›€ì´ í•„ìš”í•˜ì‹œë‚˜ìš”?"},
        {"speaker": "CSR", "text": "ì£„ì†¡í•©ë‹ˆë‹¤. í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."},
        {"speaker": "counselor", "text": "ê°ì‚¬í•©ë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”."},
        {"speaker": "staff", "text": "í˜¹ì‹œ ë‹¤ë¥¸ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”."}
    ]
    result3 = analyzer.analyze_communication_quality(various_speakers_data)
    print(f"   ê²°ê³¼: ì´ ë¬¸ì¥ ìˆ˜ = {result3.total_sentences}")


def test_pattern_matching():
    """íŒ¨í„´ ë§¤ì¹­ ì •í™•ë„ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” íŒ¨í„´ ë§¤ì¹­ ì •í™•ë„ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    analyzer = CommunicationQualityAnalyzer()
    
    # ê° íŒ¨í„´ë³„ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_cases = [
        # ì¡´ëŒ“ë§ íŒ¨í„´ í…ŒìŠ¤íŠ¸
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì•ˆë…•í•˜ì„¸ìš”. ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."},  # ì¡´ëŒ“ë§
        {"speaker": "ìƒë‹´ì‚¬", "text": "í™•ì¸í•´ì£¼ì„¸ìš”."},  # ì¡´ëŒ“ë§
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì–´ë–»ê²Œ í•˜ì‹œê² ì–´ìš”?"},  # ì¡´ëŒ“ë§ + ì£¼ì²´ë†’ì„
        
        # ì¿ ì…˜ì–´ íŒ¨í„´ í…ŒìŠ¤íŠ¸
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì‹¤ë¡€ì§€ë§Œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."},  # ì¿ ì…˜ì–´
        {"speaker": "ìƒë‹´ì‚¬", "text": "í˜¹ì‹œ ì‹œê°„ì´ ë˜ì‹œë‚˜ìš”?"},  # ì¿ ì…˜ì–´
        {"speaker": "ìƒë‹´ì‚¬", "text": "ê·¸ëŸ° ê²ƒ ê°™ìŠµë‹ˆë‹¤."},  # ì™„ê³¡í‘œí˜„
        
        # ê³µê° í‘œí˜„ í…ŒìŠ¤íŠ¸
        {"speaker": "ìƒë‹´ì‚¬", "text": "ë§ì´ í˜ë“œì…¨ì£ ."},  # ê³µê°
        {"speaker": "ìƒë‹´ì‚¬", "text": "ê±±ì •ë˜ì…¨ê² ì–´ìš”."},  # ê³µê°
        
        # ì‚¬ê³¼ í‘œí˜„ í…ŒìŠ¤íŠ¸
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì£„ì†¡í•©ë‹ˆë‹¤."},  # ì‚¬ê³¼
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì–‘í•´ ë¶€íƒë“œë¦½ë‹ˆë‹¤."},  # ì‚¬ê³¼
    ]
    
    result = analyzer.analyze_communication_quality(test_cases)
    
    print(f"ğŸ“Š íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼:")
    print(f"   ì¡´ëŒ“ë§ ë¹„ìœ¨: {result.honorific_ratio:.1f}%")
    print(f"   ì¿ ì…˜ì–´ ë¹„ìœ¨: {result.euphonious_word_ratio:.1f}%")
    print(f"   ê³µê° í‘œí˜„ ë¹„ìœ¨: {result.empathy_ratio:.1f}%")
    print(f"   ì‚¬ê³¼ í‘œí˜„ ë¹„ìœ¨: {result.apology_ratio:.1f}%")
    
    # ìƒì„¸ ì •ë³´ ì¶œë ¥
    details = result.analysis_details
    print(f"\nğŸ“‹ ìƒì„¸ ë§¤ì¹­ ì •ë³´:")
    print(f"   ì¡´ëŒ“ë§ ë¬¸ì¥ ìˆ˜: {details.get('honorific_sentences', 0)}")
    print(f"   ì¿ ì…˜ì–´ ë¬¸ì¥ ìˆ˜: {details.get('euphonious_sentences', 0)}")
    print(f"   ê³µê° ë¬¸ì¥ ìˆ˜: {details.get('empathy_sentences', 0)}")
    print(f"   ì‚¬ê³¼ ë¬¸ì¥ ìˆ˜: {details.get('apology_sentences', 0)}")


def test_sentiment_analysis():
    """ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    analyzer = CommunicationQualityAnalyzer()
    
    # ê°ì„± ë‹¨ì–´ê°€ í¬í•¨ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    sentiment_test_data = [
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì¢‹ì€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."},  # ê¸ì •
        {"speaker": "ìƒë‹´ì‚¬", "text": "ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ê°€ ë  ê²ƒì…ë‹ˆë‹¤."},  # ê¸ì •
        {"speaker": "ìƒë‹´ì‚¬", "text": "ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."},  # ë¶€ì •
        {"speaker": "ìƒë‹´ì‚¬", "text": "ì–´ë ¤ìš´ ìƒí™©ì…ë‹ˆë‹¤."},  # ë¶€ì •
        {"speaker": "ìƒë‹´ì‚¬", "text": "í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."},  # ì¤‘ë¦½
    ]
    
    result = analyzer.analyze_communication_quality(sentiment_test_data)
    
    print(f"ğŸ“Š ê°ì„± ë¶„ì„ ê²°ê³¼:")
    print(f"   ê¸ì • ë‹¨ì–´ ë¹„ìœ¨: {result.positive_word_ratio:.1f}%")
    print(f"   ë¶€ì • ë‹¨ì–´ ë¹„ìœ¨: {result.negative_word_ratio:.1f}%")
    
    # ìƒ˜í”Œ ë¬¸ì¥ë“¤ ì¶œë ¥
    details = result.analysis_details.get('sample_sentences', {})
    if details.get('positive'):
        print(f"\n   ê¸ì • ìƒ˜í”Œ: {details['positive'][0]}")
    if details.get('negative'):
        print(f"   ë¶€ì • ìƒ˜í”Œ: {details['negative'][0]}")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í’ˆì§ˆ ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    try:
        # 1. ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        result = test_basic_functionality()
        
        # 2. ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
        test_edge_cases()
        
        # 3. íŒ¨í„´ ë§¤ì¹­ í…ŒìŠ¤íŠ¸
        test_pattern_matching()
        
        # 4. ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸
        test_sentiment_analysis()
        
        print("\n" + "="*80)
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("ğŸ“‹ ìµœì¢… ê²°ê³¼ ìš”ì•½:")
        print(f"   - 6ê°€ì§€ í’ˆì§ˆ ì§€í‘œê°€ ì •ìƒì ìœ¼ë¡œ ê³„ì‚°ë¨")
        print(f"   - íŒ¨í„´ ë§¤ì¹­ì´ ì •í™•í•˜ê²Œ ë™ì‘í•¨")
        print(f"   - ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬ê°€ ì•ˆì •ì ì„")
        print(f"   - ê°ì„±ì‚¬ì „ ê¸°ë°˜ ë¶„ì„ì´ ë™ì‘í•¨")
        
        # JSON í˜•íƒœë¡œ ê²°ê³¼ ì¶œë ¥ (API ì—°ë™ í™•ì¸ìš©)
        print("\nğŸ“„ JSON ê²°ê³¼ ìƒ˜í”Œ:")
        json_result = {
            'honorific_ratio': result.honorific_ratio,
            'positive_word_ratio': result.positive_word_ratio,
            'negative_word_ratio': result.negative_word_ratio,
            'euphonious_word_ratio': result.euphonious_word_ratio,
            'empathy_ratio': result.empathy_ratio,
            'apology_ratio': result.apology_ratio,
            'total_sentences': result.total_sentences
        }
        print(json.dumps(json_result, indent=2, ensure_ascii=False))
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 