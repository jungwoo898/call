#!/usr/bin/env python3
"""
ë²„ì „ í†µì¼ ìë™í™” ìŠ¤í¬ë¦½íŠ¸
CUDA ë²„ì „ í†µì¼, ê³µí†µ requirements.txt êµ¬ì¡° ìƒì„±, Dockerfile í‘œì¤€í™”
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Set, Any

class VersionUnifier:
    def __init__(self):
        self.backup_dir = Path("backups/version_unification")
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        self.fixes_applied = []
        
        # í‘œì¤€ ë²„ì „ ì„¤ì •
        self.standard_versions = {
            'python': '3.11',
            'cuda': '11.8.2',  # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” CUDA ë²„ì „
            'cudnn': '8',
            'ubuntu': '20.04'
        }
        
    def unify_all_versions(self):
        """ëª¨ë“  ë²„ì „ í†µì¼ ì‘ì—…"""
        print("ğŸ”§ ë²„ì „ í†µì¼ ìë™í™” ì‹œì‘...")
        
        # 1. CUDA ë²„ì „ í†µì¼
        self._unify_cuda_versions()
        
        # 2. ê³µí†µ requirements.txt êµ¬ì¡° ìƒì„±
        self._create_common_requirements()
        
        # 3. ì„œë¹„ìŠ¤ë³„ requirements.txt ë¦¬íŒ©í† ë§
        self._refactor_service_requirements()
        
        # 4. Dockerfile í‘œì¤€í™”
        self._standardize_dockerfiles()
        
        # 5. CI ì„¤ì • ìƒì„±
        self._create_ci_config()
        
        # 6. ìˆ˜ì • ë¦¬í¬íŠ¸ ìƒì„±
        self._generate_unification_report()
        
        print("âœ… ë²„ì „ í†µì¼ ìë™í™” ì™„ë£Œ!")
    
    def _unify_cuda_versions(self):
        """CUDA ë²„ì „ í†µì¼"""
        print("ğŸ”§ CUDA ë²„ì „ í†µì¼ ì¤‘...")
        
        # í‘œì¤€ CUDA ë² ì´ìŠ¤ ì´ë¯¸ì§€
        standard_cuda_image = f"nvidia/cuda:{self.standard_versions['cuda']}-cudnn{self.standard_versions['cudnn']}-runtime-ubuntu{self.standard_versions['ubuntu']}"
        
        cuda_replacements = [
            (r'FROM\s+nvidia/cuda:11\.8\.0', f'FROM {standard_cuda_image}'),
            (r'FROM\s+nvidia/cuda:11\.8\.2', f'FROM {standard_cuda_image}'),
            (r'cuda-version=11\.8\.0', f'cuda-version={self.standard_versions["cuda"]}'),
            (r'cuda-version=11\.8\.2', f'cuda-version={self.standard_versions["cuda"]}'),
        ]
        
        for dockerfile in Path(".").glob("Dockerfile*"):
            try:
                with open(dockerfile, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                original_content = content
                
                for pattern, replacement in cuda_replacements:
                    content = re.sub(pattern, replacement, content)
                
                if content != original_content:
                    # ë°±ì—… ìƒì„±
                    backup_file = self.backup_dir / f"{dockerfile.name}.backup"
                    with open(backup_file, 'w', encoding='utf-8') as f:
                        f.write(original_content)
                    
                    # ìˆ˜ì •ëœ ë‚´ìš© ì €ì¥
                    with open(dockerfile, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                    self.fixes_applied.append({
                        'file': str(dockerfile),
                        'type': 'cuda_unification',
                        'description': f'CUDA ë²„ì „ {self.standard_versions["cuda"]}ë¡œ í†µì¼'
                    })
                    
            except Exception as e:
                print(f"âš ï¸ CUDA ë²„ì „ í†µì¼ ì‹¤íŒ¨: {dockerfile}, ì˜¤ë¥˜: {e}")
    
    def _create_common_requirements(self):
        """ê³µí†µ requirements.txt ìƒì„±"""
        print("ğŸ“¦ ê³µí†µ requirements.txt ìƒì„± ì¤‘...")
        
        # ëª¨ë“  requirements íŒŒì¼ì—ì„œ ê³µí†µ íŒ¨í‚¤ì§€ ìˆ˜ì§‘
        common_packages = {}
        all_requirements_files = list(Path(".").glob("requirements*.txt"))
        
        for req_file in all_requirements_files:
            try:
                with open(req_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                lines = content.split('\n')
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        match = re.match(r'^([a-zA-Z0-9_-]+)([<>=!~]+)([\d.a-zA-Z]+)', line)
                        if match:
                            package, operator, version = match.groups()
                            if package not in common_packages:
                                common_packages[package] = []
                            common_packages[package].append(f"{operator}{version}")
                            
            except Exception as e:
                print(f"âš ï¸ requirements ë¶„ì„ ì‹¤íŒ¨: {req_file}, ì˜¤ë¥˜: {e}")
        
        # ê³µí†µ íŒ¨í‚¤ì§€ ì¤‘ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë²„ì „ ì„ íƒ
        final_common_packages = {}
        for package, versions in common_packages.items():
            if len(versions) > 1:
                # ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë²„ì „ ì„ íƒ
                version_counts = {}
                for version in versions:
                    if version not in version_counts:
                        version_counts[version] = 0
                    version_counts[version] += 1
                
                most_common_version = max(version_counts.items(), key=lambda x: x[1])[0]
                final_common_packages[package] = most_common_version
            else:
                final_common_packages[package] = versions[0]
        
        # ê³µí†µ requirements.txt ìƒì„±
        common_requirements_content = """# ê³µí†µ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ëª¨ë“  ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©)
# ì´ íŒŒì¼ì„ ìˆ˜ì •í•  ë•ŒëŠ” ëª¨ë“  ì„œë¹„ìŠ¤ì— ì˜í–¥ì„ ì£¼ë¯€ë¡œ ì£¼ì˜

# ì›¹ í”„ë ˆì„ì›Œí¬
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.5.2

# HTTP í´ë¼ì´ì–¸íŠ¸
httpx==0.25.2
requests==2.31.0
aiohttp==3.9.1

# ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§
psutil==5.9.6

# ë°ì´í„° ì²˜ë¦¬
numpy==1.24.4
scipy==1.11.4
pandas==2.1.4
scikit-learn==1.3.2

# ì˜¤ë””ì˜¤ ì²˜ë¦¬
librosa==0.10.1
soundfile==0.12.1
pydub==0.25.1
noisereduce==3.0.0

# ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
torch==2.1.2
torchaudio==2.1.2
torchvision==0.16.2

# Transformers
transformers==4.35.2
tokenizers==0.14.1
accelerate==0.25.0
huggingface-hub==0.19.4

# ìŒì„± ì¸ì‹
faster-whisper==0.10.0
openai-whisper==20231117

# ìŒì„± ë¶„ì„
pyannote-audio==3.1.1
demucs==4.0.0
nemo-toolkit==1.23.0

# í…ìŠ¤íŠ¸ ì²˜ë¦¬
sentence-transformers==2.2.2
datasets==2.16.1
langdetect==1.0.9

# í•œêµ­ì–´ ì²˜ë¦¬
konlpy==0.6.0
soynlp==0.0.493

# ìœ í‹¸ë¦¬í‹°
python-dotenv==1.0.0
tqdm==4.66.1
structlog==23.2.0
prometheus-client==0.19.0

# ê°œë°œ ë„êµ¬
pytest==7.4.3
black==23.11.0
isort==5.12.0
"""
        
        # ê³µí†µ requirements.txt ì €ì¥
        with open('requirements_common.txt', 'w', encoding='utf-8') as f:
            f.write(common_requirements_content)
        
        self.fixes_applied.append({
            'file': 'requirements_common.txt',
            'type': 'common_requirements',
            'description': 'ê³µí†µ requirements.txt ìƒì„±'
        })
    
    def _refactor_service_requirements(self):
        """ì„œë¹„ìŠ¤ë³„ requirements.txt ë¦¬íŒ©í† ë§"""
        print("ğŸ“¦ ì„œë¹„ìŠ¤ë³„ requirements.txt ë¦¬íŒ©í† ë§ ì¤‘...")
        
        # ì„œë¹„ìŠ¤ë³„ íŠ¹í™” íŒ¨í‚¤ì§€ ì •ì˜
        service_specific_packages = {
            'audio-processor': [
                'joblib==1.3.2',
            ],
            'database-service': [
                'aiosqlite==0.19.0',
                'sqlalchemy==2.0.23',
            ],
            'gateway': [
                'redis==5.0.1',
                'aioredis==2.0.1',
                'aiofiles==23.2.1',
            ],
            'llm-analyzer': [
                'openai==1.6.1',
                'langchain==0.1.0',
                'langchain-openai==0.0.2',
            ],
            'punctuation-restorer': [
                'deepmultilingualpunctuation==1.0.1',
            ],
            'sentiment-analyzer': [
                # konlpy, soynlpëŠ” ê³µí†µì— í¬í•¨ë¨
            ],
            'speaker-diarizer': [
                'MPSENet==1.0.3',
                'ctc-forced-aligner==1.0.2',
                'omegaconf==2.3.0',
            ],
            'speech-recognizer': [
                # faster-whisper, openai-whisperëŠ” ê³µí†µì— í¬í•¨ë¨
            ],
        }
        
        # ê° ì„œë¹„ìŠ¤ë³„ requirements.txt ë¦¬íŒ©í† ë§
        for service, packages in service_specific_packages.items():
            req_file = Path(f"requirements.{service}.txt")
            if req_file.exists():
                try:
                    # ë°±ì—… ìƒì„±
                    backup_file = self.backup_dir / f"{req_file.name}.backup"
                    with open(backup_file, 'w', encoding='utf-8') as f:
                        with open(req_file, 'r', encoding='utf-8') as src:
                            f.write(src.read())
                    
                    # ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ì‘ì„±
                    new_content = f"""# {service} ì„œë¹„ìŠ¤ ì „ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
# ê³µí†µ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” requirements_common.txtì—ì„œ ê´€ë¦¬

# ê³µí†µ ë¼ì´ë¸ŒëŸ¬ë¦¬ í¬í•¨
-r requirements_common.txt

# ì„œë¹„ìŠ¤ ì „ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
"""
                    
                    for package in packages:
                        new_content += f"{package}\n"
                    
                    # íŒŒì¼ ì €ì¥
                    with open(req_file, 'w', encoding='utf-8') as f:
                        f.write(new_content)
                    
                    self.fixes_applied.append({
                        'file': str(req_file),
                        'type': 'service_requirements_refactor',
                        'description': f'{service} ì„œë¹„ìŠ¤ requirements ë¦¬íŒ©í† ë§'
                    })
                    
                except Exception as e:
                    print(f"âš ï¸ {service} requirements ë¦¬íŒ©í† ë§ ì‹¤íŒ¨: {e}")
    
    def _standardize_dockerfiles(self):
        """Dockerfile í‘œì¤€í™”"""
        print("ğŸ³ Dockerfile í‘œì¤€í™” ì¤‘...")
        
        # í‘œì¤€ ë² ì´ìŠ¤ ì´ë¯¸ì§€
        standard_base_image = f"nvidia/cuda:{self.standard_versions['cuda']}-cudnn{self.standard_versions['cudnn']}-runtime-ubuntu{self.standard_versions['ubuntu']}"
        
        # í‘œì¤€ Dockerfile í…œí”Œë¦¿
        dockerfile_template = f"""# í‘œì¤€í™”ëœ Dockerfile í…œí”Œë¦¿
FROM {standard_base_image}

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸
RUN apt-get update && apt-get install -y \\
    python{self.standard_versions['python']} \\
    python{self.standard_versions['python']}-pip \\
    python{self.standard_versions['python']}-dev \\
    && rm -rf /var/lib/apt/lists/*

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# Python í™˜ê²½ ì„¤ì •
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# ê³µí†µ requirements ì„¤ì¹˜
COPY requirements_common.txt .
RUN pip install --no-cache-dir -r requirements_common.txt

# ì„œë¹„ìŠ¤ë³„ requirements ì„¤ì¹˜ (ì„œë¹„ìŠ¤ì— ë”°ë¼ ë‹¤ë¦„)
# COPY requirements.<service>.txt .
# RUN pip install --no-cache-dir -r requirements.<service>.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY src/ ./src/

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# ì‹¤í–‰ ëª…ë ¹ (ì„œë¹„ìŠ¤ì— ë”°ë¼ ë‹¤ë¦„)
# CMD ["python", "-m", "src.<service>.main"]
"""
        
        # í‘œì¤€ Dockerfile í…œí”Œë¦¿ ì €ì¥
        with open('Dockerfile.template', 'w', encoding='utf-8') as f:
            f.write(dockerfile_template)
        
        self.fixes_applied.append({
            'file': 'Dockerfile.template',
            'type': 'dockerfile_standardization',
            'description': 'í‘œì¤€ Dockerfile í…œí”Œë¦¿ ìƒì„±'
        })
    
    def _create_ci_config(self):
        """CI ì„¤ì • ìƒì„±"""
        print("ğŸ”§ CI ì„¤ì • ìƒì„± ì¤‘...")
        
        # GitHub Actions ì›Œí¬í”Œë¡œìš°
        github_workflow = """name: Version Compatibility Check

on:
  push:
    paths:
      - 'requirements*.txt'
      - 'Dockerfile*'
      - 'src/**'
  pull_request:
    paths:
      - 'requirements*.txt'
      - 'Dockerfile*'
      - 'src/**'

jobs:
  version-check:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install requests
    
    - name: Run version compatibility check
      run: |
        python version_compatibility_analyzer.py
    
    - name: Check for version conflicts
      run: |
        if [ -f "version_compatibility_report.json" ]; then
          conflicts=$(python -c "import json; data=json.load(open('version_compatibility_report.json')); print(data['summary']['version_conflicts'])")
          if [ "$conflicts" -gt 0 ]; then
            echo "âŒ Version conflicts detected: $conflicts"
            exit 1
          else
            echo "âœ… No version conflicts detected"
          fi
        fi
    
    - name: Check for compatibility issues
      run: |
        if [ -f "version_compatibility_report.json" ]; then
          issues=$(python -c "import json; data=json.load(open('version_compatibility_report.json')); print(data['summary']['compatibility_issues'])")
          if [ "$issues" -gt 0 ]; then
            echo "âš ï¸ Compatibility issues detected: $issues"
            echo "Please review the report"
          else
            echo "âœ… No compatibility issues detected"
          fi
        fi
"""
        
        # .github/workflows ë””ë ‰í† ë¦¬ ìƒì„±
        workflows_dir = Path(".github/workflows")
        workflows_dir.mkdir(parents=True, exist_ok=True)
        
        # ì›Œí¬í”Œë¡œìš° íŒŒì¼ ì €ì¥
        with open(workflows_dir / "version-check.yml", 'w', encoding='utf-8') as f:
            f.write(github_workflow)
        
        self.fixes_applied.append({
            'file': '.github/workflows/version-check.yml',
            'type': 'ci_integration',
            'description': 'GitHub Actions CI ì„¤ì • ìƒì„±'
        })
        
        # GitLab CI ì„¤ì •
        gitlab_ci = """# GitLab CI ì„¤ì •
stages:
  - version_check

version_compatibility_check:
  stage: version_check
  image: python:3.11
  script:
    - pip install requests
    - python version_compatibility_analyzer.py
    - |
      if [ -f "version_compatibility_report.json" ]; then
        conflicts=$(python -c "import json; data=json.load(open('version_compatibility_report.json')); print(data['summary']['version_conflicts'])")
        if [ "$conflicts" -gt 0 ]; then
          echo "âŒ Version conflicts detected: $conflicts"
          exit 1
        fi
      fi
  rules:
    - changes:
        - requirements*.txt
        - Dockerfile*
        - src/**/*
"""
        
        with open('.gitlab-ci.yml', 'w', encoding='utf-8') as f:
            f.write(gitlab_ci)
        
        self.fixes_applied.append({
            'file': '.gitlab-ci.yml',
            'type': 'ci_integration',
            'description': 'GitLab CI ì„¤ì • ìƒì„±'
        })
    
    def _generate_unification_report(self):
        """í†µì¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "="*60)
        print("ğŸ“Š ë²„ì „ í†µì¼ ìë™í™” ë¦¬í¬íŠ¸")
        print("="*60)
        
        print(f"\nğŸ”§ ì´ ìˆ˜ì • ì‚¬í•­: {len(self.fixes_applied)}ê°œ")
        
        # íƒ€ì…ë³„ ìˆ˜ì • ì‚¬í•­ ìš”ì•½
        fix_types = {}
        for fix in self.fixes_applied:
            fix_type = fix['type']
            if fix_type not in fix_types:
                fix_types[fix_type] = 0
            fix_types[fix_type] += 1
        
        for fix_type, count in fix_types.items():
            print(f"   - {fix_type}: {count}ê°œ")
        
        # ìƒì„¸ ìˆ˜ì • ì‚¬í•­
        print(f"\nğŸ“‹ ìƒì„¸ ìˆ˜ì • ì‚¬í•­:")
        for fix in self.fixes_applied:
            print(f"   - {fix['file']}: {fix['description']}")
        
        # í‘œì¤€ ë²„ì „ ì •ë³´
        print(f"\nğŸ“‹ í‘œì¤€ ë²„ì „ ì„¤ì •:")
        for component, version in self.standard_versions.items():
            print(f"   - {component}: {version}")
        
        # ë°±ì—… ì •ë³´
        print(f"\nğŸ’¾ ë°±ì—… íŒŒì¼ ìœ„ì¹˜: {self.backup_dir}")
        
        # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
        print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"   1. requirements_common.txt ê²€í†  ë° ìˆ˜ì •")
        print(f"   2. ì„œë¹„ìŠ¤ë³„ requirements.txt í™•ì¸")
        print(f"   3. Dockerfile.template ê¸°ë°˜ìœ¼ë¡œ ì„œë¹„ìŠ¤ë³„ Dockerfile ìˆ˜ì •")
        print(f"   4. CI ì„¤ì • í…ŒìŠ¤íŠ¸")
        print(f"   5. ì „ì²´ ë¹Œë“œ ë° í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        
        # ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥
        report = {
            'summary': {
                'total_fixes': len(self.fixes_applied),
                'fix_types': fix_types,
                'standard_versions': self.standard_versions
            },
            'fixes': self.fixes_applied,
            'backup_location': str(self.backup_dir)
        }
        
        with open('version_unification_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥: version_unification_report.json")

def main():
    unifier = VersionUnifier()
    unifier.unify_all_versions()
    print("\nğŸ‰ ë²„ì „ í†µì¼ ìë™í™” ì™„ë£Œ!")

if __name__ == "__main__":
    main() 