#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
========================================================================
ğŸš€ Callytics SQLite â†’ PostgreSQL ì™„ì „ ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬
========================================================================
ëª©ì : ê¸°ì¡´ SQLite ë°ì´í„°ë¥¼ PostgreSQLë¡œ ë¬´ì†ì‹¤ ì´ì „
íŠ¹ì§•: 
- ì»¬ëŸ¼ í˜•ì‹ ë³€í™˜ (SQLite â†’ PostgreSQL)
- ë°ì´í„° íƒ€ì… ìµœì í™” 
- ì¸ë±ìŠ¤ ë° ì œì•½ì¡°ê±´ ì ìš©
- íŠ¸ëœì­ì…˜ ì•ˆì „ì„± ë³´ì¥
- ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
"""

import os
import sys
import sqlite3
import asyncio
import asyncpg
import json
import logging
from datetime import datetime, date
from decimal import Decimal
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import uuid
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('migration.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class MigrationStats:
    """ë§ˆì´ê·¸ë ˆì´ì…˜ í†µê³„"""
    total_tables: int = 0
    completed_tables: int = 0
    total_records: int = 0
    migrated_records: int = 0
    errors: List[str] = None
    start_time: datetime = None
    end_time: datetime = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []
        if self.start_time is None:
            self.start_time = datetime.now()

class DatabaseMigrator:
    """ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, sqlite_path: str, postgres_config: Dict[str, Any]):
        self.sqlite_path = sqlite_path
        self.postgres_config = postgres_config
        self.stats = MigrationStats()
        
        # í…Œì´ë¸” ë§¤í•‘ (SQLite â†’ PostgreSQL)
        self.table_mappings = {
            # ê¸°ì¡´ í˜¸í™˜ì„± í…Œì´ë¸”ë“¤ (ìš°ì„  ë§ˆì´ê·¸ë ˆì´ì…˜)
            'consultation_analysis': 'consultation_analysis',
            'utterances': 'utterances', 
            'topics': 'topics',
            'audio_properties': 'audio_properties',
            
            # ìƒˆë¡œìš´ ì •ê·œí™”ëœ í…Œì´ë¸”ë“¤
            'audio_files': 'audio_files',
            'speaker_segments': 'speaker_segments',
            'transcriptions': 'transcriptions',
            'audio_metrics': 'audio_metrics',
            'consultation_sessions': 'consultation_sessions',
            'quality_metrics': 'quality_metrics',
            'sentiment_analysis': 'sentiment_analysis',
            'communication_patterns': 'communication_patterns',
            'improvement_suggestions': 'improvement_suggestions',
            'consultation_keywords': 'consultation_keywords',
            'agent_performance': 'agent_performance',
            'analysis_history': 'analysis_history',
            'processing_logs': 'processing_logs'
        }
        
        # ë°ì´í„° íƒ€ì… ë³€í™˜ ë§¤í•‘
        self.type_conversions = {
            'INTEGER': 'INTEGER',
            'TEXT': 'TEXT',
            'REAL': 'DECIMAL',
            'DATETIME': 'TIMESTAMPTZ',
            'DATE': 'DATE',
            'BOOLEAN': 'BOOLEAN'
        }

    async def migrate_all(self) -> MigrationStats:
        """ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        logger.info("ğŸš€ Callytics ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        logger.info(f"SQLite: {self.sqlite_path}")
        logger.info(f"PostgreSQL: {self.postgres_config['host']}:{self.postgres_config['port']}")
        
        try:
            # 1. SQLite ì—°ê²° í™•ì¸
            await self._check_sqlite_connection()
            
            # 2. PostgreSQL ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ ìƒì„±
            pg_pool = await self._setup_postgresql()
            
            # 3. í…Œì´ë¸”ë³„ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
            await self._migrate_tables(pg_pool)
            
            # 4. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
            await self._verify_migration(pg_pool)
            
            # 5. ì¸ë±ìŠ¤ ì¬ìƒì„± ë° ìµœì í™”
            await self._optimize_database(pg_pool)
            
            await pg_pool.close()
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            self.stats.errors.append(str(e))
            raise
        
        finally:
            self.stats.end_time = datetime.now()
            self._print_final_stats()
        
        return self.stats

    async def _check_sqlite_connection(self):
        """SQLite ì—°ê²° ë° êµ¬ì¡° í™•ì¸"""
        logger.info("ğŸ“‹ SQLite ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì¤‘...")
        
        if not os.path.exists(self.sqlite_path):
            raise FileNotFoundError(f"SQLite íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.sqlite_path}")
        
        conn = sqlite3.connect(self.sqlite_path)
        cursor = conn.cursor()
        
        try:
            # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' ORDER BY name")
            tables = [row[0] for row in cursor.fetchall()]
            
            logger.info(f"âœ… SQLite í…Œì´ë¸” ë°œê²¬: {len(tables)}ê°œ")
            
            # ê° í…Œì´ë¸”ì˜ ë ˆì½”ë“œ ìˆ˜ ê³„ì‚°
            total_records = 0
            for table in tables:
                if table in self.table_mappings:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cursor.fetchone()[0]
                    total_records += count
                    logger.info(f"  ğŸ“Š {table}: {count:,}ê°œ ë ˆì½”ë“œ")
            
            self.stats.total_tables = len([t for t in tables if t in self.table_mappings])
            self.stats.total_records = total_records
            
        finally:
            conn.close()

    async def _setup_postgresql(self) -> asyncpg.Pool:
        """PostgreSQL ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ ìƒì„±"""
        logger.info("ğŸ˜ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì¤‘...")
        
        # ì—°ê²° í’€ ìƒì„±
        pool = await asyncpg.create_pool(
            host=self.postgres_config['host'],
            port=self.postgres_config['port'],
            user=self.postgres_config['user'],
            password=self.postgres_config['password'],
            database=self.postgres_config['database'],
            min_size=5,
            max_size=20
        )
        
        # ìŠ¤í‚¤ë§ˆ íŒŒì¼ ì‹¤í–‰
        schema_path = Path(__file__).parent / 'sql' / 'postgresql_migration_schema.sql'
        if schema_path.exists():
            async with pool.acquire() as conn:
                with open(schema_path, 'r', encoding='utf-8') as f:
                    schema_sql = f.read()
                
                # ENUM íƒ€ì… ë¶€í„° ìƒì„± (ì¶©ëŒ ë°©ì§€)
                try:
                    await conn.execute(schema_sql)
                    logger.info("âœ… PostgreSQL ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘ ì¼ë¶€ ì˜¤ë¥˜ (ì •ìƒ): {e}")
        
        return pool

    async def _migrate_tables(self, pg_pool: asyncpg.Pool):
        """í…Œì´ë¸”ë³„ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ğŸ“‹ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        # SQLite ì—°ê²°
        sqlite_conn = sqlite3.connect(self.sqlite_path)
        sqlite_conn.row_factory = sqlite3.Row  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
        
        try:
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ìˆœì„œ (ì°¸ì¡° ë¬´ê²°ì„± ê³ ë ¤)
            migration_order = [
                # 1ë‹¨ê³„: ë…ë¦½ì ì¸ í…Œì´ë¸”ë“¤
                'consultation_analysis',
                'audio_files',
                
                # 2ë‹¨ê³„: ê¸°ë³¸ í…Œì´ë¸”ë“¤
                'consultation_sessions',
                'speaker_segments', 
                'transcriptions',
                'audio_metrics',
                
                # 3ë‹¨ê³„: ì—°ê´€ í…Œì´ë¸”ë“¤
                'quality_metrics',
                'sentiment_analysis',
                'communication_patterns',
                'improvement_suggestions',
                'consultation_keywords',
                'agent_performance',
                'analysis_history',
                'processing_logs',
                
                # 4ë‹¨ê³„: í˜¸í™˜ì„± í…Œì´ë¸”ë“¤
                'utterances',
                'topics', 
                'audio_properties'
            ]
            
            for table_name in migration_order:
                if await self._table_exists_in_sqlite(sqlite_conn, table_name):
                    await self._migrate_single_table(sqlite_conn, pg_pool, table_name)
                    self.stats.completed_tables += 1
                else:
                    logger.info(f"â­ï¸ í…Œì´ë¸” ê±´ë„ˆë›°ê¸° (ì—†ìŒ): {table_name}")
                    
        finally:
            sqlite_conn.close()

    async def _table_exists_in_sqlite(self, sqlite_conn: sqlite3.Connection, table_name: str) -> bool:
        """SQLiteì— í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        cursor = sqlite_conn.cursor()
        cursor.execute(
            "SELECT name FROM sqlite_master WHERE type='table' AND name=?", 
            (table_name,)
        )
        return cursor.fetchone() is not None

    async def _migrate_single_table(self, sqlite_conn: sqlite3.Connection, 
                                   pg_pool: asyncpg.Pool, table_name: str):
        """ë‹¨ì¼ í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info(f"ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘: {table_name}")
        
        cursor = sqlite_conn.cursor()
        
        # SQLite í…Œì´ë¸” êµ¬ì¡° ë¶„ì„
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns_info = cursor.fetchall()
        
        # ë°ì´í„° ì¡°íšŒ
        cursor.execute(f"SELECT * FROM {table_name}")
        rows = cursor.fetchall()
        
        if not rows:
            logger.info(f"  â­ï¸ ë¹ˆ í…Œì´ë¸”: {table_name}")
            return
        
        logger.info(f"  ğŸ“Š {len(rows):,}ê°œ ë ˆì½”ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        
        # PostgreSQLì— ë°ì´í„° ì‚½ì…
        async with pg_pool.acquire() as pg_conn:
            # íŠ¸ëœì­ì…˜ ì‹œì‘
            async with pg_conn.transaction():
                
                # íŠ¹ë³„ ì²˜ë¦¬ê°€ í•„ìš”í•œ í…Œì´ë¸”ë“¤
                if table_name == 'audio_files':
                    await self._migrate_audio_files(pg_conn, rows)
                elif table_name == 'consultation_sessions':
                    await self._migrate_consultation_sessions(pg_conn, rows)
                elif table_name == 'consultation_analysis':
                    await self._migrate_consultation_analysis(pg_conn, rows)
                else:
                    # ì¼ë°˜ì ì¸ í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜
                    await self._migrate_generic_table(pg_conn, table_name, rows)
        
        logger.info(f"  âœ… {table_name} ì™„ë£Œ: {len(rows):,}ê°œ ë ˆì½”ë“œ")
        self.stats.migrated_records += len(rows)

    async def _migrate_audio_files(self, pg_conn: asyncpg.Connection, rows: List[sqlite3.Row]):
        """audio_files í…Œì´ë¸” íŠ¹ë³„ ì²˜ë¦¬"""
        insert_sql = None"
        INSERT INTO audio_files (
            file_path, file_name, file_size, duration_seconds, 
            sample_rate, channels, format, upload_timestamp,
            processing_status, processing_started_at, processing_completed_at,
            error_message, created_at, updated_at
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
        ON CONFLICT (file_path) DO UPDATE SET
            file_name = EXCLUDED.file_name,
            updated_at = CURRENT_TIMESTAMP
        """
        
        for row in rows:
            try:
                # ìƒíƒœ ë³€í™˜ (SQLite â†’ PostgreSQL ENUM)
                status = row.get('processing_status', 'pending')
                if status not in ('pending', 'processing', 'completed', 'failed', 'reprocessing'):
                    status = 'pending'
                
                await pg_conn.execute(insert_sql,
                    row['file_path'],
                    row['file_name'] or Path(row['file_path']).name,
                    row.get('file_size'),
                    row.get('duration_seconds'),
                    row.get('sample_rate'),
                    row.get('channels', 1),
                    row.get('format', 'mp3'),
                    self._convert_timestamp(row.get('upload_timestamp')),
                    status,
                    self._convert_timestamp(row.get('processing_started_at')),
                    self._convert_timestamp(row.get('processing_completed_at')),
                    row.get('error_message'),
                    self._convert_timestamp(row.get('created_at')),
                    self._convert_timestamp(row.get('updated_at'))
                )
            except Exception as e:
                logger.error(f"  âŒ audio_files ë ˆì½”ë“œ ì˜¤ë¥˜: {e}")
                self.stats.errors.append(f"audio_files: {e}")

    async def _migrate_consultation_sessions(self, pg_conn: asyncpg.Connection, rows: List[sqlite3.Row]):
        """consultation_sessions í…Œì´ë¸” íŠ¹ë³„ ì²˜ë¦¬"""
        insert_sql = None"
        INSERT INTO consultation_sessions (
            audio_file_id, session_date, duration_minutes, agent_name,
            customer_id, consultation_type, overall_quality_score,
            analysis_status, analysis_started_at, analysis_completed_at,
            analysis_error_message, summary, key_issues, resolution_status,
            customer_satisfaction_score, created_at, updated_at
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17)
        """
        
        for row in rows:
            try:
                await pg_conn.execute(insert_sql,
                    row.get('audio_file_id'),
                    self._convert_date(row.get('session_date')),
                    row.get('duration_minutes'),
                    row.get('agent_name'),
                    row.get('customer_id'),
                    self._convert_enum(row.get('consultation_type'), 
                                     ['inquiry', 'complaint', 'support', 'sales', 'technical', 'billing', 'other']),
                    row.get('overall_quality_score'),
                    self._convert_enum(row.get('analysis_status', 'pending'),
                                     ['pending', 'processing', 'completed', 'failed', 'reprocessing']),
                    self._convert_timestamp(row.get('analysis_started_at')),
                    self._convert_timestamp(row.get('analysis_completed_at')),
                    row.get('analysis_error_message'),
                    row.get('summary'),
                    self._convert_to_jsonb(row.get('key_issues')),
                    self._convert_enum(row.get('resolution_status'),
                                     ['resolved', 'partially_resolved', 'unresolved', 'escalated']),
                    row.get('customer_satisfaction_score'),
                    self._convert_timestamp(row.get('created_at')),
                    self._convert_timestamp(row.get('updated_at'))
                )
            except Exception as e:
                logger.error(f"  âŒ consultation_sessions ë ˆì½”ë“œ ì˜¤ë¥˜: {e}")
                self.stats.errors.append(f"consultation_sessions: {e}")

    async def _migrate_consultation_analysis(self, pg_conn: asyncpg.Connection, rows: List[sqlite3.Row]):
        """consultation_analysis í…Œì´ë¸” (í˜¸í™˜ì„±)"""
        insert_sql = None"
        INSERT INTO consultation_analysis (
            consultation_id, audio_path, business_type, classification_type,
            detail_classification, consultation_result, summary, customer_request,
            solution, additional_info, sentiment_score, topic_keywords,
            quality_score, created_at
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
        ON CONFLICT (consultation_id) DO UPDATE SET
            summary = EXCLUDED.summary,
            quality_score = EXCLUDED.quality_score
        """
        
        for row in rows:
            try:
                await pg_conn.execute(insert_sql,
                    row['consultation_id'],
                    row['audio_path'],
                    row.get('business_type'),
                    row.get('classification_type'),
                    row.get('detail_classification'),
                    row.get('consultation_result'),
                    row.get('summary'),
                    row.get('customer_request'),
                    row.get('solution'),
                    self._convert_to_jsonb(row.get('additional_info')),
                    row.get('sentiment_score'),
                    self._convert_to_jsonb(row.get('topic_keywords')),
                    row.get('quality_score'),
                    self._convert_timestamp(row.get('created_at'))
                )
            except Exception as e:
                logger.error(f"  âŒ consultation_analysis ë ˆì½”ë“œ ì˜¤ë¥˜: {e}")
                self.stats.errors.append(f"consultation_analysis: {e}")

    async def _migrate_generic_table(self, pg_conn: asyncpg.Connection, 
                                   table_name: str, rows: List[sqlite3.Row]):
        """ì¼ë°˜ì ì¸ í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜"""
        if not rows:
            return
        
        # ì²« ë²ˆì§¸ í–‰ìœ¼ë¡œ ì»¬ëŸ¼ êµ¬ì¡° íŒŒì•…
        first_row = rows[0]
        columns = list(first_row.keys())
        
        # id ì»¬ëŸ¼ ì œì™¸ (SERIAL ìë™ ìƒì„±)
        insert_columns = [col for col in columns if col != 'id']
        placeholders = [f"${i+1}" for i in range(len(insert_columns))]
        
        insert_sql = f"""
        INSERT INTO {table_name} ({', '.join(insert_columns)})
        VALUES ({', '.join(placeholders)})
        """
        
        for row in rows:
            try:
                values = []
                for col in insert_columns:
                    value = row[col]
                    
                    # ë°ì´í„° íƒ€ì… ë³€í™˜
                    if col.endswith('_at') or col.endswith('timestamp'):
                        value = self._convert_timestamp(value)
                    elif col.endswith('_date'):
                        value = self._convert_date(value)
                    elif isinstance(value, str) and value.startswith('{'):
                        value = self._convert_to_jsonb(value)
                    
                    values.append(value)
                
                await pg_conn.execute(insert_sql, *values)
                
            except Exception as e:
                logger.error(f"  âŒ {table_name} ë ˆì½”ë“œ ì˜¤ë¥˜: {e}")
                self.stats.errors.append(f"{table_name}: {e}")

    def _convert_timestamp(self, value: Any) -> Optional[datetime]:
        """íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜"""
        if not value:
            return None
        
        if isinstance(value, datetime):
            return value
        
        try:
            if isinstance(value, str):
                # SQLiteì˜ ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
                for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S.%f', 
                           '%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M:%S.%f']:
                    try:
                        return datetime.strptime(value, fmt)
                    except ValueError:
                        continue
            
            return datetime.fromisoformat(str(value))
        except:
            logger.warning(f"íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜ ì‹¤íŒ¨: {value}")
            return None

    def _convert_date(self, value: Any) -> Optional[date]:
        """ë‚ ì§œ ë³€í™˜"""
        if not value:
            return None
        
        if isinstance(value, date):
            return value
        
        try:
            if isinstance(value, str):
                return datetime.strptime(value, '%Y-%m-%d').date()
            return date.fromisoformat(str(value))
        except:
            logger.warning(f"ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {value}")
            return None

    def _convert_enum(self, value: Any, allowed_values: List[str]) -> str | None:
        """ENUM ê°’ ë³€í™˜"""
        if not value:
            return None
        
        str_value = str(value).lower()
        if str_value in allowed_values:
            return str_value
        
        # ë§¤í•‘ ì‹œë„
        mapping = {
            'pending': 'pending',
            'processing': 'processing', 
            'completed': 'completed',
            'failed': 'failed',
            'error': 'failed'
        }
        
        return mapping.get(str_value, allowed_values[0] if allowed_values else None)

    def _convert_to_jsonb(self, value: Any) -> Optional[dict]:
        """JSONB í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not value:
            return None
        
        if isinstance(value, dict):
            return value
        
        try:
            if isinstance(value, str):
                return json.loads(value)
            return json.loads(str(value))
        except:
            # JSONì´ ì•„ë‹Œ ê²½ìš° ë¬¸ìì—´ë¡œ ë˜í•‘
            return {"content": str(value)}

    async def _verify_migration(self, pg_pool: asyncpg.Pool):
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        logger.info("ğŸ” ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì¤‘...")
        
        async with pg_pool.acquire() as conn:
            # ì£¼ìš” í…Œì´ë¸” ë ˆì½”ë“œ ìˆ˜ í™•ì¸
            verification_queries = [
                ("SELECT COUNT(*) FROM audio_files", "audio_files"),
                ("SELECT COUNT(*) FROM consultation_sessions", "consultation_sessions"),
                ("SELECT COUNT(*) FROM consultation_analysis", "consultation_analysis"),
                ("SELECT COUNT(*) FROM transcriptions", "transcriptions"),
                ("SELECT COUNT(*) FROM sentiment_analysis", "sentiment_analysis"),
            ]
            
            for query, table_name in verification_queries:
                try:
                    result = await conn.fetchval(query)
                    logger.info(f"  âœ… {table_name}: {result:,}ê°œ ë ˆì½”ë“œ")
                except Exception as e:
                    logger.warning(f"  âš ï¸ {table_name} ê²€ì¦ ì‹¤íŒ¨: {e}")

    async def _optimize_database(self, pg_pool: asyncpg.Pool):
        """ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”"""
        logger.info("âš¡ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì¤‘...")
        
        async with pg_pool.acquire() as conn:
            # í†µê³„ ì—…ë°ì´íŠ¸
            await conn.execute("ANALYZE;")
            
            # ì‹œí€€ìŠ¤ ì¬ì„¤ì • (auto increment)
            sequence_reset_queries = [
                "SELECT setval('audio_files_id_seq', COALESCE((SELECT MAX(id) FROM audio_files), 1), true);",
                "SELECT setval('consultation_sessions_id_seq', COALESCE((SELECT MAX(id) FROM consultation_sessions), 1), true);",
                "SELECT setval('consultation_analysis_id_seq', COALESCE((SELECT MAX(id) FROM consultation_analysis), 1), true);"
            ]
            
            for query in sequence_reset_queries:
                try:
                    await conn.execute(query)
                except Exception as e:
                    logger.warning(f"ì‹œí€€ìŠ¤ ì¬ì„¤ì • ì‹¤íŒ¨: {e}")
            
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì™„ë£Œ")

    def _print_final_stats(self):
        """ìµœì¢… í†µê³„ ì¶œë ¥"""
        duration = (self.stats.end_time - self.stats.start_time).total_seconds()
        
        print("\n" + "="*60)
        print("ğŸ‰ Callytics PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        print("="*60)
        print(f"ğŸ“‹ ì²˜ë¦¬ëœ í…Œì´ë¸”: {self.stats.completed_tables}/{self.stats.total_tables}")
        print(f"ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ë ˆì½”ë“œ: {self.stats.migrated_records:,}ê°œ")
        print(f"â±ï¸ ì†Œìš” ì‹œê°„: {duration:.1f}ì´ˆ")
        print(f"âš¡ ì²˜ë¦¬ ì†ë„: {self.stats.migrated_records/max(duration, 1):.0f} ë ˆì½”ë“œ/ì´ˆ")
        
        if self.stats.errors:
            print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {len(self.stats.errors)}ê±´")
            for error in self.stats.errors[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                print(f"   - {error}")
        else:
            print("âœ… ì˜¤ë¥˜ ì—†ì´ ì™„ë£Œ!")
        
        print("="*60)

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ PostgreSQL ì„¤ì • ì½ê¸°
    postgres_config = {
        'host': os.getenv('POSTGRES_HOST', 'localhost'),
        'port': int(os.getenv('POSTGRES_PORT', '5432')),
        'user': os.getenv('POSTGRES_USER', 'callytics'),
        'password': os.getenv('POSTGRES_PASSWORD', '1234'),
        'database': os.getenv('POSTGRES_DB', 'callytics')
    }
    
    # SQLite íŒŒì¼ ê²½ë¡œ
    sqlite_path = os.getenv('SQLITE_PATH', 'Callytics_new.sqlite')
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    migrator = DatabaseMigrator(sqlite_path, postgres_config)
    stats = await migrator.migrate_all()
    
    # ì„±ê³µ ì—¬ë¶€ ë°˜í™˜
    return len(stats.errors) == 0

if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("âš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        sys.exit(1)