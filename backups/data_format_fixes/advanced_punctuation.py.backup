# Standard library imports
import os
import re
import json
import threading
import time
from typing import Annotated, List, Dict, Any, Optional
from pathlib import Path

# deepmultilingualpunctuation ì•ˆì „ import
PunctuationModel = None
try:
    from deepmultilingualpunctuation import PunctuationModel
    print("âœ… deepmultilingualpunctuation imported successfully")
except ImportError as e:
    print(f"âš ï¸ deepmultilingualpunctuation import failed: {e}")
    print("ğŸ”„ AdvancedPunctuationRestorer will run in fallback mode")
except Exception as e:
    print(f"âš ï¸ deepmultilingualpunctuation error: {e}")
    print("ğŸ”„ AdvancedPunctuationRestorer will run in fallback mode")


class AdvancedPunctuationRestorer:
    """
    ê³ ì„±ëŠ¥ ë¬¸ì¥ ë¶€í˜¸ ë³µì› í´ë˜ìŠ¤
    batch í¬ê¸° ìë™ ì¡°ì •, fallback, ìºì‹± ì§€ì›
    """
    
    def __init__(self, 
                 language: str = 'ko',
                 cache_dir: str = "/app/.cache/punctuation",
                 enable_cache: bool = True,
                 max_batch_size: int = 100,
                 min_batch_size: int = 10):
        """
        AdvancedPunctuationRestorer ì´ˆê¸°í™”
        
        Parameters
        ----------
        language : str
            ì–¸ì–´ ì„¤ì •
        cache_dir : str
            ìºì‹œ ë””ë ‰í† ë¦¬
        enable_cache : bool
            ìºì‹œ í™œì„±í™” ì—¬ë¶€
        max_batch_size : int
            ìµœëŒ€ batch í¬ê¸°
        min_batch_size : int
            ìµœì†Œ batch í¬ê¸°
        """
        self.language = language
        self.cache_dir = Path(cache_dir)
        self.enable_cache = enable_cache
        self.max_batch_size = max_batch_size
        self.min_batch_size = min_batch_size
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        if self.enable_cache:
            self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ìºì‹œ ë©”íƒ€ë°ì´í„° ê´€ë¦¬
        self.cache_metadata_file = self.cache_dir / "metadata.json"
        self.cache_metadata = self._load_cache_metadata()
        self.cache_lock = threading.Lock()
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = None
        if PunctuationModel is not None:
            try:
                self.model = PunctuationModel()
                print("âœ… ë¬¸ì¥ ë¶€í˜¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ë¬¸ì¥ ë¶€í˜¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.model = None
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_stats = {
            "total_processed": 0,
            "cache_hits": 0,
            "fallback_used": 0,
            "avg_processing_time": 0.0
        }
    
    def _load_cache_metadata(self) -> Dict[str, Any]:
        """ìºì‹œ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        try:
            if self.cache_metadata_file.exists():
                with open(self.cache_metadata_file, 'r') as f:
                    return json.load(f)
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}
    
    def _save_cache_metadata(self):
        """ìºì‹œ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        try:
            with open(self.cache_metadata_file, 'w') as f:
                json.dump(self.cache_metadata, f, indent=2)
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _get_cache_key(self, text: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        import hashlib
        text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
        return f"{text_hash}_{self.language}"
    
    def _is_cached(self, text: str) -> str | None:
        """ìºì‹œëœ ê²°ê³¼ í™•ì¸"""
        if not self.enable_cache:
            return None
        
        cache_key = self._get_cache_key(text)
        
        with self.cache_lock:
            if cache_key in self.cache_metadata:
                cache_info = self.cache_metadata[cache_key]
                cache_path = self.cache_dir / cache_info["filename"]
                
                if cache_path.exists() and os.path.getsize(cache_path) > 0:
                    return str(cache_path)
        
        return None
    
    def _save_to_cache(self, text: str, result: str):
        """ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥"""
        if not self.enable_cache:
            return
        
        try:
            cache_key = self._get_cache_key(text)
            cache_filename = f"{cache_key}.txt"
            cache_path = self.cache_dir / cache_filename
            
            # ê²°ê³¼ ì €ì¥
            with open(cache_path, 'w', encoding='utf-8') as f:
                f.write(result)
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            with self.cache_lock:
                self.cache_metadata[cache_key] = {
                    "filename": cache_filename,
                    "language": self.language,
                    "created_at": time.time(),
                    "file_size": os.path.getsize(cache_path)
                }
                self._save_cache_metadata()
            
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _load_from_cache(self, cache_path: str) -> str:
        """ìºì‹œì—ì„œ ê²°ê³¼ ë¡œë“œ"""
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _calculate_optimal_batch_size(self, texts: List[str]) -> int:
        """ìµœì  batch í¬ê¸° ê³„ì‚°"""
        if not texts:
            return self.min_batch_size
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ batch í¬ê¸° ì¡°ì •
        avg_length = sum(len(text) for text in texts) / len(texts)
        
        if avg_length < 50:  # ì§§ì€ í…ìŠ¤íŠ¸
            optimal_size = min(self.max_batch_size, len(texts))
        elif avg_length < 200:  # ì¤‘ê°„ í…ìŠ¤íŠ¸
            optimal_size = min(self.max_batch_size // 2, len(texts))
        else:  # ê¸´ í…ìŠ¤íŠ¸
            optimal_size = min(self.max_batch_size // 4, len(texts))
        
        # ì„±ëŠ¥ í†µê³„ ê¸°ë°˜ ì¡°ì •
        if self.performance_stats["avg_processing_time"] > 1.0:  # 1ì´ˆ ì´ìƒ
            optimal_size = max(self.min_batch_size, optimal_size // 2)
        
        return max(self.min_batch_size, optimal_size)
    
    def _restore_punctuation_with_model(self, text: str) -> str:
        """ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¬¸ì¥ ë¶€í˜¸ ë³µì›"""
        if self.model is None:
            return self._restore_punctuation_fallback(text)
        
        try:
            # ëª¨ë¸ ì²˜ë¦¬
            result = self.model.audio_restore_punctuation(text)
            return result
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ì²˜ë¦¬ ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}")
            return self._restore_punctuation_fallback(text)
    
    def _restore_punctuation_fallback(self, text: str) -> str:
        """Fallback ë¬¸ì¥ ë¶€í˜¸ ë³µì›"""
        self.performance_stats["fallback_used"] += 1
        
        if self.language == 'ko':
            return self._apply_korean_punctuation_rules(text)
        else:
            return self._apply_simple_punctuation_rules(text)
    
    def _apply_korean_punctuation_rules(self, text: str) -> str:
        """í•œêµ­ì–´ ë¬¸ì¥ ë¶€í˜¸ ê·œì¹™ ì ìš©"""
        # ê¸°ë³¸ ì •ë¦¬
        text = text.strip()
        if not text:
            return text
        
        # ë¬¸ì¥ ë ë¶€í˜¸ ì¶”ê°€
        if not text.endswith(('.', '!', '?', '~', 'ã…‹', 'ã…')):
            # ë¬¸ì¥ ì¢…ë¥˜ íŒë‹¨
            if any(word in text for word in ['ìš”', 'ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤']):
                text += '.'
            elif any(word in text for word in ['ê¹Œ', 'ë‚˜', 'ë‹ˆ', 'ì–´', 'ì•„']):
                text += '?'
            elif any(word in text for word in ['ë„¤', 'ì–´', 'ì•„', 'ì•¼']):
                text += '!'
            else:
                text += '.'
        
        # ì‰¼í‘œ ì¶”ê°€ (ê¸´ ë¬¸ì¥)
        if len(text) > 30 and ',' not in text:
            # ì ì ˆí•œ ìœ„ì¹˜ì— ì‰¼í‘œ ì¶”ê°€
            words = text.split()
            if len(words) > 5:
                mid_point = len(words) // 2
                words.insert(mid_point, ',')
                text = ' '.join(words)
        
        return text
    
    def _apply_simple_punctuation_rules(self, text: str) -> str:
        """ê°„ë‹¨í•œ ë¬¸ì¥ ë¶€í˜¸ ê·œì¹™ ì ìš©"""
        # ê¸°ë³¸ ì •ë¦¬
        text = text.strip()
        if not text:
            return text
        
        # ë¬¸ì¥ ë ë¶€í˜¸ ì¶”ê°€
        if not text.endswith(('.', '!', '?')):
            # ê°„ë‹¨í•œ ê·œì¹™
            if text.lower().startswith(('what', 'where', 'when', 'why', 'how', 'who')):
                text += '?'
            elif any(word in text.lower() for word in ['please', 'could', 'would', 'can']):
                text += '?'
            else:
                text += '.'
        
        return text
    
    def audio_restore_punctuation_advanced(self, texts: List[str]) -> List[str]:
        """
        ê³ ì„±ëŠ¥ ë¬¸ì¥ ë¶€í˜¸ ë³µì›
        
        Parameters
        ----------
        texts : List[str]
            ë³µì›í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns
        -------
        List[str]
            ë¬¸ì¥ ë¶€í˜¸ê°€ ë³µì›ëœ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if not texts:
                return []
            
            print(f"ğŸ”¤ ë¬¸ì¥ ë¶€í˜¸ ë³µì› ì‹œì‘: {len(texts)}ê°œ í…ìŠ¤íŠ¸")
            start_time = time.time()
            
            results = []
            processed_count = 0
            
            # ìµœì  batch í¬ê¸° ê³„ì‚°
            batch_size = self._calculate_optimal_batch_size(texts)
            print(f"ğŸ“¦ Batch í¬ê¸°: {batch_size}")
            
            # Batch ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i + batch_size]
                batch_results = []
                
                for text in batch_texts:
                    # ìºì‹œ í™•ì¸
                    cached_path = self._is_cached(text)
                    if cached_path:
                        result = self._load_from_cache(cached_path)
                        self.performance_stats["cache_hits"] += 1
                    else:
                        # ëª¨ë¸ ë˜ëŠ” fallback ì²˜ë¦¬
                        result = self._restore_punctuation_with_model(text)
                        
                        # ìºì‹œì— ì €ì¥
                        self._save_to_cache(text, result)
                    
                    batch_results.append(result)
                    processed_count += 1
                
                results.extend(batch_results)
                
                # ì§„í–‰ë¥  ì¶œë ¥
                progress = (processed_count / len(texts)) * 100
                print(f"ğŸ“Š ì§„í–‰ë¥ : {progress:.1f}% ({processed_count}/{len(texts)})")
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self.performance_stats["total_processed"] += len(texts)
            self.performance_stats["avg_processing_time"] = (
                (self.performance_stats["avg_processing_time"] * (self.performance_stats["total_processed"] - len(texts)) + processing_time) 
                / self.performance_stats["total_processed"]
            )
            
            print(f"âœ… ë¬¸ì¥ ë¶€í˜¸ ë³µì› ì™„ë£Œ: {processing_time:.2f}ì´ˆ")
            print(f"ğŸ“ˆ ì„±ëŠ¥ í†µê³„: ìºì‹œ íˆíŠ¸ {self.performance_stats['cache_hits']}, Fallback {self.performance_stats['fallback_used']}")
            
            return results
            
        except Exception as e:
            print(f"âš ï¸ ë¬¸ì¥ ë¶€í˜¸ ë³µì› ì‹¤íŒ¨: {e}")
            # Fallback: ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
            return texts
    
    def audio_restore_punctuation_single(self, text: str) -> str:
        """
        ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¬¸ì¥ ë¶€í˜¸ ë³µì›
        
        Parameters
        ----------
        text : str
            ë³µì›í•  í…ìŠ¤íŠ¸
            
        Returns
        -------
        str
            ë¬¸ì¥ ë¶€í˜¸ê°€ ë³µì›ëœ í…ìŠ¤íŠ¸
        """
        results = self.audio_restore_punctuation_advanced([text])
        return results[0] if results else text
    
    def audio_get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        return self.performance_stats.copy()
    
    def audio_cleanup_cache(self, max_age_hours: int = 24):
        """ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬"""
        try:
            current_time = time.time()
            max_age_seconds = max_age_hours * 3600
            
            with self.cache_lock:
                keys_to_remove = []
                
                for cache_key, cache_info in self.cache_metadata.items():
                    if current_time - cache_info["created_at"] > max_age_seconds:
                        keys_to_remove.append(cache_key)
                
                for cache_key in keys_to_remove:
                    cache_info = self.cache_metadata[cache_key]
                    cache_path = self.cache_dir / cache_info["filename"]
                    
                    try:
                        if cache_path.exists():
                            os.remove(cache_path)
                            print(f"ğŸ§¹ ë¬¸ì¥ ë¶€í˜¸ ìºì‹œ ì •ë¦¬: {cache_info['filename']}")
                    except Exception as e:
                        print(f"âš ï¸ ìºì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {cache_path}, {e}")
                    
                    del self.cache_metadata[cache_key]
                
                if keys_to_remove:
                    self._save_cache_metadata()
                    print(f"ğŸ§¹ {len(keys_to_remove)}ê°œ ë¬¸ì¥ ë¶€í˜¸ ìºì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                    
        except Exception as e:
            print(f"âš ï¸ ë¬¸ì¥ ë¶€í˜¸ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")


class PunctuationRestorer:
    """
    ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë¬¸ì¥ ë¶€í˜¸ ë³µì› í´ë˜ìŠ¤
    """
    
    def __init__(self, language: str = 'en'):
        self.advanced_restorer = AdvancedPunctuationRestorer(language=language)
    
    def audio_restore_punctuation(self, word_speaker_mapping: List[Dict]) -> List[Dict]:
        """ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜"""
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        texts = []
        for item in word_speaker_mapping:
            if isinstance(item, dict) and 'word' in item:
                texts.append(item['word'])
            elif isinstance(item, str):
                texts.append(item)
        
        # ë¬¸ì¥ ë¶€í˜¸ ë³µì›
        restored_texts = self.advanced_restorer.audio_restore_punctuation_advanced(texts)
        
        # ê²°ê³¼ ë§¤í•‘
        result = []
        text_index = 0
        
        for item in word_speaker_mapping:
            if isinstance(item, dict) and 'word' in item:
                new_item = item.copy()
                new_item['word'] = restored_texts[text_index] if text_index < len(restored_texts) else item['word']
                result.append(new_item)
                text_index += 1
            elif isinstance(item, str):
                result.append(restored_texts[text_index] if text_index < len(restored_texts) else item)
                text_index += 1
            else:
                result.append(item)
        
        return result 