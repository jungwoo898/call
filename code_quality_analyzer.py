#!/usr/bin/env python3
"""
ì½”ë“œ í’ˆì§ˆ ë¶„ì„ ë° ë¦¬íŒ©í„°ë§ ìŠ¤í¬ë¦½íŠ¸
ì¤‘ë³µ ì •ì˜, íƒ€ì… ë¶ˆì¼ì¹˜, ì£½ì€ ì½”ë“œë¥¼ íƒì§€í•˜ê³  ì¼ê´€ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ë¦¬íŒ©í„°ë§í•©ë‹ˆë‹¤.
"""

import os
import re
import ast
import json
from pathlib import Path
from typing import Dict, List, Set, Tuple, Any
from collections import defaultdict
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CodeQualityAnalyzer:
    def __init__(self):
        self.duplicate_definitions = []
        self.type_mismatches = []
        self.dead_code = []
        self.namespace_inconsistencies = []
        self.import_issues = []
        self.function_signatures = {}
        self.class_definitions = {}
        self.variable_usage = defaultdict(list)
        
    def analyze_project(self, project_root: str = "."):
        """ì „ì²´ í”„ë¡œì íŠ¸ ë¶„ì„"""
        print("ğŸ” ì½”ë“œ í’ˆì§ˆ ë¶„ì„ ì‹œì‘...")
        
        python_files = list(Path(project_root).rglob("*.py"))
        print(f"ğŸ“ ë°œê²¬ëœ Python íŒŒì¼: {len(python_files)}ê°œ")
        
        for file_path in python_files:
            if self._should_skip_file(file_path):
                continue
                
            try:
                self._analyze_file(file_path)
            except Exception as e:
                logger.warning(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {file_path}, ì˜¤ë¥˜: {e}")
        
        self._detect_duplicates()
        self._detect_type_mismatches()
        self._detect_dead_code()
        self._analyze_namespace_consistency()
        self._generate_refactoring_plan()
        
    def _should_skip_file(self, file_path: Path) -> bool:
        """ë¶„ì„ì—ì„œ ì œì™¸í•  íŒŒì¼ íŒë‹¨"""
        skip_patterns = [
            "__pycache__",
            ".git",
            "venv",
            ".venv",
            "node_modules",
            ".pytest_cache",
            "build",
            "dist"
        ]
        
        return any(pattern in str(file_path) for pattern in skip_patterns)
    
    def _analyze_file(self, file_path: Path):
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        try:
            tree = ast.parse(content)
            analyzer = FileAnalyzer(file_path, tree, content)
            analyzer.analyze()
            
            # ê²°ê³¼ ìˆ˜ì§‘
            self.function_signatures[file_path] = analyzer.function_signatures
            self.class_definitions[file_path] = analyzer.class_definitions
            self.variable_usage[file_path] = analyzer.variable_usage
            
        except SyntaxError as e:
            logger.warning(f"êµ¬ë¬¸ ì˜¤ë¥˜: {file_path}, ë¼ì¸ {e.lineno}: {e.text}")
    
    def _detect_duplicates(self):
        """ì¤‘ë³µ ì •ì˜ íƒì§€"""
        print("ğŸ” ì¤‘ë³µ ì •ì˜ íƒì§€ ì¤‘...")
        
        # í•¨ìˆ˜ ì¤‘ë³µ íƒì§€
        all_functions = {}
        for file_path, functions in self.function_signatures.items():
            for func_name, func_info in functions.items():
                if func_name in all_functions:
                    self.duplicate_definitions.append({
                        'type': 'function',
                        'name': func_name,
                        'locations': [
                            {'file': str(all_functions[func_name]['file']), 'line': all_functions[func_name]['line']},
                            {'file': str(file_path), 'line': func_info['line']}
                        ]
                    })
                else:
                    all_functions[func_name] = {'file': file_path, 'line': func_info['line']}
        
        # í´ë˜ìŠ¤ ì¤‘ë³µ íƒì§€
        all_classes = {}
        for file_path, classes in self.class_definitions.items():
            for class_name, class_info in classes.items():
                if class_name in all_classes:
                    self.duplicate_definitions.append({
                        'type': 'class',
                        'name': class_name,
                        'locations': [
                            {'file': str(all_classes[class_name]['file']), 'line': all_classes[class_name]['line']},
                            {'file': str(file_path), 'line': class_info['line']}
                        ]
                    })
                else:
                    all_classes[class_name] = {'file': file_path, 'line': class_info['line']}
    
    def _detect_type_mismatches(self):
        """íƒ€ì… ë¶ˆì¼ì¹˜ íƒì§€"""
        print("ğŸ” íƒ€ì… ë¶ˆì¼ì¹˜ íƒì§€ ì¤‘...")
        
        # í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ íƒ€ì… ë¶ˆì¼ì¹˜ íƒì§€
        function_signatures = defaultdict(list)
        for file_path, functions in self.function_signatures.items():
            for func_name, func_info in functions.items():
                function_signatures[func_name].append({
                    'file': file_path,
                    'signature': func_info['signature'],
                    'line': func_info['line']
                })
        
        for func_name, signatures in function_signatures.items():
            if len(signatures) > 1:
                # ì‹œê·¸ë‹ˆì²˜ ë¹„êµ
                unique_signatures = set(sig['signature'] for sig in signatures)
                if len(unique_signatures) > 1:
                    self.type_mismatches.append({
                        'type': 'function_signature',
                        'name': func_name,
                        'signatures': signatures
                    })
    
    def _detect_dead_code(self):
        """ì£½ì€ ì½”ë“œ íƒì§€"""
        print("ğŸ” ì£½ì€ ì½”ë“œ íƒì§€ ì¤‘...")
        
        # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” í•¨ìˆ˜ íƒì§€
        all_functions = set()
        used_functions = set()
        
        for file_path, functions in self.function_signatures.items():
            for func_name in functions.keys():
                all_functions.add(func_name)
        
        # í•¨ìˆ˜ ì‚¬ìš© ë¶„ì„
        for file_path, usage in self.variable_usage.items():
            for var_name in usage:
                if var_name in all_functions:
                    used_functions.add(var_name)
        
        # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” í•¨ìˆ˜ ì°¾ê¸°
        unused_functions = all_functions - used_functions
        for func_name in unused_functions:
            for file_path, functions in self.function_signatures.items():
                if func_name in functions:
                    self.dead_code.append({
                        'type': 'unused_function',
                        'name': func_name,
                        'file': str(file_path),
                        'line': functions[func_name]['line']
                    })
    
    def _analyze_namespace_consistency(self):
        """ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¼ê´€ì„± ë¶„ì„"""
        print("ğŸ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¼ê´€ì„± ë¶„ì„ ì¤‘...")
        
        # íŒŒì¼ë³„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ íŒ¨í„´ ë¶„ì„
        namespace_patterns = {}
        
        for file_path in self.function_signatures.keys():
            module_name = file_path.stem
            namespace_patterns[file_path] = {
                'module': module_name,
                'functions': list(self.function_signatures[file_path].keys()),
                'classes': list(self.class_definitions.get(file_path, {}).keys())
            }
        
        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¼ê´€ì„± ê²€ì‚¬
        for file_path, patterns in namespace_patterns.items():
            module_name = patterns['module']
            
            # í•¨ìˆ˜ëª…ì´ ëª¨ë“ˆëª…ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°
            for func_name in patterns['functions']:
                if not func_name.startswith(module_name.lower()) and not func_name.startswith('_'):
                    self.namespace_inconsistencies.append({
                        'type': 'function_naming',
                        'file': str(file_path),
                        'function': func_name,
                        'module': module_name,
                        'suggestion': f"{module_name.lower()}_{func_name}"
                    })
    
    def _generate_refactoring_plan(self):
        """ë¦¬íŒ©í„°ë§ ê³„íš ìƒì„±"""
        print("ğŸ“‹ ë¦¬íŒ©í„°ë§ ê³„íš ìƒì„± ì¤‘...")
        
        # WindowsPathë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        def convert_paths(obj):
            if isinstance(obj, dict):
                return {k: convert_paths(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_paths(item) for item in obj]
            elif hasattr(obj, '__str__') and 'WindowsPath' in str(type(obj)):
                return str(obj)
            else:
                return obj
        
        refactoring_plan = {
            'duplicate_definitions': convert_paths(self.duplicate_definitions),
            'type_mismatches': convert_paths(self.type_mismatches),
            'dead_code': convert_paths(self.dead_code),
            'namespace_inconsistencies': convert_paths(self.namespace_inconsistencies),
            'recommendations': []
        }
        
        # ë¦¬íŒ©í„°ë§ ê¶Œì¥ì‚¬í•­ ìƒì„±
        if self.duplicate_definitions:
            refactoring_plan['recommendations'].append({
                'type': 'consolidate_duplicates',
                'description': 'ì¤‘ë³µ ì •ì˜ëœ í•¨ìˆ˜/í´ë˜ìŠ¤ë¥¼ í†µí•©í•˜ê±°ë‚˜ ì´ë¦„ì„ ë³€ê²½í•˜ì„¸ìš”.',
                'count': len(self.duplicate_definitions)
            })
        
        if self.type_mismatches:
            refactoring_plan['recommendations'].append({
                'type': 'fix_type_mismatches',
                'description': 'í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ íƒ€ì… ë¶ˆì¼ì¹˜ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.',
                'count': len(self.type_mismatches)
            })
        
        if self.dead_code:
            refactoring_plan['recommendations'].append({
                'type': 'remove_dead_code',
                'description': 'ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” í•¨ìˆ˜ë¥¼ ì œê±°í•˜ê±°ë‚˜ ë¬¸ì„œí™”í•˜ì„¸ìš”.',
                'count': len(self.dead_code)
            })
        
        if self.namespace_inconsistencies:
            refactoring_plan['recommendations'].append({
                'type': 'standardize_namespaces',
                'description': 'í•¨ìˆ˜ëª…ì„ ëª¨ë“ˆ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ë§ê²Œ í‘œì¤€í™”í•˜ì„¸ìš”.',
                'count': len(self.namespace_inconsistencies)
            })
        
        # ê²°ê³¼ ì €ì¥
        with open('code_quality_report.json', 'w', encoding='utf-8') as f:
            json.dump(refactoring_plan, f, indent=2, ensure_ascii=False)
        
        self._print_summary(refactoring_plan)
    
    def _print_summary(self, plan: Dict):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š ì½”ë“œ í’ˆì§ˆ ë¶„ì„ ê²°ê³¼")
        print("="*60)
        
        print(f"ğŸ” ì¤‘ë³µ ì •ì˜: {len(plan['duplicate_definitions'])}ê°œ")
        for dup in plan['duplicate_definitions'][:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
            print(f"   - {dup['type']}: {dup['name']}")
        
        print(f"ğŸ” íƒ€ì… ë¶ˆì¼ì¹˜: {len(plan['type_mismatches'])}ê°œ")
        for mismatch in plan['type_mismatches'][:5]:
            print(f"   - í•¨ìˆ˜: {mismatch['name']}")
        
        print(f"ğŸ” ì£½ì€ ì½”ë“œ: {len(plan['dead_code'])}ê°œ")
        for dead in plan['dead_code'][:5]:
            print(f"   - {dead['type']}: {dead['name']} ({dead['file']})")
        
        print(f"ğŸ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¶ˆì¼ì¹˜: {len(plan['namespace_inconsistencies'])}ê°œ")
        for ns in plan['namespace_inconsistencies'][:5]:
            print(f"   - {ns['function']} â†’ {ns['suggestion']}")
        
        print(f"\nğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: code_quality_report.json")
        print("="*60)

class FileAnalyzer(ast.NodeVisitor):
    def __init__(self, file_path: Path, tree: ast.AST, content: str):
        self.file_path = file_path
        self.tree = tree
        self.content = content
        self.function_signatures = {}
        self.class_definitions = {}
        self.variable_usage = []
        
    def analyze(self):
        """íŒŒì¼ ë¶„ì„ ì‹¤í–‰"""
        self.visit(self.tree)
    
    def visit_FunctionDef(self, node: ast.FunctionDef):
        """í•¨ìˆ˜ ì •ì˜ ë°©ë¬¸"""
        # í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ìƒì„±
        args = []
        for arg in node.args.args:
            if arg.annotation:
                args.append(f"{arg.arg}: {ast.unparse(arg.annotation)}")
            else:
                args.append(arg.arg)
        
        signature = f"({', '.join(args)})"
        
        self.function_signatures[node.name] = {
            'signature': signature,
            'line': node.lineno,
            'args': [arg.arg for arg in node.args.args]
        }
        
        self.generic_visit(node)
    
    def visit_ClassDef(self, node: ast.ClassDef):
        """í´ë˜ìŠ¤ ì •ì˜ ë°©ë¬¸"""
        self.class_definitions[node.name] = {
            'line': node.lineno,
            'bases': [ast.unparse(base) for base in node.bases]
        }
        
        self.generic_visit(node)
    
    def visit_Name(self, node: ast.Name):
        """ë³€ìˆ˜ëª… ë°©ë¬¸"""
        if isinstance(node.ctx, ast.Load):  # ì½ê¸° ì „ìš© ì‚¬ìš©
            self.variable_usage.append(node.id)
        
        self.generic_visit(node)
    
    def visit_Attribute(self, node: ast.Attribute):
        """ì†ì„± ì ‘ê·¼ ë°©ë¬¸"""
        if isinstance(node.ctx, ast.Load):
            # ì „ì²´ ê²½ë¡œ ìƒì„± (ì˜ˆ: module.function)
            path = self._get_attribute_path(node)
            if path:
                self.variable_usage.append(path)
        
        self.generic_visit(node)
    
    def _get_attribute_path(self, node: ast.Attribute) -> str:
        """ì†ì„± ê²½ë¡œ ìƒì„±"""
        parts = []
        current = node
        
        while isinstance(current, ast.Attribute):
            parts.append(current.attr)
            current = current.value
        
        if isinstance(current, ast.Name):
            parts.append(current.id)
            return '.'.join(reversed(parts))
        
        return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = CodeQualityAnalyzer()
    analyzer.analyze_project()
    
    print("\nğŸ‰ ì½”ë“œ í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ!")
    print("ğŸ“‹ ë¦¬íŒ©í„°ë§ ê³„íšì„ í™•ì¸í•˜ì„¸ìš”: code_quality_report.json")

if __name__ == "__main__":
    main() 