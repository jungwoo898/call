#!/usr/bin/env python3
"""
Callytics Docker νΈν™μ„± λ¶„μ„ μ¤ν¬λ¦½νΈ
ChatGPT μ§€μ μ‚¬ν•­λ“¤μ„ κ²€μ¦ν•κ³  ν•΄κ²°μ±…μ„ μ μ‹ν•©λ‹λ‹¤.
"""

import subprocess
import sys
import json
from packaging import version
from packaging.specifiers import SpecifierSet
from typing import Dict, List, Tuple, Optional
import re

class CompatibilityAnalyzer:
    def __init__(self):
        self.issues = []
        self.recommendations = []
        
    def log_issue(self, category: str, description: str, severity: str = "WARNING"):
        self.issues.append({
            "category": category,
            "description": description,
            "severity": severity
        })
    
    def log_recommendation(self, category: str, description: str, action: str):
        self.recommendations.append({
            "category": category,
            "description": description,
            "action": action
        })

    def check_transformers_tokenizers_compatibility(self):
        """Transformersμ™€ Tokenizers νΈν™μ„± κ²€μ‚¬"""
        print("π” Transformers β†” Tokenizers νΈν™μ„± κ²€μ‚¬...")
        
        # Transformers 4.40.2λ” tokenizers >= 0.19, < 0.20μ„ μ”κµ¬
        current_tokenizers = "0.13.2"  # requirements.txtμ—μ„ ν™•μΈλ λ²„μ „
        required_tokenizers = "0.19.4"
        
        if version.parse(current_tokenizers) < version.parse("0.19.0"):
            self.log_issue(
                "Transformers β†” Tokenizers",
                f"transformers 4.40.2λ” tokenizers >= 0.19κ°€ ν•„μ”ν•μ§€λ§ ν„μ¬ {current_tokenizers}κ°€ μ„¤μ •λ¨",
                "CRITICAL"
            )
            self.log_recommendation(
                "Transformers β†” Tokenizers",
                "Tokenizers λ²„μ „μ„ 0.19.4λ΅ μ—…κ·Έλ μ΄λ“",
                f"tokenizers=={required_tokenizers}"
            )
            return False
        return True

    def check_fastapi_pydantic_compatibility(self):
        """FastAPIμ™€ Pydantic νΈν™μ„± κ²€μ‚¬"""
        print("π” FastAPI β†” Pydantic νΈν™μ„± κ²€μ‚¬...")
        
        current_fastapi = "0.104.1"
        current_pydantic = "1.10.12"  # requirements.txtμ—μ„ ν™•μΈ
        
        # FastAPI 0.104.1μ€ Pydantic 1.xμ™€ νΈν™
        # ν•μ§€λ§ Gradio 4.19.2λ” Pydantic 2.xκ°€ ν•„μ”
        self.log_issue(
            "FastAPI β†” Pydantic",
            f"FastAPI {current_fastapi} (Pydantic 1.x)μ™€ Gradio 4.19.2 (Pydantic 2.x) κ°„ μ¶©λ",
            "HIGH"
        )
        self.log_recommendation(
            "FastAPI β†” Pydantic",
            "FastAPIμ™€ Pydanticμ„ μµμ‹  λ²„μ „μΌλ΅ μ—…κ·Έλ μ΄λ“",
            "fastapi==0.115.13, pydantic==2.7.4"
        )
        return False

    def check_pytorch_audio_stack_compatibility(self):
        """PyTorchμ™€ Audio μ¤νƒ νΈν™μ„± κ²€μ‚¬"""
        print("π” PyTorch β†” Audio μ¤νƒ νΈν™μ„± κ²€μ‚¬...")
        
        current_torch = "2.1.2"
        current_demucs = "4.0.1"
        current_speechbrain = "0.5.12"
        
        # PyTorch 2.1.2μ™€ νΈν™λλ” λ²„μ „λ“¤ ν™•μΈ
        if version.parse(current_demucs) < version.parse("4.1.0"):
            self.log_issue(
                "PyTorch β†” Audio",
                f"demucs {current_demucs}λ” PyTorch 2.1κ³Ό μ™„μ „ νΈν™λμ§€ μ•μ„ μ μμ",
                "MEDIUM"
            )
            self.log_recommendation(
                "PyTorch β†” Audio",
                "Demucsλ¥Ό 4.1.0 μ΄μƒμΌλ΅ μ—…κ·Έλ μ΄λ“",
                "demucs>=4.1.0"
            )
        
        if version.parse(current_speechbrain) < version.parse("0.5.16"):
            self.log_issue(
                "PyTorch β†” Audio",
                f"speechbrain {current_speechbrain}λ” PyTorch 2.1κ³Ό μµμ ν™”λμ§€ μ•μ",
                "MEDIUM"
            )
            self.log_recommendation(
                "PyTorch β†” Audio",
                "SpeechBrainμ„ 0.5.16 μ΄μƒμΌλ΅ μ—…κ·Έλ μ΄λ“",
                "speechbrain>=0.5.16"
            )
        
        return True

    def check_nemo_compatibility(self):
        """NeMo λ²„μ „ νΈν™μ„± κ²€μ‚¬"""
        print("π” NeMo λ²„μ „ νΈν™μ„± κ²€μ‚¬...")
        
        current_nemo = "1.17.0"
        
        # NeMo 1.xλ” PyTorch 1.13 κΈ°λ°μ΄λ―€λ΅ PyTorch 2.xμ™€ μ¥κΈ°μ μΌλ΅ νΈν™μ„± λ¬Έμ 
        if version.parse(current_nemo) < version.parse("2.0.0"):
            self.log_issue(
                "NeMo νΈν™μ„±",
                f"nemo_toolkit {current_nemo}λ” PyTorch 1.13 κΈ°λ°μΌλ΅ PyTorch 2.xμ™€ μ¥κΈ° νΈν™μ„± λ¬Έμ ",
                "HIGH"
            )
            self.log_recommendation(
                "NeMo νΈν™μ„±",
                "NeMoλ¥Ό 2.x κ³„μ—΄λ΅ μ—…κ·Έλ μ΄λ“ (PyTorch 2.x μ§€μ›)",
                "nemo_toolkit>=2.3.1"
            )
            return False
        return True

    def check_numpy_compatibility(self):
        """NumPy λ²„μ „ νΈν™μ„± κ²€μ‚¬"""
        print("π” NumPy λ²”μ„ νΈν™μ„± κ²€μ‚¬...")
        
        current_numpy = "1.23.5"
        
        # NeMo 1.17μ€ numpy < 1.24λ΅ μ ν•
        if version.parse(current_numpy) >= version.parse("1.24.0"):
            self.log_issue(
                "NumPy νΈν™μ„±",
                f"numpy {current_numpy}λ” NeMo 1.17μ numpy < 1.24 μ ν•κ³Ό μ¶©λ",
                "MEDIUM"
            )
        else:
            print(f"β… NumPy {current_numpy}λ” ν„μ¬ NeMo λ²„μ „κ³Ό μ•μ „ν•¨")
        
        return True

    def check_docker_runtime_issues(self):
        """Docker λ°νƒ€μ„ μ΄μ κ²€μ‚¬"""
        print("π” Docker λ°νƒ€μ„ μ΄μ κ²€μ‚¬...")
        
        issues_found = []
        
        # PortAudio λ°νƒ€μ„ λΌμ΄λΈλ¬λ¦¬ λ„λ½
        self.log_issue(
            "Docker λ°νƒ€μ„",
            "builderμ—μ„ portaudio19-devλ΅ μ»΄νμΌλ λ°”μ΄λ„λ¦¬κ°€ λ°νƒ€μ„μ—μ„ libportaudio2 λ„λ½",
            "HIGH"
        )
        self.log_recommendation(
            "Docker λ°νƒ€μ„",
            "λ°νƒ€μ„ μ¤ν…μ΄μ§€μ— libportaudio2 μ¶”κ°€",
            "apt-get install -y libportaudio2"
        )
        
        # NLTK λ°μ΄ν„° λ„λ½
        self.log_issue(
            "Docker λ°νƒ€μ„",
            "builderμ—μ„ λ‹¤μ΄λ΅λ“ν• /root/nltk_dataκ°€ λ°νƒ€μ„μΌλ΅ λ³µμ‚¬λμ§€ μ•μ",
            "MEDIUM"
        )
        self.log_recommendation(
            "Docker λ°νƒ€μ„",
            "NLTK λ°μ΄ν„° κ²½λ΅ κ³ μ • λ° λ³µμ‚¬",
            "ENV NLTK_DATA=/usr/local/nltk_data λ° COPY λ…λ Ήμ–΄ μ¶”κ°€"
        )
        
        return len(issues_found) == 0

    def check_health_endpoint(self):
        """ν—¬μ¤μ²΄ν¬ μ—”λ“ν¬μΈνΈ κ²€μ‚¬"""
        print("π” ν—¬μ¤μ²΄ν¬ μ—”λ“ν¬μΈνΈ κ²€μ‚¬...")
        
        # main.pyμ—μ„ /health μ—”λ“ν¬μΈνΈ ν™•μΈ ν•„μ”
        self.log_issue(
            "ν—¬μ¤μ²΄ν¬",
            "Dockerfileμ—μ„ /health μ—”λ“ν¬μΈνΈλ¥Ό μ‚¬μ©ν•μ§€λ§ FastAPI μ•±μ— κµ¬ν„λμ§€ μ•μ",
            "MEDIUM"
        )
        self.log_recommendation(
            "ν—¬μ¤μ²΄ν¬",
            "FastAPI μ•±μ— /health μ—”λ“ν¬μΈνΈ κµ¬ν„",
            "@app.get('/health') μ—”λ“ν¬μΈνΈ μ¶”κ°€"
        )
        
        return False

    def generate_fixed_requirements(self):
        """μμ •λ requirements.txt μƒμ„±"""
        print("\nπ“ μμ •λ requirements.txt μƒμ„± μ¤‘...")
        
        fixed_requirements = [
            "# μμ •λ requirements.txt - νΈν™μ„± λ¬Έμ  ν•΄κ²°",
            "",
            "# ν•µμ‹¬ ν”„λ μ„μ›ν¬",
            "torch==2.1.2",
            "torchvision==0.16.2", 
            "torchaudio==2.1.2",
            "",
            "# μμ •λ νΈν™μ„± ν¨ν‚¤μ§€λ“¤",
            "transformers==4.40.2",
            "tokenizers==0.19.4  # transformers 4.40.2 νΈν™μ„±",
            "",
            "fastapi==0.115.13  # Pydantic 2.x νΈν™",
            "pydantic==2.7.4    # Gradio 4.19.2 νΈν™",
            "",
            "# μ—…κ·Έλ μ΄λ“λ μ¤λ””μ¤ μ¤νƒ",
            "demucs>=4.1.0      # PyTorch 2.1 νΈν™μ„± κ°μ„ ",
            "speechbrain>=0.5.16  # PyTorch 2.1 μµμ ν™”",
            "",
            "# μ—…κ·Έλ μ΄λ“λ NeMo (μ„ νƒμ‚¬ν•­ - ν° λ³€κ²½)",
            "# nemo_toolkit>=2.3.1  # PyTorch 2.x μ§€μ›",
            "nemo_toolkit==1.17.0  # ν„μ¬ λ²„μ „ μ μ§€ (μ•μ •μ„±)",
            "",
            "# κΈ°μ΅΄ ν¨ν‚¤μ§€λ“¤ (λ³€κ²½ μ—†μ)",
            "numpy==1.23.5",
            "gradio==4.19.2",
            "# ... λ‚λ¨Έμ§€ ν¨ν‚¤μ§€λ“¤"
        ]
        
        with open("requirements_fixed.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(fixed_requirements))
        
        print("β… requirements_fixed.txt μƒμ„± μ™„λ£")

    def generate_dockerfile_fixes(self):
        """Dockerfile μμ •μ‚¬ν•­ μƒμ„±"""
        print("\nπ³ Dockerfile μμ •μ‚¬ν•­ μƒμ„± μ¤‘...")
        
        dockerfile_fixes = [
            "# Dockerfile μμ •μ‚¬ν•­",
            "",
            "# λ°νƒ€μ„ μ¤ν…μ΄μ§€μ— μ¶”κ°€ν•  λ‚΄μ©:",
            "",
            "# 1. PortAudio λ°νƒ€μ„ λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ",
            "RUN apt-get update && apt-get install -y \\",
            "    libportaudio2 \\",
            "    && rm -rf /var/lib/apt/lists/*",
            "",
            "# 2. NLTK λ°μ΄ν„° κ²½λ΅ μ„¤μ • λ° λ³µμ‚¬",
            "ENV NLTK_DATA=/usr/local/nltk_data",
            "COPY --from=builder /root/nltk_data /usr/local/nltk_data",
            "",
            "# 3. pip dependency check μ¶”κ°€ (μ„ νƒμ‚¬ν•­)",
            "RUN pip install pip-tools && pip check",
            "",
            "# 4. ν—¬μ¤μ²΄ν¬ μ—”λ“ν¬μΈνΈ ν™•μΈ",
            "# main.pyμ— λ‹¤μ μ½”λ“ μ¶”κ°€ ν•„μ”:",
            "# @app.get('/health')",
            "# async def health_check():",
            "#     return {'status': 'healthy'}"
        ]
        
        with open("dockerfile_fixes.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(dockerfile_fixes))
        
        print("β… dockerfile_fixes.txt μƒμ„± μ™„λ£")

    def run_analysis(self):
        """μ „μ²΄ νΈν™μ„± λ¶„μ„ μ‹¤ν–‰"""
        print("π€ Callytics Docker νΈν™μ„± λ¶„μ„ μ‹μ‘\n")
        
        # κ° κ²€μ‚¬ μ‹¤ν–‰
        checks = [
            ("Transformers β†” Tokenizers", self.check_transformers_tokenizers_compatibility),
            ("FastAPI β†” Pydantic", self.check_fastapi_pydantic_compatibility),
            ("PyTorch β†” Audio μ¤νƒ", self.check_pytorch_audio_stack_compatibility),
            ("NeMo νΈν™μ„±", self.check_nemo_compatibility),
            ("NumPy νΈν™μ„±", self.check_numpy_compatibility),
            ("Docker λ°νƒ€μ„", self.check_docker_runtime_issues),
            ("ν—¬μ¤μ²΄ν¬", self.check_health_endpoint)
        ]
        
        results = {}
        for name, check_func in checks:
            try:
                results[name] = check_func()
                print()
            except Exception as e:
                print(f"β {name} κ²€μ‚¬ μ¤‘ μ¤λ¥: {e}")
                results[name] = False
        
        # κ²°κ³Ό μ”μ•½
        self.print_summary(results)
        
        # μμ •μ‚¬ν•­ μƒμ„±
        self.generate_fixed_requirements()
        self.generate_dockerfile_fixes()
        
        return results

    def print_summary(self, results: Dict[str, bool]):
        """λ¶„μ„ κ²°κ³Ό μ”μ•½ μ¶λ ¥"""
        print("=" * 80)
        print("π“ νΈν™μ„± λ¶„μ„ κ²°κ³Ό μ”μ•½")
        print("=" * 80)
        
        # μ‹¬κ°λ„λ³„ μ΄μ λ¶„λ¥
        critical_issues = [i for i in self.issues if i["severity"] == "CRITICAL"]
        high_issues = [i for i in self.issues if i["severity"] == "HIGH"]
        medium_issues = [i for i in self.issues if i["severity"] == "MEDIUM"]
        warning_issues = [i for i in self.issues if i["severity"] == "WARNING"]
        
        print(f"\nπ”΄ CRITICAL μ΄μ: {len(critical_issues)}κ°")
        for issue in critical_issues:
            print(f"   β€Ά {issue['category']}: {issue['description']}")
        
        print(f"\nπ  HIGH μ΄μ: {len(high_issues)}κ°")
        for issue in high_issues:
            print(f"   β€Ά {issue['category']}: {issue['description']}")
        
        print(f"\nπ΅ MEDIUM μ΄μ: {len(medium_issues)}κ°")
        for issue in medium_issues:
            print(f"   β€Ά {issue['category']}: {issue['description']}")
        
        print(f"\nπΆ WARNING μ΄μ: {len(warning_issues)}κ°")
        for issue in warning_issues:
            print(f"   β€Ά {issue['category']}: {issue['description']}")
        
        print(f"\nπ“‹ μ΄ κ¶μ¥μ‚¬ν•­: {len(self.recommendations)}κ°")
        
        # ChatGPT μ§€μ μ‚¬ν•­ κ²€μ¦ κ²°κ³Ό
        print("\n" + "=" * 80)
        print("π¤– ChatGPT μ§€μ μ‚¬ν•­ κ²€μ¦ κ²°κ³Ό")
        print("=" * 80)
        
        chatgpt_points = [
            ("1. Transformers β†” Tokenizers", len(critical_issues) > 0),
            ("2. FastAPI β†” Pydantic", len([i for i in high_issues if "FastAPI" in i["category"]]) > 0),
            ("3. PyTorch β†” Audio μ¤νƒ", len([i for i in medium_issues if "Audio" in i["category"]]) > 0),
            ("4. NeMo λ²„μ „ νΈν™μ„±", len([i for i in high_issues if "NeMo" in i["category"]]) > 0),
            ("5. NumPy λ²”μ„", len([i for i in medium_issues if "NumPy" in i["category"]]) == 0),
            ("6. PortAudio λ°νƒ€μ„", len([i for i in high_issues if "Docker" in i["category"]]) > 0),
            ("7. NLTK λ°μ΄ν„°", len([i for i in medium_issues if "Docker" in i["category"]]) > 0),
            ("8. ν—¬μ¤μ²΄ν¬ μ—”λ“ν¬μΈνΈ", len([i for i in medium_issues if "ν—¬μ¤μ²΄ν¬" in i["category"]]) > 0)
        ]
        
        for point, is_valid in chatgpt_points:
            status = "β… νƒ€λ‹Ήν•¨" if is_valid else "β λ¬Έμ μ—†μ"
            print(f"   {point}: {status}")
        
        print(f"\nπ― ChatGPT μ§€μ μ‚¬ν•­ μ •ν™•λ„: {sum(1 for _, valid in chatgpt_points if valid)}/{len(chatgpt_points)} ({sum(1 for _, valid in chatgpt_points if valid)/len(chatgpt_points)*100:.1f}%)")
        
        # μ¦‰μ‹ μ μ© κ°€λ¥ν• μμ •μ‚¬ν•­
        print("\n" + "=" * 80)
        print("π› οΈ  μ¦‰μ‹ μ μ© κ¶μ¥ μμ •μ‚¬ν•­")
        print("=" * 80)
        
        immediate_fixes = [
            "tokenizers==0.19.4 (CRITICAL - transformers νΈν™μ„±)",
            "fastapi==0.115.13, pydantic==2.7.4 (HIGH - Gradio νΈν™μ„±)",
            "Dockerfileμ— libportaudio2 μ„¤μΉ μ¶”κ°€ (HIGH - λ°νƒ€μ„ μ¤λ¥ λ°©μ§€)",
            "main.pyμ— /health μ—”λ“ν¬μΈνΈ μ¶”κ°€ (MEDIUM - ν—¬μ¤μ²΄ν¬)"
        ]
        
        for i, fix in enumerate(immediate_fixes, 1):
            print(f"   {i}. {fix}")
        
        print(f"\nπ“ μƒμ„±λ νμΌ:")
        print(f"   β€Ά requirements_fixed.txt - μμ •λ μμ΅΄μ„±")
        print(f"   β€Ά dockerfile_fixes.txt - Dockerfile μμ •μ‚¬ν•­")

if __name__ == "__main__":
    analyzer = CompatibilityAnalyzer()
    results = analyzer.run_analysis()
    
    # μΆ…λ£ μ½”λ“ μ„¤μ •
    critical_count = len([i for i in analyzer.issues if i["severity"] == "CRITICAL"])
    high_count = len([i for i in analyzer.issues if i["severity"] == "HIGH"])
    
    if critical_count > 0:
        print(f"\nβ CRITICAL μ΄μ {critical_count}κ° λ°κ²¬ - μ¦‰μ‹ μμ • ν•„μ”")
        sys.exit(2)
    elif high_count > 0:
        print(f"\nβ οΈ  HIGH μ΄μ {high_count}κ° λ°κ²¬ - μμ • κ¶μ¥")
        sys.exit(1)
    else:
        print(f"\nβ… μ‹¬κ°ν• νΈν™μ„± λ¬Έμ  μ—†μ")
        sys.exit(0) 