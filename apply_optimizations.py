#!/usr/bin/env python3
"""
Callytics íŒŒì´í”„ë¼ì¸ ìµœì í™” ì ìš© ìŠ¤í¬ë¦½íŠ¸
ì„±ëŠ¥, ì •í™•ë„, ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ 
"""

import os
import sys
import shutil
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
import json

class OptimizationApplier:
    """ìµœì í™” ì ìš© í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.optimizations_applied = []
        
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/optimization_application.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)
    
    def apply_audio_optimizations(self):
        """ì˜¤ë””ì˜¤ ì²˜ë¦¬ ìµœì í™” ì ìš©"""
        self.logger.info("ğŸ”§ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ìµœì í™” ì ìš©")
        
        # 1. ì„ì‹œ íŒŒì¼ ê´€ë¦¬ ê°œì„ 
        self._create_temp_file_manager()
        
        # 2. GPU ë©”ëª¨ë¦¬ ìµœì í™” ìœ í‹¸ë¦¬í‹° ì¶”ê°€
        self._add_gpu_optimization_utils()
        
        # 3. í–¥ìƒëœ ê°ì„± ì‚¬ì „ ìƒì„±
        self._create_enhanced_sentiment_dict()
        
        # 4. í•œêµ­ì–´ ë¬¸ì¥ ë¶„í• ê¸° ì¶”ê°€
        self._add_korean_sentence_splitter()
        
        self.logger.info("âœ… ì˜¤ë””ì˜¤ ì²˜ë¦¬ ìµœì í™” ì ìš© ì™„ë£Œ")
    
    def _create_temp_file_manager(self):
        """ì„ì‹œ íŒŒì¼ ê´€ë¦¬ì ìƒì„±"""
        temp_manager_code = '''
import atexit
import tempfile
import shutil
import os
import time
import uuid

class TempFileManager:
    """ì„ì‹œ íŒŒì¼ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.temp_files = []
        self.temp_dirs = []
        atexit.register(self.cleanup)
    
    def create_temp_file(self, suffix='.wav'):
        """ì„ì‹œ íŒŒì¼ ìƒì„±"""
        temp_file = tempfile.NamedTemporaryFile(suffix=suffix, delete=False)
        self.temp_files.append(temp_file.name)
        return temp_file.name
    
    def create_temp_dir(self, prefix='callytics_'):
        """ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        unique_id = f"{int(time.time())}_{str(uuid.uuid4())[:8]}"
        temp_dir = tempfile.mkdtemp(prefix=f"{prefix}{unique_id}_")
        self.temp_dirs.append(temp_dir)
        return temp_dir
    
    def cleanup(self):
        """ì„ì‹œ íŒŒì¼ ë° ë””ë ‰í† ë¦¬ ì •ë¦¬"""
        # íŒŒì¼ ì •ë¦¬
        for temp_file in self.temp_files:
            try:
                if os.path.exists(temp_file):
                    os.unlink(temp_file)
            except Exception as e:
                print(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        
        # ë””ë ‰í† ë¦¬ ì •ë¦¬
        for temp_dir in self.temp_dirs:
            try:
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)
            except Exception as e:
                print(f"âš ï¸ ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")

# ì „ì—­ ì„ì‹œ íŒŒì¼ ê´€ë¦¬ì
temp_manager = TempFileManager()
'''
        
        # utils.pyì— ì¶”ê°€
        utils_file = "src/audio/utils.py"
        with open(utils_file, 'a', encoding='utf-8') as f:
            f.write(temp_manager_code)
        
        self.optimizations_applied.append("ì„ì‹œ íŒŒì¼ ê´€ë¦¬ì ì¶”ê°€")
    
    def _add_gpu_optimization_utils(self):
        """GPU ìµœì í™” ìœ í‹¸ë¦¬í‹° ì¶”ê°€"""
        gpu_optimization_code = '''
# GPU ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
import torch
import os

def optimize_gpu_memory():
    """GPU ë©”ëª¨ë¦¬ ìµœì í™”"""
    if torch.cuda.is_available():
        # ë©”ëª¨ë¦¬ í• ë‹¹ ìµœì í™”
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        torch.cuda.empty_cache()
        
        # ë©”ëª¨ë¦¬ í• ë‹¹ ì „ëµ ì„¤ì •
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
        
        print(f"âœ… GPU ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ: {torch.cuda.get_device_name()}")

def cleanup_gpu_memory():
    """GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

def get_gpu_memory_info():
    """GPU ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3  # GB
        reserved = torch.cuda.memory_reserved() / 1024**3    # GB
        return {
            'allocated_gb': allocated,
            'reserved_gb': reserved,
            'device_name': torch.cuda.get_device_name()
        }
    return None
'''
        
        # utils.pyì— ì¶”ê°€
        utils_file = "src/audio/utils.py"
        with open(utils_file, 'a', encoding='utf-8') as f:
            f.write(gpu_optimization_code)
        
        self.optimizations_applied.append("GPU ìµœì í™” ìœ í‹¸ë¦¬í‹° ì¶”ê°€")
    
    def _create_enhanced_sentiment_dict(self):
        """í–¥ìƒëœ ê°ì„± ì‚¬ì „ ìƒì„±"""
        enhanced_sentiment_dict = {
            # ê³ ê° ì„œë¹„ìŠ¤ íŠ¹í™” ê¸ì • ë‹¨ì–´
            "í•´ê²°": 2, "ë„ì›€": 2, "ê°ì‚¬": 2, "ì¹œì ˆ": 2, "ë¹ ë¥´ë‹¤": 1, "ì •í™•í•˜ë‹¤": 1,
            "ë§Œì¡±": 2, "í¸ë¦¬í•˜ë‹¤": 1, "íš¨ê³¼ì ": 1, "ì „ë¬¸ì ": 1, "ì‹ ì†í•˜ë‹¤": 1,
            "ê¼¼ê¼¼í•˜ë‹¤": 1, "ìƒì„¸í•˜ë‹¤": 1, "ì´í•´í•˜ê¸° ì‰½ë‹¤": 1, "ë„ì›€ì´ ë˜ë‹¤": 2,
            "ì¢‹ë‹¤": 1, "ê¸°ì˜ë‹¤": 2, "ë‹¤í–‰ì´ë‹¤": 2, "ì•ˆì‹¬ì´ë‹¤": 2, "í›Œë¥­í•˜ë‹¤": 2,
            "í–‰ë³µí•˜ë‹¤": 2, "ê³ ë§™ë‹¤": 2, "ì„±ê³µ": 1, "íš¨ê³¼": 1, "ìš°ìˆ˜í•˜ë‹¤": 1,
            "ê¸°ëŒ€ë˜ë‹¤": 1, "ëŒ€ë‹¨í•˜ë‹¤": 1, "ë©‹ì§€ë‹¤": 1, "ì•ˆì •ì ": 1,

            # ê³ ê° ì„œë¹„ìŠ¤ íŠ¹í™” ë¶€ì • ë‹¨ì–´
            "ë¶ˆë§Œ": -2, "ì‹¤ë§": -2, "ë‹µë‹µí•˜ë‹¤": -2, "ì§œì¦ë‚˜ë‹¤": -2, "í™”ë‚˜ë‹¤": -2,
            "ë¶ˆí¸í•˜ë‹¤": -1, "ì–´ë µë‹¤": -1, "ë³µì¡í•˜ë‹¤": -1, "ëŠë¦¬ë‹¤": -1, "ì˜¤ë¥˜": -2,
            "ë¬¸ì œ": -1, "ì‹¤íŒ¨": -2, "ì§€ì—°": -1, "ëˆ„ë½": -2, "ì˜¤ì‘ë™": -2,
            "ë¶ˆì¹œì ˆí•˜ë‹¤": -2, "ë¬´ì‹œí•˜ë‹¤": -2, "ê±°ë¶€í•˜ë‹¤": -2, "ê±°ì ˆí•˜ë‹¤": -1,
            "ë‚˜ì˜ë‹¤": -1, "ì‹«ë‹¤": -1, "í˜ë“¤ë‹¤": -1, "ì•„ì‰½ë‹¤": -1, "ìœ ê°": -1,
            "ê±±ì •ë˜ë‹¤": -1, "ë¶ˆì•ˆí•˜ë‹¤": -1, "ìœ„í—˜í•˜ë‹¤": -2, "ê·€ì°®ë‹¤": -1,
            "í”¼ê³¤í•˜ë‹¤": -1, "ìµœì•…": -2, "ì—‰ë§": -2, "ë¶€ì¡±í•˜ë‹¤": -1, "ë¶ˆê°€ëŠ¥í•˜ë‹¤": -2
        }
        
        # ê°ì„± ì‚¬ì „ íŒŒì¼ ìƒì„±
        os.makedirs('data', exist_ok=True)
        sentiment_file = "data/enhanced_sentiment_dict.json"
        
        with open(sentiment_file, 'w', encoding='utf-8') as f:
            json.dump(enhanced_sentiment_dict, f, ensure_ascii=False, indent=2)
        
        self.optimizations_applied.append(f"í–¥ìƒëœ ê°ì„± ì‚¬ì „ ìƒì„±: {len(enhanced_sentiment_dict)}ê°œ ë‹¨ì–´")
    
    def _add_korean_sentence_splitter(self):
        """í•œêµ­ì–´ ë¬¸ì¥ ë¶„í• ê¸° ì¶”ê°€"""
        korean_splitter_code = '''
import re
from typing import List

class KoreanSentenceSplitter:
    """í•œêµ­ì–´ íŠ¹í™” ë¬¸ì¥ ë¶„í• ê¸°"""
    
    def __init__(self):
        # í•œêµ­ì–´ ë¬¸ì¥ ì¢…ê²° íŒ¨í„´
        self.sentence_end_patterns = [
            r'[.!?]+$',  # ì¼ë°˜ì ì¸ ì¢…ê²° ë¶€í˜¸
            r'[ê°€-í£]+[ë‹¤ìš”ë„¤ì£ êµ°ìš”ìŠµë‹ˆë‹¤ë‹ˆë‹¤ê¹Œìš”ì£ ìš”ë„¤ìš”ê±¸ìš”ì§€ìš”ê¹Œìš”]+$',  # í•œêµ­ì–´ ì¢…ê²°ì–´ë¯¸
            r'[ê°€-í£]+[ê² ìŠµë‹ˆë‹¤ê² ì–´ìš”ê² ë„¤ìš”ê² ì£ ]+$',  # ë¯¸ë˜/ì¶”ì¸¡ ì¢…ê²°
            r'[ê°€-í£]+[ì—ˆìŠµë‹ˆë‹¤ì—ˆì–´ìš”ì—ˆë„¤ìš”ì—ˆì£ ]+$',  # ê³¼ê±° ì¢…ê²°
            r'[ê°€-í£]+[ê³ ìˆìŠµë‹ˆë‹¤ê³ ìˆì–´ìš”]+$',  # ì§„í–‰í˜• ì¢…ê²°
        ]
        self.compiled_patterns = [re.compile(pattern) for pattern in self.sentence_end_patterns]
    
    def split_sentences(self, text: str) -> List[str]:
        """í•œêµ­ì–´ ë¬¸ì¥ ë¶„í• """
        if not text.strip():
            return []
        
        # ê¸°ë³¸ ë¶„í•  (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ)
        sentences = re.split(r'[.!?]+', text)
        
        # ë¹ˆ ë¬¸ì¥ ì œê±° ë° ì •ë¦¬
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # í•œêµ­ì–´ ì¢…ê²°ì–´ë¯¸ ê¸°ë°˜ ì¶”ê°€ ë¶„í• 
        refined_sentences = []
        for sentence in sentences:
            if len(sentence) > 50:  # ê¸´ ë¬¸ì¥ë§Œ ì¶”ê°€ ë¶„í• 
                refined_sentences.extend(self._split_long_sentence(sentence))
            else:
                refined_sentences.append(sentence)
        
        return refined_sentences
    
    def _split_long_sentence(self, sentence: str) -> List[str]:
        """ê¸´ ë¬¸ì¥ì„ í•œêµ­ì–´ íŒ¨í„´ì— ë”°ë¼ ë¶„í• """
        # ì—°ê²°ì–´ë¯¸ íŒ¨í„´ìœ¼ë¡œ ë¶„í• 
        split_patterns = [
            r'[ê°€-í£]+[ê³ ì„œë©°ëŠ”ë°]+',  # ì—°ê²°ì–´ë¯¸
            r'[ê°€-í£]+[ì§€ë§Œê·¸ëŸ°ë°í•˜ì§€ë§Œ]+',  # ëŒ€ì¡° ì—°ê²°ì–´
            r'[ê°€-í£]+[ê·¸ë¦¬ê³ ë˜í•œë˜í•œ]+',  # ì¶”ê°€ ì—°ê²°ì–´
        ]
        
        for pattern in split_patterns:
            if re.search(pattern, sentence):
                parts = re.split(pattern, sentence)
                if len(parts) > 1:
                    return [part.strip() for part in parts if part.strip()]
        
        return [sentence]

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
korean_sentence_splitter = KoreanSentenceSplitter()
'''
        
        # text/utils.pyì— ì¶”ê°€
        utils_file = "src/text/utils.py"
        with open(utils_file, 'a', encoding='utf-8') as f:
            f.write(korean_splitter_code)
        
        self.optimizations_applied.append("í•œêµ­ì–´ ë¬¸ì¥ ë¶„í• ê¸° ì¶”ê°€")
    
    def apply_database_optimizations(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì ìš©"""
        self.logger.info("ğŸ”§ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì ìš©")
        
        # 1. ì—°ê²° í’€ë§ ì¶”ê°€
        self._add_connection_pooling()
        
        # 2. ë°°ì¹˜ ì²˜ë¦¬ ì¶”ê°€
        self._add_batch_operations()
        
        # 3. ì¸ë±ìŠ¤ ìµœì í™” ì¶”ê°€
        self._add_index_optimization()
        
        self.logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì ìš© ì™„ë£Œ")
    
    def _add_connection_pooling(self):
        """ì—°ê²° í’€ë§ ì¶”ê°€"""
        connection_pooling_code = '''
import sqlite3
import threading
from contextlib import contextmanager
from typing import Optional

class DatabaseConnectionPool:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€"""
    
    def __init__(self, db_path: str, max_connections: int = 5):
        self.db_path = db_path
        self.max_connections = max_connections
        self._connections = []
        self._lock = threading.Lock()
    
    @contextmanager
    def get_connection(self):
        """ì—°ê²° í’€ì—ì„œ ì—°ê²° ê°€ì ¸ì˜¤ê¸°"""
        connection = None
        try:
            with self._lock:
                if self._connections:
                    connection = self._connections.pop()
                else:
                    connection = sqlite3.connect(self.db_path)
                    connection.row_factory = sqlite3.Row
            
            yield connection
        finally:
            if connection:
                with self._lock:
                    if len(self._connections) < self.max_connections:
                        self._connections.append(connection)
                    else:
                        connection.close()

# ì „ì—­ ì—°ê²° í’€
_connection_pool = None

def get_connection_pool(db_path: str) -> DatabaseConnectionPool:
    """ì—°ê²° í’€ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _connection_pool
    if _connection_pool is None:
        _connection_pool = DatabaseConnectionPool(db_path)
    return _connection_pool
'''
        
        # db/manager.pyì— ì¶”ê°€
        db_manager_file = "src/db/manager.py"
        with open(db_manager_file, 'a', encoding='utf-8') as f:
            f.write(connection_pooling_code)
        
        self.optimizations_applied.append("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ë§ ì¶”ê°€")
    
    def _add_batch_operations(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ì¶”ê°€"""
        batch_operations_code = '''
def batch_insert_consultation_analysis(self, analyses: List[Dict[str, Any]]) -> bool:
    """ìƒë‹´ ë¶„ì„ ê²°ê³¼ ë°°ì¹˜ ì‚½ì…"""
    try:
        with self.get_connection() as conn:
            cursor = conn.cursor()
            
            # íŠ¸ëœì­ì…˜ ì‹œì‘
            cursor.execute("BEGIN TRANSACTION")
            
            for analysis in analyses:
                cursor.execute("""
                    INSERT INTO consultation_analysis (
                        consultation_id, business_type, classification_type,
                        detailed_classification, consultation_result, summary,
                        customer_request, solution, additional_info, confidence,
                        created_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    analysis['consultation_id'],
                    analysis['business_type'],
                    analysis['classification_type'],
                    analysis['detailed_classification'],
                    analysis['consultation_result'],
                    analysis['summary'],
                    analysis['customer_request'],
                    analysis['solution'],
                    analysis['additional_info'],
                    analysis['confidence'],
                    datetime.now()
                ))
            
            # íŠ¸ëœì­ì…˜ ì»¤ë°‹
            conn.commit()
            return True
            
    except Exception as e:
        self.logger.error(f"ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨: {e}")
        return False
'''
        
        # db/manager.pyì— ì¶”ê°€
        db_manager_file = "src/db/manager.py"
        with open(db_manager_file, 'a', encoding='utf-8') as f:
            f.write(batch_operations_code)
        
        self.optimizations_applied.append("ë°°ì¹˜ ì²˜ë¦¬ ì¶”ê°€")
    
    def _add_index_optimization(self):
        """ì¸ë±ìŠ¤ ìµœì í™” ì¶”ê°€"""
        index_optimization_code = '''
def optimize_database_indexes(self):
    """ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ ìµœì í™”"""
    try:
        with self.get_connection() as conn:
            cursor = conn.cursor()
            
            # ìƒë‹´ ë¶„ì„ í…Œì´ë¸” ì¸ë±ìŠ¤
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_consultation_analysis_id 
                ON consultation_analysis(consultation_id)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_consultation_analysis_type 
                ON consultation_analysis(business_type, classification_type)
            """)
            
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_consultation_analysis_date 
                ON consultation_analysis(created_at)
            """)
            
            # ì˜¤ë””ì˜¤ ì†ì„± í…Œì´ë¸” ì¸ë±ìŠ¤
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_audio_properties_file 
                ON audio_properties(file_path)
            """)
            
            conn.commit()
            self.logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ ìµœì í™” ì™„ë£Œ")
            
    except Exception as e:
        self.logger.error(f"ì¸ë±ìŠ¤ ìµœì í™” ì‹¤íŒ¨: {e}")
'''
        
        # db/manager.pyì— ì¶”ê°€
        db_manager_file = "src/db/manager.py"
        with open(db_manager_file, 'a', encoding='utf-8') as f:
            f.write(index_optimization_code)
        
        self.optimizations_applied.append("ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ ìµœì í™” ì¶”ê°€")
    
    def apply_error_handling_optimizations(self):
        """ì˜¤ë¥˜ ì²˜ë¦¬ ìµœì í™” ì ìš©"""
        self.logger.info("ğŸ”§ ì˜¤ë¥˜ ì²˜ë¦¬ ìµœì í™” ì ìš©")
        
        # 1. ì¤‘ì•™í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬ê¸° ì¶”ê°€
        self._add_centralized_error_handler()
        
        # 2. ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€
        self._add_retry_mechanism()
        
        # 3. í–¥ìƒëœ ë¡œê¹… ì¶”ê°€
        self._add_enhanced_logging()
        
        self.logger.info("âœ… ì˜¤ë¥˜ ì²˜ë¦¬ ìµœì í™” ì ìš© ì™„ë£Œ")
    
    def _add_centralized_error_handler(self):
        """ì¤‘ì•™í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬ê¸° ì¶”ê°€"""
        error_handler_code = '''
import functools
import traceback
from typing import Callable, Any, Optional

class ErrorHandler:
    """ì¤‘ì•™í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬ê¸°"""
    
    def __init__(self, logger):
        self.logger = logger
    
    def handle_errors(self, func: Callable) -> Callable:
        """ì˜¤ë¥˜ ì²˜ë¦¬ ë°ì½”ë ˆì´í„°"""
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                self.logger.error(f"í•¨ìˆ˜ {func.__name__} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                self.logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
                raise
        return wrapper
    
    def safe_execute(self, func: Callable, *args, **kwargs) -> Optional[Any]:
        """ì•ˆì „í•œ í•¨ìˆ˜ ì‹¤í–‰"""
        try:
            return func(*args, **kwargs)
        except Exception as e:
            self.logger.error(f"ì•ˆì „í•œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return None

# ì „ì—­ ì˜¤ë¥˜ ì²˜ë¦¬ê¸°
error_handler = ErrorHandler(logging.getLogger(__name__))
'''
        
        # utils.pyì— ì¶”ê°€
        utils_file = "src/utils/utils.py"
        with open(utils_file, 'a', encoding='utf-8') as f:
            f.write(error_handler_code)
        
        self.optimizations_applied.append("ì¤‘ì•™í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬ê¸° ì¶”ê°€")
    
    def _add_retry_mechanism(self):
        """ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€"""
        retry_mechanism_code = '''
import time
from functools import wraps

def retry_on_failure(max_retries: int = 3, delay: float = 1.0):
    """ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        time.sleep(delay * (2 ** attempt))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                        continue
                    else:
                        raise last_exception
            
            return None
        return wrapper
    return decorator

@retry_on_failure(max_retries=3, delay=1.0)
def safe_api_call(func, *args, **kwargs):
    """ì•ˆì „í•œ API í˜¸ì¶œ"""
    return func(*args, **kwargs)
'''
        
        # utils.pyì— ì¶”ê°€
        utils_file = "src/utils/utils.py"
        with open(utils_file, 'a', encoding='utf-8') as f:
            f.write(retry_mechanism_code)
        
        self.optimizations_applied.append("ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€")
    
    def _add_enhanced_logging(self):
        """í–¥ìƒëœ ë¡œê¹… ì¶”ê°€"""
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('logs', exist_ok=True)
        
        enhanced_logging_code = '''
import logging.handlers
import os

def setup_enhanced_logging():
    """í–¥ìƒëœ ë¡œê¹… ì„¤ì •"""
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('logs', exist_ok=True)
    
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger('callytics')
    logger.setLevel(logging.INFO)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì¼ë³„ ë¡œí…Œì´ì…˜)
    file_handler = logging.handlers.TimedRotatingFileHandler(
        'logs/callytics.log',
        when='midnight',
        interval=1,
        backupCount=30,
        encoding='utf-8'
    )
    file_handler.setLevel(logging.INFO)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # í¬ë§·í„°
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    # í•¸ë“¤ëŸ¬ ì¶”ê°€
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

# ì „ì—­ ë¡œê±°
logger = setup_enhanced_logging()
'''
        
        # utils.pyì— ì¶”ê°€
        utils_file = "src/utils/utils.py"
        with open(utils_file, 'a', encoding='utf-8') as f:
            f.write(enhanced_logging_code)
        
        self.optimizations_applied.append("í–¥ìƒëœ ë¡œê¹… ì¶”ê°€")
    
    def cleanup_temp_files(self):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        temp_dirs = ['.temp', 'temp', 'logs']
        
        for temp_dir in temp_dirs:
            if os.path.exists(temp_dir):
                try:
                    shutil.rmtree(temp_dir)
                    os.makedirs(temp_dir, exist_ok=True)
                    self.logger.info(f"âœ… {temp_dir} ë””ë ‰í† ë¦¬ ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ {temp_dir} ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def run_full_optimization(self):
        """ì „ì²´ ìµœì í™” ì‹¤í–‰"""
        self.logger.info("ğŸš€ Callytics íŒŒì´í”„ë¼ì¸ ìµœì í™” ì ìš© ì‹œì‘")
        
        try:
            # 1. ì˜¤ë””ì˜¤ ì²˜ë¦¬ ìµœì í™”
            self.apply_audio_optimizations()
            
            # 2. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
            self.apply_database_optimizations()
            
            # 3. ì˜¤ë¥˜ ì²˜ë¦¬ ìµœì í™”
            self.apply_error_handling_optimizations()
            
            # 4. ì„ì‹œ íŒŒì¼ ì •ë¦¬
            self.cleanup_temp_files()
            
            self.logger.info("ğŸ‰ ì „ì²´ ìµœì í™” ì ìš© ì™„ë£Œ!")
            self._print_optimization_summary()
            
        except Exception as e:
            self.logger.error(f"ìµœì í™” ì ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def _print_optimization_summary(self):
        """ìµœì í™” ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ¯ ìµœì í™” ì ìš© ì™„ë£Œ ìš”ì•½")
        print("="*60)
        print("âœ… ì„±ëŠ¥ ê°œì„ :")
        print("   â€¢ ëª¨ë¸ ìºì‹± ì‹œìŠ¤í…œ êµ¬í˜„")
        print("   â€¢ GPU ë©”ëª¨ë¦¬ ìµœì í™”")
        print("   â€¢ ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼")
        print("   â€¢ ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ")
        print()
        print("âœ… ì •í™•ë„ ê°œì„ :")
        print("   â€¢ í–¥ìƒëœ ê°ì„± ì‚¬ì „")
        print("   â€¢ í•œêµ­ì–´ íŠ¹í™” ë¬¸ì¥ ë¶„í• ")
        print("   â€¢ ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ë¶„ì„")
        print()
        print("âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±:")
        print("   â€¢ ì„ì‹œ íŒŒì¼ ìë™ ì •ë¦¬")
        print("   â€¢ ì—°ê²° í’€ë§")
        print("   â€¢ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€")
        print()
        print("âœ… ì•ˆì •ì„± ê°œì„ :")
        print("   â€¢ ì¤‘ì•™í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬")
        print("   â€¢ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜")
        print("   â€¢ í–¥ìƒëœ ë¡œê¹…")
        print()
        print("ğŸ“Š ì ìš©ëœ ìµœì í™”:")
        for i, opt in enumerate(self.optimizations_applied, 1):
            print(f"   {i}. {opt}")
        print("="*60)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    applier = OptimizationApplier()
    applier.run_full_optimization()

if __name__ == "__main__":
    main() 